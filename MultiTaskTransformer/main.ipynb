{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import List, Optional\n",
    "from numpy.typing import NDArray\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Tuple\n",
    "import pm4py\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from package.processtransformer.models import transformer\n",
    "from package.processtransformer.data.loader import LogsDataLoader\n",
    "from package.processtransformer.data.processor import LogsDataProcessor\n",
    "from package.processtransformer.constants import Feature_Type, Target, Temporal_Feature, Model_Architecture\n",
    "\n",
    "\n",
    "# Initialize data dir, if not exists\n",
    "if not os.path.exists(\"datasets\"): \n",
    "    os.mkdir(\"datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pipeline:\n",
    "    \n",
    "    def __init__(self, dataset_name: str, filepath: str, columns: List[str], additional_columns: Optional[Dict[Feature_Type, List[str]]],\n",
    "                 datetime_format: str, model_learning_rate: float, model_epochs: int, model_num_layers: int,\n",
    "                 input_columns: List[str], target_columns: Dict[str, Target], temporal_features: Dict[Temporal_Feature, bool],\n",
    "                 model_architecture = Model_Architecture):\n",
    "        self.dataset_name: str = dataset_name\n",
    "        self.filepath: str = filepath\n",
    "        self.columns: List[str] = columns\n",
    "        self.additional_columns: Optional[Dict[Feature_Type, List[str]]] = additional_columns\n",
    "        self.datetime_format: str = datetime_format\n",
    "        self.model_learning_rate: float = model_learning_rate\n",
    "        self.model_epochs: int = model_epochs\n",
    "        self.model_num_layers: int = model_num_layers\n",
    "        \n",
    "        self.target_columns: Dict[str, Target] = target_columns\n",
    "        for target_col in target_columns.keys():\n",
    "            if target_col == columns[1]:\n",
    "                self.target_columns[\"concept_name\"] = self.target_columns.pop(target_col)\n",
    "                break\n",
    "                \n",
    "        self.input_columns: List[str] = input_columns\n",
    "        for idx, input_col in enumerate(input_columns):\n",
    "            if input_col == columns[1]:\n",
    "                self.input_columns[idx] = \"concept_name\"\n",
    "                break\n",
    "        self.temporal_features: Dict[Temporal_Feature, bool] = temporal_features\n",
    "        self.model_architecture = model_architecture\n",
    "        \n",
    "        # self._model_id: str = (\n",
    "        #     f\"{dataset_name}\"\n",
    "        #     f\"##{'#'.join(self.columns)}\"\n",
    "        #     f\"##{'#'.join(self.additional_columns)}\"\n",
    "        #     f\"##{'#'.join(self.task.value)}\"\n",
    "        #     f\"##{self.model_learning_rate}\"\n",
    "        #     f\"##{self.model_epochs}\"\n",
    "        #     f\"##{self.model_num_layers}\")\n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        return (\n",
    "            f\"dataset_name: '{self.dataset_name}'\\n\"\n",
    "            f\"filepath: '{self.filepath}'\\n\"\n",
    "            f\"columns: '{self.columns}'\\n\"\n",
    "            f\"additional_columns: '{self.additional_columns}'\\n\"\n",
    "            f\"datetime_format: '{self.datetime_format}'\\n\"\n",
    "            f\"Model learning rate: '{self.model_learning_rate}'\\n\"\n",
    "            f\"Model Epochs: '{self.model_epochs}'\\n\"\n",
    "            f\"Number of Transformer Layers in Model: '{self.model_num_layers}'\\n\"\n",
    "            f\"Target columns: '{self.target_columns}'\\n\"\n",
    "            f\"Input columns: '{self.input_columns}'\\n\")\n",
    "        \n",
    "    \n",
    "    def save_as_csv(self):\n",
    "        dir_path = os.path.join( \"datasets\", self.dataset_name )\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        file_path = os.path.join( dir_path, self.filepath )\n",
    "        \n",
    "        \n",
    "        if file_path.endswith('.xes'):\n",
    "            print(\"Converting xes to csv file\")\n",
    "            df = pm4py.convert_to_dataframe(pm4py.read_xes(file_path)).astype(str)\n",
    "            df.to_csv(file_path.replace(\".xes\", \".csv\"), index=False)\n",
    "        elif file_path.endswith('.csv'):\n",
    "            print(\"Input file already has csv format\")\n",
    "            \n",
    "    \n",
    "    # preprocess the event log and save the train-test split as csv files\n",
    "    def preprocess_log(self) -> List[int]:\n",
    "        data_processor = LogsDataProcessor(\n",
    "            name=self.dataset_name,\n",
    "            filepath=self.filepath,\n",
    "            columns=self.columns,\n",
    "            additional_columns=self.additional_columns,  # Add all additional columns here, first all categorical, then all numerical features\n",
    "            input_columns=self.input_columns,\n",
    "            target_columns=self.target_columns,\n",
    "            datetime_format=self.datetime_format,\n",
    "            temporal_features=self.temporal_features,\n",
    "            pool=4\n",
    "        )\n",
    "        \n",
    "        # TODO: sanitize columns\n",
    "        # self.columns = [data_processor.sanitize_filename(col) for col in self.columns]\n",
    "        \n",
    "        # self.additional_columns = {\n",
    "        #                         feature_type: [data_processor.sanitize_filename(feature) for feature in feature_lst] for feature_type,\n",
    "        #                         feature_lst in self.additional_columns.items()\n",
    "        #                         } if len(self.additional_columns)>0 else self.additional_columns\n",
    "        self.target_columns = {data_processor.sanitize_filename(feature, self.columns): target for feature, target in self.target_columns.items()}\n",
    "        self.input_columns = [data_processor.sanitize_filename(col, self.columns) for col in self.input_columns]\n",
    "        self.columns = [data_processor.sanitize_filename(col, self.columns) for col in self.columns]\n",
    "        \n",
    "        # Preprocess the event log and make train-test split\n",
    "        data_processor.process_logs()\n",
    "        # flatten self.additional_columns to get all used features\n",
    "        self.additional_columns = data_processor.additional_columns\n",
    "        self.used_features = [item for sublist in self.additional_columns.values() for item in sublist]\n",
    "        \n",
    "        \n",
    "        # TODO: Compute the number of unique classes in each categorical column\n",
    "        # train_df = pd.read_csv(os.path.join(\"datasets\", self.dataset_name, \"processed\", f\"{self._preprocessing_id}_train.csv\"))\n",
    "        # num_classes_list = data_processor._compute_num_classes(train_df)\n",
    "        \n",
    "        # return num_classes_list\n",
    "    \n",
    "    \n",
    "    # load the preprocessed train-test split from the csv files\n",
    "    def load_data(self) -> Tuple [ LogsDataLoader, Dict[str, pd.DataFrame], Dict[str, pd.DataFrame], Dict[str, Dict[str, int]], Dict[Feature_Type, List[str]] ]:\n",
    "        data_loader = LogsDataLoader(name=self.dataset_name, input_columns=self.input_columns,\n",
    "                                     target_columns=self.target_columns, temporal_features=self.temporal_features)\n",
    "        train_dfs, test_dfs, word_dicts, feature_type_dict, mask = data_loader.load_data()\n",
    "        word_dicts = dict(sorted(word_dicts.items()))\n",
    "        return data_loader, train_dfs, test_dfs, word_dicts, feature_type_dict, mask\n",
    "    \n",
    "    \n",
    "    def prepare_data( self, data_loader, dfs: Dict[str, pd.DataFrame], x_scaler=None, y_scaler=None,\n",
    "                     train: bool = True) -> Tuple[ Dict[str, NDArray[np.float32]], Dict[str, NDArray[np.float32]], Dict[str, NDArray[np.float32]], int ]:\n",
    "        print(\"Preparing data...\")\n",
    "        # initialize max_case_length\n",
    "        max_case_length = False\n",
    "        # initialize token dicts\n",
    "        x_token_dict, y_token_dict, x_token_dict_numerical, y_token_dict_numerical = {}, {}, {}, {}\n",
    "        \n",
    "        # loop over all feature dfs\n",
    "        for idx, (feature, feature_df) in enumerate(dfs.items()):\n",
    "            \n",
    "            # get current feature_type\n",
    "            for feature_type, feature_lst in self.additional_columns.items():\n",
    "                if feature in feature_lst: break\n",
    "            \n",
    "            if idx == 0 and train:\n",
    "                (x_tokens, y_tokens, max_case_length\n",
    "                ) = data_loader.prepare_data(feature=feature, df=feature_df, max_case_length=True)\n",
    "            else:\n",
    "                x_tokens, y_tokens = data_loader.prepare_data(feature=feature, df=feature_df)\n",
    "            \n",
    "            if feature_type is Feature_Type.TIMESTAMP or feature_type is Feature_Type.NUMERICAL:\n",
    "                x_token_dict_numerical.update(x_tokens)\n",
    "                y_token_dict_numerical.update(y_tokens)\n",
    "            else:\n",
    "                # update x_token_dict\n",
    "                x_token_dict.update(x_tokens)\n",
    "                y_token_dict.update(y_tokens)\n",
    "            \n",
    "        # TODO:\n",
    "        if len(x_token_dict_numerical) > 0  and len(list(x_token_dict_numerical.values())[0]) > 0:\n",
    "            # Concatenate all the feature arrays along the rows (axis=0)\n",
    "            combined_data = np.vstack(list(x_token_dict_numerical.values()))\n",
    "            if x_scaler is None:\n",
    "                # Initialize the StandardScaler\n",
    "                x_scaler = StandardScaler()\n",
    "                # Fit the scaler on the combined data\n",
    "                x_scaler.fit(combined_data)\n",
    "            # Transform the combined data\n",
    "            scaled_combined_data = x_scaler.transform(combined_data)\n",
    "            # split the scaled combined data back into the original feature dict\n",
    "            split_indices = np.cumsum([value.shape[0] for value in x_token_dict_numerical.values()])[:-1]\n",
    "            scaled_data_parts = np.vsplit(scaled_combined_data, split_indices)\n",
    "            # Reconstruct the dictionary with scaled data\n",
    "            scaled_dict = {key: scaled_data_parts[i] for i, key in enumerate(x_token_dict_numerical.keys())}\n",
    "            # update x_token_dict\n",
    "            x_token_dict.update(scaled_dict)\n",
    "        if len(y_token_dict_numerical) > 0:\n",
    "            # Prepare list to store valid arrays (non-empty)\n",
    "            valid_arrays = []\n",
    "            valid_keys = []\n",
    "\n",
    "            # Check for empty arrays and prepare data for scaling\n",
    "            for key, value in y_token_dict_numerical.items():\n",
    "                if value.size > 0:  # Only consider non-empty arrays\n",
    "                    valid_arrays.append(value.reshape(-1, 1))  # Reshape to 2D\n",
    "                    valid_keys.append(key)\n",
    "\n",
    "            # If there are valid arrays to scale\n",
    "            if valid_arrays:\n",
    "                combined_data = np.hstack(valid_arrays)  # Horizontal stacking for features\n",
    "\n",
    "                if y_scaler is None:\n",
    "                    # Initialize the StandardScaler\n",
    "                    y_scaler = StandardScaler()\n",
    "                    # Fit the scaler on the combined data\n",
    "                    y_scaler.fit(combined_data)\n",
    "\n",
    "                # Transform the combined data\n",
    "                scaled_combined_data = y_scaler.transform(combined_data)\n",
    "\n",
    "                # Split the scaled combined data back into individual features\n",
    "                scaled_data_parts = np.hsplit(scaled_combined_data, scaled_combined_data.shape[1])\n",
    "\n",
    "                # Reconstruct the dictionary with scaled data\n",
    "                scaled_dict = {key: scaled_data_parts[i].flatten() for i, key in enumerate(valid_keys)}\n",
    "\n",
    "                # Update y_token_dict with the scaled data\n",
    "                y_token_dict.update(scaled_dict)\n",
    "\n",
    "            # Handle any empty arrays (if necessary)\n",
    "            for key, value in y_token_dict_numerical.items():\n",
    "                if value.size == 0:\n",
    "                    # Optionally, you can handle empty arrays here, e.g., leave them as-is\n",
    "                    y_token_dict[key] = value\n",
    "            \n",
    "            \n",
    "        # sort dicts\n",
    "        x_token_dict = dict(sorted(x_token_dict.items()))\n",
    "        y_token_dict = dict(sorted(y_token_dict.items()))\n",
    "\n",
    "        return x_token_dict, y_token_dict, x_scaler, y_scaler, max_case_length\n",
    "    \n",
    "    \n",
    "    # TODO: implement training reporting for numerica featurey\n",
    "    # Prepare data and train the model\n",
    "    def train(self,\n",
    "            feature_type_dict: Dict[Feature_Type, List[str]],\n",
    "            train_token_dict_x: Dict[str, NDArray[np.float32]],\n",
    "            train_token_dict_y: Dict[str, NDArray[np.float32]],\n",
    "            word_dicts: Dict[str, Dict[str, int]],\n",
    "            max_case_length: int,\n",
    "            mask,\n",
    "            validation_split: float = 0.2  # Fraction of the training data to be used for validation\n",
    "            ) -> tf.keras.Model:\n",
    "\n",
    "        # Ensure that input columns and dictionaries are sorted\n",
    "        self.input_columns.sort()\n",
    "        self.target_columns = dict(sorted(self.target_columns.items()))\n",
    "        train_token_dict_x = dict(sorted(train_token_dict_x.items()))\n",
    "        train_token_dict_y = dict(sorted(train_token_dict_y.items()))\n",
    "        word_dicts = dict(sorted(word_dicts.items()))\n",
    "\n",
    "        batch_size = 12\n",
    "\n",
    "        model_wrapper = transformer.ModelWrapper(model_architecture=self.model_architecture, max_case_length=max_case_length, masking=True)\n",
    "        \n",
    "        # Define and compile the model\n",
    "        model = model_wrapper.get_model(\n",
    "            input_columns=self.input_columns,\n",
    "            target_columns=self.target_columns,\n",
    "            word_dicts=word_dicts,\n",
    "            max_case_length=max_case_length,\n",
    "            feature_type_dict=feature_type_dict,\n",
    "            temporal_features=self.temporal_features,\n",
    "            model_architecture=self.model_architecture\n",
    "        )\n",
    "\n",
    "        # Check the number of target columns to determine if it's a multi-task or single-task problem\n",
    "        if len(self.target_columns) > 1:\n",
    "            print(\"Using Multi-Task Learning Setup\")\n",
    "            # Multi-task scenario: use MultiTaskLoss\n",
    "            # Define the loss functions for each output and whether they are regression tasks\n",
    "            losses = []\n",
    "            is_regression = []\n",
    "\n",
    "            for feature, target in self.target_columns.items():\n",
    "                if feature_type_dict[Feature_Type.CATEGORICAL]:\n",
    "                    losses.append(tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False))\n",
    "                    is_regression.append(False)  # False for classification tasks\n",
    "                if feature_type_dict[Feature_Type.TIMESTAMP]:\n",
    "                    losses.append(tf.keras.losses.LogCosh())\n",
    "                    is_regression.append(True)  # True for regression tasks\n",
    "\n",
    "            # Create the MultiTaskLoss layer\n",
    "            multitask_loss_layer = transformer.MultiTaskLoss(is_regression=is_regression, reduction='sum')\n",
    "\n",
    "            # Convert losses to a tensor and apply the MultiTaskLoss\n",
    "            def combined_loss(y_true, y_pred):\n",
    "                loss_values = []\n",
    "                for i in range(len(losses)):\n",
    "                    loss_value = losses[i](y_true[i], y_pred[i])\n",
    "                    loss_values.append(loss_value)\n",
    "\n",
    "                loss_tensor = tf.stack(loss_values)\n",
    "                return multitask_loss_layer(loss_tensor)\n",
    "\n",
    "            # Compile the model with the combined loss\n",
    "            model.compile(\n",
    "                optimizer=tf.keras.optimizers.Adam(self.model_learning_rate),\n",
    "                loss=combined_loss,\n",
    "                metrics=[combined_loss]\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            print(\"Using Single-Task Learning Setup\")\n",
    "            # Single-task scenario: use standard loss\n",
    "            target_feature = list(self.target_columns.keys())[0]\n",
    "            # get feature_type\n",
    "            for feature_type, feature_lst in self.additional_columns.items():\n",
    "                if target_feature in feature_lst: break\n",
    "                \n",
    "            # if target is categorical\n",
    "            if feature_type is Feature_Type.CATEGORICAL:\n",
    "                # Classification task\n",
    "                model.compile(\n",
    "                    optimizer=tf.keras.optimizers.Adam(self.model_learning_rate),\n",
    "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "                )\n",
    "                \n",
    "            # if target is temporal\n",
    "            elif feature_type is Feature_Type.TIMESTAMP:\n",
    "                # Regression task\n",
    "                model.compile(\n",
    "                    optimizer=tf.keras.optimizers.Adam(self.model_learning_rate),\n",
    "                    loss=tf.keras.losses.LogCosh(),\n",
    "                    metrics=[tf.keras.metrics.MeanAbsoluteError()]\n",
    "                )\n",
    "\n",
    "        # Train-validation split\n",
    "        first_key = next(iter(train_token_dict_x.keys()))\n",
    "        n_samples = train_token_dict_x[first_key].shape[0]\n",
    "        indices = np.arange(n_samples)\n",
    "        train_indices, val_indices = train_test_split(indices, test_size=validation_split, random_state=42)\n",
    "\n",
    "        # Split the data\n",
    "        train_token_dict_x_split = {key: x_data[train_indices] for key, x_data in train_token_dict_x.items()}\n",
    "        val_token_dict_x_split = {key: x_data[val_indices] for key, x_data in train_token_dict_x.items()}\n",
    "        train_token_dict_y_split = {key: y_data[train_indices] for key, y_data in train_token_dict_y.items()}\n",
    "        val_token_dict_y_split = {key: y_data[val_indices] for key, y_data in train_token_dict_y.items()}\n",
    "\n",
    "        # Define callbacks\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True,\n",
    "            min_delta=0.001\n",
    "        )\n",
    "\n",
    "        model_specs_dir = os.path.join(\"datasets\", self.dataset_name, \"model_specs\")\n",
    "        os.makedirs(model_specs_dir, exist_ok=True)\n",
    "\n",
    "        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(model_specs_dir, \"best_model.h5\"),\n",
    "            save_weights_only=True,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\", save_best_only=True)\n",
    "\n",
    "        # Train the model\n",
    "        print(\"----------------------------------------------------\")\n",
    "        print(\"Training...\")\n",
    "        history = model.fit(\n",
    "            x=train_token_dict_x_split,\n",
    "            y=train_token_dict_y_split,\n",
    "            validation_data=(val_token_dict_x_split, val_token_dict_y_split),\n",
    "            epochs=self.model_epochs, batch_size=batch_size, shuffle=True,\n",
    "            callbacks=[early_stopping, model_checkpoint_callback]\n",
    "        )\n",
    "\n",
    "        # Plot training loss\n",
    "        self._plot_training_loss(history)\n",
    "        return model\n",
    "            \n",
    "            \n",
    "    # helper function for plotting the training loss\n",
    "    def _plot_training_loss(self, history):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        if 'val_loss' in history.history:\n",
    "            plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss Over Epochs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "    def evaluate(self, model, data_loader: LogsDataLoader, test_dfs: Dict[str, pd.DataFrame],\n",
    "                 max_case_length: int, x_scaler=None, y_scaler=None):\n",
    "        print(\"Evaluating...\")\n",
    "\n",
    "        # Prepare lists to store evaluation metrics\n",
    "        k, accuracies, fscores, precisions, recalls, weights = {}, {}, {}, {}, {}, {}\n",
    "        mae, mse, rmse, r2 = {}, {}, {}, {}\n",
    "        \n",
    "        for target_col in self.target_columns.keys():\n",
    "            for feature_type, feature_lst in self.additional_columns.items():\n",
    "                if target_col in feature_lst:\n",
    "                    k.update({target_col: []})\n",
    "                    weights.update({target_col: []})\n",
    "                    \n",
    "                    if feature_type is Feature_Type.CATEGORICAL:\n",
    "                        accuracies.update({target_col: []})\n",
    "                        fscores.update({target_col: []})\n",
    "                        precisions.update({target_col: []})\n",
    "                        recalls.update({target_col: []})\n",
    "                    elif feature_type is Feature_Type.TIMESTAMP:\n",
    "                        mae.update({target_col: []})\n",
    "                        mse.update({target_col: []})\n",
    "                        rmse.update({target_col: []})\n",
    "                        r2.update({target_col: []})\n",
    "\n",
    "        # Calculate total number of samples\n",
    "        total_samples = len(list(test_dfs.values())[0])\n",
    "\n",
    "        # Iterate over all prefixes (k)\n",
    "        for i in range(1, max_case_length + 1):\n",
    "            print(\"Prefix length: \" + str(i))\n",
    "            test_data_subsets = {}\n",
    "\n",
    "            for key, df in test_dfs.items():\n",
    "                if (Feature_Type.TIMESTAMP in self.additional_columns\n",
    "                        and key in self.additional_columns[Feature_Type.TIMESTAMP]):\n",
    "                    prefix_str = f\"{key}##Prefix Length\"\n",
    "                else:\n",
    "                    prefix_str = \"Prefix Length\"\n",
    "                filtered_df = df[df[prefix_str] == i]\n",
    "                test_data_subsets.update({key: filtered_df})\n",
    "\n",
    "\n",
    "            x_token_dict, y_token_dict, _, _, _ = self.prepare_data(data_loader=data_loader, dfs=test_data_subsets,\n",
    "                                                            x_scaler=x_scaler, y_scaler=y_scaler, train=False)\n",
    "\n",
    "            # sort dicts\n",
    "            x_token_dict = dict(sorted(x_token_dict.items()))\n",
    "            y_token_dict = dict(sorted(y_token_dict.items()))\n",
    "\n",
    "            if len(test_data_subsets[self.input_columns[0]]) > 0:\n",
    "\n",
    "                # Make predictions\n",
    "                predictions = model.predict(x_token_dict)\n",
    "                \n",
    "                # Handle multiple outputs for multitask learning\n",
    "                if len(self.target_columns) > 1:\n",
    "                    result_dict = dict(zip(self.target_columns.keys(), predictions))\n",
    "                else:\n",
    "                    result_dict = dict(zip(self.target_columns.keys(), [predictions]))\n",
    "\n",
    "                # Compute metrics\n",
    "                for feature, result in result_dict.items():\n",
    "                    for feature_type, feature_lst in self.additional_columns.items():\n",
    "                        if feature in feature_lst:\n",
    "                            if feature_type is Feature_Type.CATEGORICAL:\n",
    "                                result = np.argmax(result, axis=1)\n",
    "                                accuracy = metrics.accuracy_score(y_token_dict[f\"output_{feature}\"], result)\n",
    "                                precision, recall, fscore, _ = metrics.precision_recall_fscore_support(\n",
    "                                    y_token_dict[f\"output_{feature}\"], result, average=\"weighted\", zero_division=0)\n",
    "                                weight = len(test_data_subsets[feature]) / total_samples\n",
    "\n",
    "                                k[feature].append(i)\n",
    "                                accuracies[feature].append(accuracy)\n",
    "                                fscores[feature].append(fscore)\n",
    "                                precisions[feature].append(precision)\n",
    "                                recalls[feature].append(recall)\n",
    "                                weights[feature].append(weight)\n",
    "                            \n",
    "                            elif feature_type is Feature_Type.TIMESTAMP:\n",
    "                                y_true_unscaled = y_token_dict[f\"output_{feature}\"]\n",
    "                                y_true = y_scaler.inverse_transform( y_true_unscaled.reshape(-1, y_true_unscaled.shape[-1])\n",
    "                                                                    ).reshape(y_true_unscaled.shape)\n",
    "                                y_pred = y_scaler.inverse_transform( result )\n",
    "                                mae_value = metrics.mean_absolute_error(y_true, y_pred)\n",
    "                                mse_value = metrics.mean_squared_error(y_true, y_pred)\n",
    "                                rmse_value = np.sqrt(mse_value)\n",
    "                                r2_value = metrics.r2_score(y_true, y_pred)\n",
    "                                weight = len(test_data_subsets[feature]) / total_samples\n",
    "\n",
    "                                k[feature].append(i)\n",
    "                                mae[feature].append(mae_value)\n",
    "                                mse[feature].append(mse_value)\n",
    "                                rmse[feature].append(rmse_value)\n",
    "                                r2[feature].append(r2_value)\n",
    "                                weights[feature].append(weight)\n",
    "\n",
    "        for target_col in self.target_columns.keys():\n",
    "            for feature_type, feature_lst in self.additional_columns.items():\n",
    "                if target_col in feature_lst:\n",
    "                    if feature_type is Feature_Type.CATEGORICAL:\n",
    "                        # Compute weighted mean metrics over all k\n",
    "                        weighted_accuracy = np.average(accuracies[target_col], weights=weights[target_col])\n",
    "                        weighted_fscore = np.average(fscores[target_col], weights=weights[target_col])\n",
    "                        weighted_precision = np.average(precisions[target_col], weights=weights[target_col])\n",
    "                        weighted_recall = np.average(recalls[target_col], weights=weights[target_col])\n",
    "                        # Append weighted mean metrics to the lists\n",
    "                        weights[target_col].append(\"\")\n",
    "                        k[target_col].append(\"Weighted Mean\")\n",
    "                        accuracies[target_col].append(weighted_accuracy)\n",
    "                        fscores[target_col].append(weighted_fscore)\n",
    "                        precisions[target_col].append(weighted_precision)\n",
    "                        recalls[target_col].append(weighted_recall)\n",
    "                        # Create a DataFrame to display the results\n",
    "                        print(f\"Results for {target_col}\")\n",
    "                        results_df = pd.DataFrame({\n",
    "                            'k': k[target_col],\n",
    "                            'weight': weights[target_col],\n",
    "                            'accuracy': accuracies[target_col],\n",
    "                            'fscore': fscores[target_col],\n",
    "                            'precision': precisions[target_col],\n",
    "                            'recall': recalls[target_col]\n",
    "                        })\n",
    "                        # Display the results\n",
    "                        print(results_df)\n",
    "                    \n",
    "                    elif feature_type is Feature_Type.TIMESTAMP:\n",
    "                        # Compute weighted mean metrics over all k\n",
    "                        weighted_mae = np.average(mae[target_col], weights=weights[target_col])\n",
    "                        weighted_mse = np.average(mse[target_col], weights=weights[target_col])\n",
    "                        weighted_rmse = np.average(rmse[target_col], weights=weights[target_col])\n",
    "                        weighted_r2 = np.average(r2[target_col], weights=weights[target_col])\n",
    "                        # Append weighted mean metrics to the lists\n",
    "                        weights[target_col].append(\"\")\n",
    "                        k[target_col].append(\"Weighted Mean\")\n",
    "                        mae[target_col].append(weighted_mae)\n",
    "                        mse[target_col].append(weighted_mse)\n",
    "                        rmse[target_col].append(weighted_rmse)\n",
    "                        r2[target_col].append(weighted_r2)\n",
    "                        # Create a DataFrame to display the results\n",
    "                        print(f\"Results for {target_col}\")\n",
    "                        results_df = pd.DataFrame({\n",
    "                            'k': k[target_col],\n",
    "                            'weight': weights[target_col],\n",
    "                            'mae': mae[target_col],\n",
    "                            'mse': mse[target_col],\n",
    "                            'rmse': rmse[target_col],\n",
    "                            'r2': r2[target_col]\n",
    "                        })\n",
    "                        # Display the results\n",
    "                        print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper Functions ###\n",
    "\n",
    "# helper function to save xes file as csv\n",
    "def save_csv(args):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(**args)  # Examples: \"concept:name\", \"Resource\"\n",
    "    pipe.save_as_csv()\n",
    "    \n",
    "\n",
    "# helper function: do only preprocessing on data\n",
    "def preprocess(args):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(**args)  # Examples: \"concept:name\", \"Resource\"\n",
    "    # preprocess data\n",
    "    pipe.preprocess_log()\n",
    "\n",
    "\n",
    "# helper function\n",
    "def run(args):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(**args)  # Examples: \"concept:name\", \"Resource\"\n",
    "\n",
    "    # print parameters\n",
    "    print(pipe)\n",
    "\n",
    "    # preprocess data\n",
    "    pipe.preprocess_log()\n",
    "\n",
    "    # load data\n",
    "    data_loader, train_dfs, test_dfs, word_dicts, feature_type_dict, mask = pipe.load_data()\n",
    "\n",
    "    # prepare data\n",
    "    train_token_dict_x, train_token_dict_y, x_scaler, y_scaler, max_case_length = pipe.prepare_data(data_loader, train_dfs)\n",
    "\n",
    "    # train the model\n",
    "    model = pipe.train(\n",
    "                feature_type_dict = feature_type_dict,\n",
    "                train_token_dict_x = train_token_dict_x,\n",
    "                train_token_dict_y = train_token_dict_y,\n",
    "                word_dicts = word_dicts,\n",
    "                max_case_length = max_case_length,\n",
    "                mask = mask\n",
    "                )\n",
    "\n",
    "    # evaluate the model\n",
    "    pipe.evaluate(model=model, data_loader=data_loader, test_dfs=test_dfs, x_scaler=x_scaler,\n",
    "                  y_scaler=y_scaler, max_case_length=max_case_length)\n",
    "    print(\"\")\n",
    "    print(\"======================================\")\n",
    "    print(\"======================================\")\n",
    "    \n",
    "    \n",
    "# function for testing out code\n",
    "def test(args):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(**args)  # Examples: \"concept:name\", \"Resource\"\n",
    "\n",
    "    # print parameters\n",
    "    print(pipe)\n",
    "\n",
    "    # preprocess data\n",
    "    pipe.preprocess_log()\n",
    "\n",
    "    # load data\n",
    "    data_loader, train_dfs, test_dfs, word_dicts, feature_type_dict = pipe.load_data()\n",
    "\n",
    "    # prepare data\n",
    "    train_token_dict_x, train_token_dict_y, x_scaler, y_scaler, max_case_length = pipe.prepare_data(data_loader, train_dfs)\n",
    "\n",
    "    # # train the model\n",
    "    # model = pipe.train(\n",
    "    #             feature_type_dict = feature_type_dict,\n",
    "    #             train_token_dict_x = train_token_dict_x,\n",
    "    #             train_token_dict_y = train_token_dict_y,\n",
    "    #             word_dicts = word_dicts,\n",
    "    #             max_case_length = max_case_length\n",
    "    #             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Args & Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: 'helpdesk'\n",
      "filepath: 'helpdesk.csv'\n",
      "columns: '['Case ID', 'Activity', 'Complete Timestamp']'\n",
      "additional_columns: '{}'\n",
      "datetime_format: '%Y-%m-%d %H:%M:%S.%f'\n",
      "Model learning rate: '0.001'\n",
      "Model Epochs: '1'\n",
      "Number of Transformer Layers in Model: '1'\n",
      "Target columns: '{'Complete Timestamp': <Target.NEXT_FEATURE: 'next_feature'>}'\n",
      "Input columns: '['concept_name', 'Complete Timestamp']'\n",
      "\n",
      "All processed files for current spec found. Preprocessing skipped.\n",
      "Loading data from preprocessed train-test split...\n",
      "['time_timestamp', 'concept_name']\n",
      "Preparing data...\n",
      "Creating model...\n",
      "Masking active.\n",
      "Propagated Mask NumericalMaskGeneration Layer\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 1)\n",
      "Propagated Mask NumericalMaskGeneration Layer\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 1)\n",
      "Propagated Mask NumericalMaskGeneration Layer\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 1)\n",
      "Shape of tensor before concat: (None, 14, 36)\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 14, 36), dtype=tf.float32, name=None), name='token_embedding/concept_name_token-embeddings/embedding_lookup/Identity_1:0', description=\"created by layer 'token_embedding'\")\n",
      "Shape of tensor before concat: (None, 14, 1)\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 14, 1), dtype=tf.float32, name=None), name='numerical_mask_generation/multiply/mul:0', description=\"created by layer 'numerical_mask_generation'\")\n",
      "Shape of tensor before concat: (None, 14, 1)\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 14, 1), dtype=tf.float32, name=None), name='numerical_mask_generation_1/multiply/mul:0', description=\"created by layer 'numerical_mask_generation_1'\")\n",
      "Shape of tensor before concat: (None, 14, 1)\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 14, 1), dtype=tf.float32, name=None), name='numerical_mask_generation_2/multiply/mul:0', description=\"created by layer 'numerical_mask_generation_2'\")\n",
      "Shape of tensor after concat: (None, 14, 39)\n",
      "Propagated Mask PositionEmbeddingLayer\n",
      "Mask shape: (None, 14)\n",
      "Inputs shape: (None, 14, 39)\n",
      "last transformer\n",
      "(None, 14, 39)\n",
      "Mask for Transformer\n",
      "Mask shape: (None, 1, 14)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Propagated Mask Transformer\n",
      "Mask shape: (None, 14)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Mask for MaskedGlobalAveragePooling1D\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Propagated Mask MaskedGlobalAveragePooling1D\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Using Single-Task Learning Setup\n",
      "----------------------------------------------------\n",
      "Training...\n",
      "Propagated Mask NumericalMaskGeneration Layer\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 1)\n",
      "Propagated Mask NumericalMaskGeneration Layer\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 1)\n",
      "Propagated Mask NumericalMaskGeneration Layer\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 1)\n",
      "Propagated Mask PositionEmbeddingLayer\n",
      "Mask shape: (None, 14)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Mask for Transformer\n",
      "Mask shape: (None, 1, 14)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Propagated Mask Transformer\n",
      "Mask shape: (None, 14)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Mask for MaskedGlobalAveragePooling1D\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Propagated Mask MaskedGlobalAveragePooling1D\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Propagated Mask NumericalMaskGeneration Layer\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 1)\n",
      "Propagated Mask NumericalMaskGeneration Layer\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 1)\n",
      "Propagated Mask NumericalMaskGeneration Layer\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 1)\n",
      "Propagated Mask PositionEmbeddingLayer\n",
      "Mask shape: (None, 14)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Mask for Transformer\n",
      "Mask shape: (None, 1, 14)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Propagated Mask Transformer\n",
      "Mask shape: (None, 14)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Mask for MaskedGlobalAveragePooling1D\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Propagated Mask MaskedGlobalAveragePooling1D\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 39)\n",
      "895/896 [============================>.] - ETA: 0s - loss: 0.1462 - mean_absolute_error: 0.4243Propagated Mask NumericalMaskGeneration Layer\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 1)\n",
      "Propagated Mask NumericalMaskGeneration Layer\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 1)\n",
      "Propagated Mask NumericalMaskGeneration Layer\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 1)\n",
      "Propagated Mask PositionEmbeddingLayer\n",
      "Mask shape: (None, 14)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Mask for Transformer\n",
      "Mask shape: (None, 1, 14)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Propagated Mask Transformer\n",
      "Mask shape: (None, 14)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Mask for MaskedGlobalAveragePooling1D\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Propagated Mask MaskedGlobalAveragePooling1D\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 39)\n",
      "896/896 [==============================] - 51s 46ms/step - loss: 0.1462 - mean_absolute_error: 0.4243 - val_loss: 0.1127 - val_mean_absolute_error: 0.3707\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Prefix length: 1\n",
      "Preparing data...\n",
      "Propagated Mask NumericalMaskGeneration Layer\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 1)\n",
      "Propagated Mask NumericalMaskGeneration Layer\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 1)\n",
      "Propagated Mask NumericalMaskGeneration Layer\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 1)\n",
      "Propagated Mask PositionEmbeddingLayer\n",
      "Mask shape: (None, 14)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Mask for Transformer\n",
      "Mask shape: (None, 1, 14)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Propagated Mask Transformer\n",
      "Mask shape: (None, 14)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Mask for MaskedGlobalAveragePooling1D\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 39)\n",
      "Propagated Mask MaskedGlobalAveragePooling1D\n",
      "Mask shape: (None, 14, 1)\n",
      "Inputs shape: (None, 14, 39)\n",
      "29/29 [==============================] - 9s 46ms/step\n",
      "Prefix length: 2\n",
      "Preparing data...\n",
      "29/29 [==============================] - 2s 34ms/step\n",
      "Prefix length: 3\n",
      "Preparing data...\n",
      "28/28 [==============================] - 2s 34ms/step\n",
      "Prefix length: 4\n",
      "Preparing data...\n",
      "12/12 [==============================] - 2s 37ms/step\n",
      "Prefix length: 5\n",
      "Preparing data...\n",
      "5/5 [==============================] - 1s 19ms/step\n",
      "Prefix length: 6\n",
      "Preparing data...\n",
      "2/2 [==============================] - 1s 28ms/step\n",
      "Prefix length: 7\n",
      "Preparing data...\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prefix length: 8\n",
      "Preparing data...\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prefix length: 9\n",
      "Preparing data...\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prefix length: 10\n",
      "Preparing data...\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\sklearn\\metrics\\_regression.py:1187: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix length: 11\n",
      "Preparing data...\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Prefix length: 12\n",
      "Preparing data...\n",
      "Prefix length: 13\n",
      "Preparing data...\n",
      "Prefix length: 14\n",
      "Preparing data...\n",
      "Results for time_timestamp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\sklearn\\metrics\\_regression.py:1187: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                k    weight        mae         mse       rmse        r2\n",
      "0               1  0.274745   4.719369   44.227707   6.650392  0.065744\n",
      "1               2  0.274445   5.637692   80.344658   8.963518  0.367842\n",
      "2               3  0.262448   8.661096  137.408676  11.722145  0.500935\n",
      "3               4  0.111878   7.534636  102.415588  10.120059  0.541644\n",
      "4               5  0.046191   6.780898   76.517540   8.747431  0.638627\n",
      "5               6  0.017996   6.665586   81.654503   9.036288  0.679191\n",
      "6               7  0.007199   7.075613   72.769234   8.530488  0.621527\n",
      "7               8  0.003299   7.868285   97.407837   9.869541  0.668569\n",
      "8               9    0.0012   8.173287  102.418571  10.120206 -0.687639\n",
      "9              10    0.0003   6.091103   37.101532   6.091103       NaN\n",
      "10             11    0.0003  10.932175  119.512444  10.932175       NaN\n",
      "11  Weighted Mean             6.484878   87.741078   9.173701       NaN\n",
      "\n",
      "======================================\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "# args_helpdesk = {\n",
    "#         \"dataset_name\": \"helpdesk\",\n",
    "#         \"filepath\": \"helpdesk.csv\",\n",
    "#         \"columns\": [\"Case ID\", \"Activity\", \"Complete Timestamp\"],\n",
    "#         \"additional_columns\": {},\n",
    "#         \"datetime_format\": \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "#         \"model_learning_rate\": 0.001,\n",
    "#         \"model_epochs\": 3,\n",
    "#         \"model_num_layers\": 1,\n",
    "#         \"target_columns\": {\"Complete Timestamp\": Target.NEXT_FEATURE},\n",
    "#         \"input_columns\": [\"Activity\"],\n",
    "#         \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: False, Temporal_Feature.HOUR_OF_DAY: False},\n",
    "#         \"model_architecture\": Model_Architecture.COMMON_POSEMBS_TRANSF\n",
    "#         }\n",
    "\n",
    "args_helpdesk = {\n",
    "        \"dataset_name\": \"helpdesk\",\n",
    "        \"filepath\": \"helpdesk.csv\",\n",
    "        \"columns\": [\"Case ID\", \"Activity\", \"Complete Timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"Resource\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 1,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"Complete Timestamp\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"Activity\", \"Resource\", \"Complete Timestamp\"],\n",
    "        \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: True, Temporal_Feature.HOUR_OF_DAY: True},\n",
    "        \"model_architecture\": Model_Architecture.COMMON_POSEMBS_TRANSF\n",
    "        }\n",
    "\n",
    "# args_helpdesk = {\n",
    "#         \"dataset_name\": \"helpdesk\",\n",
    "#         \"filepath\": \"helpdesk.csv\",\n",
    "#         \"columns\": [\"Case ID\", \"Activity\", \"Complete Timestamp\"],\n",
    "#         \"additional_columns\": {Feature_Type.CATEGORICAL: [\"Resource\"]},\n",
    "#         \"datetime_format\": \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "#         \"model_learning_rate\": 0.001,\n",
    "#         \"model_epochs\": 1,\n",
    "#         \"model_num_layers\": 1,\n",
    "#         \"target_columns\": {\"Activity\": Target.NEXT_FEATURE},\n",
    "#         \"input_columns\": [\"Activity\", \"Resource\", \"Complete Timestamp\"],\n",
    "#         \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: True, Temporal_Feature.HOUR_OF_DAY: True}\n",
    "#         }\n",
    "\n",
    "args_sepsis = {\n",
    "        \"dataset_name\": \"sepsis\",\n",
    "        \"filepath\": \"sepsis.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:group\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S%z\",\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 1,\n",
    "        \"model_num_layers\": 10,\n",
    "        \"target_columns\": {\"concept:name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept:name\", \"org:group\"],\n",
    "        \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: True, Temporal_Feature.HOUR_OF_DAY: True}\n",
    "        }\n",
    "\n",
    "args_bpi_2012 = {\n",
    "        \"dataset_name\": \"bpi_2012\",\n",
    "        \"filepath\": \"BPI_Challenge_2012.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:resource\"]},\n",
    "        \"datetime_format\": None,\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 10,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"concept:name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept:name\", \"org:resource\"]\n",
    "        }\n",
    "\n",
    "args_bpi_2013 = {\n",
    "        \"dataset_name\": \"bpi_2013\",\n",
    "        \"filepath\": \"BPI_Challenge_2013_incidents.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:resource\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S%z\",\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 2,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"concept:name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept:name\", \"org:resource\"]\n",
    "        }\n",
    "\n",
    "args_bpi_2015_1 = {\n",
    "        \"dataset_name\": \"bpi_2015_1\",\n",
    "        \"filepath\": \"BPIC15_1.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:resource\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S%z\",\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 2,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"concept_name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept_name\", \"org_resource\"]\n",
    "        }\n",
    "\n",
    "\n",
    "run(args_helpdesk)\n",
    "# preprocess(args_helpdesk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change settings and run again\n",
    "\n",
    "# args_bpi_2012[\"additional_columns\"] = {}\n",
    "# args_bpi_2012[\"input_columns\"] = [\"concept:name\"]\n",
    "# run(args_bpi_2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run(additional_columns={Feature_Type.CATEGORICAL: [\"Resource\"]}, input_columns=[\"Activity\", \"Resource\"], target_columns=[\"Activity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run(additional_columns={Feature_Type.CATEGORICAL: [\"Resource\"]}, input_columns=[\"Activity\", \"Resource\"], target_columns=[\"Activity\", \"Resource\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
