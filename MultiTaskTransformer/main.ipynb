{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler\n",
    "from typing import List, Optional\n",
    "from numpy.typing import NDArray\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Tuple\n",
    "import pm4py\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from package import transformer\n",
    "from package.loader import LogsDataLoader\n",
    "from package.processor import LogsDataProcessor, masked_standard_scaler, masked_min_max_scaler\n",
    "from package.constants import Feature_Type, Target, Temporal_Feature, Model_Architecture\n",
    "\n",
    "\n",
    "# Initialize data dir, if not exists\n",
    "if not os.path.exists(\"datasets\"): \n",
    "    os.mkdir(\"datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pipeline:\n",
    "    \n",
    "    def __init__(self, dataset_name: str, filepath: str, columns: List[str], additional_columns: Optional[Dict[Feature_Type, List[str]]],\n",
    "                 datetime_format: str, model_learning_rate: float, model_epochs: int, model_num_layers: int,\n",
    "                 input_columns: List[str], target_columns: Dict[str, Target], temporal_features: Dict[Temporal_Feature, bool],\n",
    "                 model_architecture = Model_Architecture):\n",
    "        self.dataset_name: str = dataset_name\n",
    "        self.filepath: str = filepath\n",
    "        self.columns: List[str] = columns\n",
    "        self.additional_columns: Optional[Dict[Feature_Type, List[str]]] = additional_columns\n",
    "        self.datetime_format: str = datetime_format\n",
    "        self.model_learning_rate: float = model_learning_rate\n",
    "        self.model_epochs: int = model_epochs\n",
    "        self.model_num_layers: int = model_num_layers\n",
    "        \n",
    "        self.target_columns: Dict[str, Target] = target_columns\n",
    "        for target_col in target_columns.keys():\n",
    "            if target_col == columns[1]:\n",
    "                self.target_columns[\"concept_name\"] = self.target_columns.pop(target_col)\n",
    "                break\n",
    "                \n",
    "        self.input_columns: List[str] = input_columns\n",
    "        for idx, input_col in enumerate(input_columns):\n",
    "            if input_col == columns[1]:\n",
    "                self.input_columns[idx] = \"concept_name\"\n",
    "                break\n",
    "        self.temporal_features: Dict[Temporal_Feature, bool] = temporal_features\n",
    "        self.model_architecture = model_architecture\n",
    "        \n",
    "        # self._model_id: str = (\n",
    "        #     f\"{dataset_name}\"\n",
    "        #     f\"##{'#'.join(self.columns)}\"\n",
    "        #     f\"##{'#'.join(self.additional_columns)}\"\n",
    "        #     f\"##{'#'.join(self.task.value)}\"\n",
    "        #     f\"##{self.model_learning_rate}\"\n",
    "        #     f\"##{self.model_epochs}\"\n",
    "        #     f\"##{self.model_num_layers}\")\n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        return (\n",
    "            f\"dataset_name: '{self.dataset_name}'\\n\"\n",
    "            f\"filepath: '{self.filepath}'\\n\"\n",
    "            f\"columns: '{self.columns}'\\n\"\n",
    "            f\"additional_columns: '{self.additional_columns}'\\n\"\n",
    "            f\"datetime_format: '{self.datetime_format}'\\n\"\n",
    "            f\"Model learning rate: '{self.model_learning_rate}'\\n\"\n",
    "            f\"Model Epochs: '{self.model_epochs}'\\n\"\n",
    "            f\"Number of Transformer Layers in Model: '{self.model_num_layers}'\\n\"\n",
    "            f\"Target columns: '{self.target_columns}'\\n\"\n",
    "            f\"Input columns: '{self.input_columns}'\\n\")\n",
    "        \n",
    "    \n",
    "    def save_as_csv(self):\n",
    "        dir_path = os.path.join( \"datasets\", self.dataset_name )\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        file_path = os.path.join( dir_path, self.filepath )\n",
    "        \n",
    "        \n",
    "        if file_path.endswith('.xes'):\n",
    "            print(\"Converting xes to csv file\")\n",
    "            df = pm4py.convert_to_dataframe(pm4py.read_xes(file_path)).astype(str)\n",
    "            df.to_csv(file_path.replace(\".xes\", \".csv\"), index=False)\n",
    "        elif file_path.endswith('.csv'):\n",
    "            print(\"Input file already has csv format\")\n",
    "            \n",
    "    \n",
    "    # preprocess the event log and save the train-test split as csv files\n",
    "    def preprocess_log(self) -> List[int]:\n",
    "        data_processor = LogsDataProcessor(\n",
    "            name=self.dataset_name,\n",
    "            filepath=self.filepath,\n",
    "            columns=self.columns,\n",
    "            additional_columns=self.additional_columns,  # Add all additional columns here, first all categorical, then all numerical features\n",
    "            input_columns=self.input_columns,\n",
    "            target_columns=self.target_columns,\n",
    "            datetime_format=self.datetime_format,\n",
    "            temporal_features=self.temporal_features,\n",
    "            pool=4\n",
    "        )\n",
    "        \n",
    "        # TODO: sanitize columns\n",
    "        # self.columns = [data_processor.sanitize_filename(col) for col in self.columns]\n",
    "        \n",
    "        # self.additional_columns = {\n",
    "        #                         feature_type: [data_processor.sanitize_filename(feature) for feature in feature_lst] for feature_type,\n",
    "        #                         feature_lst in self.additional_columns.items()\n",
    "        #                         } if len(self.additional_columns)>0 else self.additional_columns\n",
    "        self.target_columns = {data_processor.sanitize_filename(feature, self.columns): target for feature, target in self.target_columns.items()}\n",
    "        self.input_columns = [data_processor.sanitize_filename(col, self.columns) for col in self.input_columns]\n",
    "        self.columns = [data_processor.sanitize_filename(col, self.columns) for col in self.columns]\n",
    "        \n",
    "        # Preprocess the event log and make train-test split\n",
    "        data_processor.process_logs()\n",
    "        # flatten self.additional_columns to get all used features\n",
    "        self.additional_columns = data_processor.additional_columns\n",
    "        self.used_features = [item for sublist in self.additional_columns.values() for item in sublist]\n",
    "        \n",
    "        \n",
    "        # TODO: Compute the number of unique classes in each categorical column\n",
    "        # train_df = pd.read_csv(os.path.join(\"datasets\", self.dataset_name, \"processed\", f\"{self._preprocessing_id}_train.csv\"))\n",
    "        # num_classes_list = data_processor._compute_num_classes(train_df)\n",
    "        \n",
    "        # return num_classes_list\n",
    "    \n",
    "    \n",
    "    # load the preprocessed train-test split from the csv files\n",
    "    def load_data(self) -> Tuple [ LogsDataLoader, Dict[str, pd.DataFrame], Dict[str, pd.DataFrame], Dict[str, Dict[str, int]], Dict[Feature_Type, List[str]] ]:\n",
    "        data_loader = LogsDataLoader(name=self.dataset_name, input_columns=self.input_columns,\n",
    "                                     target_columns=self.target_columns, temporal_features=self.temporal_features)\n",
    "        train_dfs, test_dfs, word_dicts, feature_type_dict, mask = data_loader.load_data()\n",
    "        word_dicts = dict(sorted(word_dicts.items()))\n",
    "        return data_loader, train_dfs, test_dfs, word_dicts, feature_type_dict, mask\n",
    "    \n",
    "    \n",
    "    def prepare_data( self, data_loader, dfs: Dict[str, pd.DataFrame], x_scaler=None, y_scaler=None,\n",
    "                     train: bool = True) -> Tuple[ Dict[str, NDArray[np.float32]], Dict[str, NDArray[np.float32]], Dict[str, NDArray[np.float32]], int ]:\n",
    "        print(\"Preparing data...\")\n",
    "        # initialize max_case_length\n",
    "        max_case_length = False\n",
    "        # initialize token dicts\n",
    "        x_token_dict, y_token_dict, x_token_dict_numerical, y_token_dict_numerical = {}, {}, {}, {}\n",
    "        \n",
    "        # loop over all feature dfs\n",
    "        for idx, (feature, feature_df) in enumerate(dfs.items()):\n",
    "            \n",
    "            # get current feature_type\n",
    "            for feature_type, feature_lst in self.additional_columns.items():\n",
    "                if feature in feature_lst: break\n",
    "            \n",
    "            if idx == 0 and train:\n",
    "                (x_tokens, y_tokens, max_case_length\n",
    "                ) = data_loader.prepare_data(feature=feature, df=feature_df, max_case_length=True)\n",
    "            else:\n",
    "                x_tokens, y_tokens = data_loader.prepare_data(feature=feature, df=feature_df)\n",
    "            \n",
    "            if feature_type is Feature_Type.TIMESTAMP or feature_type is Feature_Type.NUMERICAL:\n",
    "                x_token_dict_numerical.update(x_tokens)\n",
    "                y_token_dict_numerical.update(y_tokens)\n",
    "            else:\n",
    "                # update x_token_dict\n",
    "                x_token_dict.update(x_tokens)\n",
    "                y_token_dict.update(y_tokens)\n",
    "            \n",
    "        # TODO:\n",
    "        if len(x_token_dict_numerical) > 0  and len(list(x_token_dict_numerical.values())[0]) > 0:\n",
    "            # Concatenate all the feature arrays along the rows (axis=0)\n",
    "            combined_data = np.vstack(list(x_token_dict_numerical.values()))\n",
    "            if x_scaler is None:\n",
    "                # Initialize the StandardScaler\n",
    "                # x_scaler = StandardScaler()\n",
    "                # x_scaler = MinMaxScaler(feature_range=(0, 30))\n",
    "                # x_scaler = FunctionTransformer(masked_standard_scaler, kw_args={'padding_value': -1})\n",
    "                x_scaler = FunctionTransformer(masked_min_max_scaler, kw_args={'padding_value': -1})\n",
    "                # Fit the scaler on the combined data\n",
    "                x_scaler.fit(combined_data)\n",
    "            # Transform the combined data\n",
    "            scaled_combined_data = x_scaler.transform(combined_data)\n",
    "            # split the scaled combined data back into the original feature dict\n",
    "            split_indices = np.cumsum([value.shape[0] for value in x_token_dict_numerical.values()])[:-1]\n",
    "            scaled_data_parts = np.vsplit(scaled_combined_data, split_indices)\n",
    "            # Reconstruct the dictionary with scaled data\n",
    "            scaled_dict = {key: scaled_data_parts[i] for i, key in enumerate(x_token_dict_numerical.keys())}\n",
    "            # update x_token_dict\n",
    "            x_token_dict.update(scaled_dict)\n",
    "        if len(y_token_dict_numerical) > 0:\n",
    "            # Prepare list to store valid arrays (non-empty)\n",
    "            valid_arrays = []\n",
    "            valid_keys = []\n",
    "\n",
    "            # Check for empty arrays and prepare data for scaling\n",
    "            for key, value in y_token_dict_numerical.items():\n",
    "                if value.size > 0:  # Only consider non-empty arrays\n",
    "                    valid_arrays.append(value.reshape(-1, 1))  # Reshape to 2D\n",
    "                    valid_keys.append(key)\n",
    "\n",
    "            # If there are valid arrays to scale\n",
    "            if valid_arrays:\n",
    "                combined_data = np.hstack(valid_arrays)  # Horizontal stacking for features\n",
    "\n",
    "                if y_scaler is None:\n",
    "                    # Initialize the StandardScaler\n",
    "                    # y_scaler = StandardScaler()\n",
    "                    y_scaler = MinMaxScaler(feature_range=(0, 30))\n",
    "                    # Fit the scaler on the combined data\n",
    "                    y_scaler.fit(combined_data)\n",
    "\n",
    "                # Transform the combined data\n",
    "                scaled_combined_data = y_scaler.transform(combined_data)\n",
    "\n",
    "                # Split the scaled combined data back into individual features\n",
    "                scaled_data_parts = np.hsplit(scaled_combined_data, scaled_combined_data.shape[1])\n",
    "\n",
    "                # Reconstruct the dictionary with scaled data\n",
    "                scaled_dict = {key: scaled_data_parts[i].flatten() for i, key in enumerate(valid_keys)}\n",
    "\n",
    "                # Update y_token_dict with the scaled data\n",
    "                y_token_dict.update(scaled_dict)\n",
    "\n",
    "            # Handle any empty arrays (if necessary)\n",
    "            for key, value in y_token_dict_numerical.items():\n",
    "                if value.size == 0:\n",
    "                    # Optionally, you can handle empty arrays here, e.g., leave them as-is\n",
    "                    y_token_dict[key] = value\n",
    "            \n",
    "            \n",
    "        # sort dicts\n",
    "        x_token_dict = dict(sorted(x_token_dict.items()))\n",
    "        y_token_dict = dict(sorted(y_token_dict.items()))\n",
    "\n",
    "        return x_token_dict, y_token_dict, x_scaler, y_scaler, max_case_length\n",
    "    \n",
    "    \n",
    "    # Prepare data and train the model\n",
    "    def train(self,\n",
    "            feature_type_dict: Dict[Feature_Type, List[str]],\n",
    "            train_token_dict_x: Dict[str, NDArray[np.float32]],\n",
    "            train_token_dict_y: Dict[str, NDArray[np.float32]],\n",
    "            word_dicts: Dict[str, Dict[str, int]],\n",
    "            max_case_length: int,\n",
    "            mask,\n",
    "            validation_split: float = 0.2  # Fraction of the training data to be used for validation\n",
    "            ) -> tf.keras.Model:\n",
    "\n",
    "        # Ensure that input columns and dictionaries are sorted\n",
    "        self.input_columns.sort()\n",
    "        self.target_columns = dict(sorted(self.target_columns.items()))\n",
    "        train_token_dict_x = dict(sorted(train_token_dict_x.items()))\n",
    "        train_token_dict_y = dict(sorted(train_token_dict_y.items()))\n",
    "        word_dicts = dict(sorted(word_dicts.items()))\n",
    "\n",
    "        batch_size = 12\n",
    "\n",
    "        model_wrapper = transformer.ModelWrapper(model_architecture=self.model_architecture, max_case_length=max_case_length, masking=True)\n",
    "        \n",
    "        # Define and compile the model\n",
    "        model = model_wrapper.get_model(\n",
    "            input_columns=self.input_columns,\n",
    "            target_columns=self.target_columns,\n",
    "            word_dicts=word_dicts,\n",
    "            max_case_length=max_case_length,\n",
    "            feature_type_dict=feature_type_dict,\n",
    "            temporal_features=self.temporal_features,\n",
    "            model_architecture=self.model_architecture\n",
    "        )\n",
    "\n",
    "        # Check the number of target columns to determine if it's a multi-task or single-task problem\n",
    "        if len(self.target_columns) > 1:\n",
    "            print(\"Using Multi-Task Learning Setup\")\n",
    "            # Multi-task scenario: use MultiTaskLoss\n",
    "            \n",
    "            # Define if output is regression task tasks\n",
    "            is_regression = []\n",
    "            for feature in self.target_columns.keys():\n",
    "                if feature in feature_type_dict[Feature_Type.CATEGORICAL]:\n",
    "                    is_regression.append(False)  # False for classification tasks\n",
    "                elif feature in feature_type_dict[Feature_Type.TIMESTAMP]:\n",
    "                    is_regression.append(True)  # True for regression tasks\n",
    "\n",
    "\n",
    "            # Custom loss function that integrates MultiTaskLossLayer\n",
    "            def multi_task_loss_fn(is_regression):\n",
    "                multi_task_loss_layer = transformer.MultiTaskLossLayer(is_regression)\n",
    "                def loss_fn(y_true, y_pred):\n",
    "                    # Since y_true and y_pred are passed separately for each output, we wrap them in a list\n",
    "                    y_trues = [y_true]\n",
    "                    y_preds = [y_pred]\n",
    "                    # Call the multi-task loss layer for a single task\n",
    "                    return multi_task_loss_layer(y_trues, y_preds)\n",
    "                return loss_fn\n",
    "            \n",
    "            # Define the loss functions for each output\n",
    "            losses = {}\n",
    "            for output_key, reg in zip(train_token_dict_y.keys(), is_regression):\n",
    "                losses.update({output_key: multi_task_loss_fn([reg])})\n",
    "\n",
    "            # Compile the model with the combined loss\n",
    "            model.compile(\n",
    "                optimizer=tf.keras.optimizers.Adam(self.model_learning_rate),\n",
    "                loss=losses#,\n",
    "                #metrics=[combined_loss]\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            print(\"Using Single-Task Learning Setup\")\n",
    "            # Single-task scenario: use standard loss\n",
    "            target_feature = list(self.target_columns.keys())[0]\n",
    "            # get feature_type\n",
    "            for feature_type, feature_lst in self.additional_columns.items():\n",
    "                if target_feature in feature_lst: break\n",
    "                \n",
    "            # if target is categorical\n",
    "            if feature_type is Feature_Type.CATEGORICAL:\n",
    "                # Classification task\n",
    "                model.compile(\n",
    "                    optimizer=tf.keras.optimizers.Adam(self.model_learning_rate),\n",
    "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "                )\n",
    "                \n",
    "            # if target is temporal\n",
    "            elif feature_type is Feature_Type.TIMESTAMP:\n",
    "                # Regression task\n",
    "                model.compile(\n",
    "                    optimizer=tf.keras.optimizers.Adam(self.model_learning_rate),\n",
    "                    loss=tf.keras.losses.LogCosh(),\n",
    "                    metrics=[tf.keras.metrics.MeanAbsoluteError()]\n",
    "                )\n",
    "\n",
    "        # Train-validation split\n",
    "        first_key = next(iter(train_token_dict_x.keys()))\n",
    "        n_samples = train_token_dict_x[first_key].shape[0]\n",
    "        indices = np.arange(n_samples)\n",
    "        train_indices, val_indices = train_test_split(indices, test_size=validation_split, random_state=42)\n",
    "\n",
    "        # Split the data\n",
    "        train_token_dict_x_split = {key: x_data[train_indices] for key, x_data in train_token_dict_x.items()}\n",
    "        val_token_dict_x_split = {key: x_data[val_indices] for key, x_data in train_token_dict_x.items()}\n",
    "        train_token_dict_y_split = {key: y_data[train_indices] for key, y_data in train_token_dict_y.items()}\n",
    "        val_token_dict_y_split = {key: y_data[val_indices] for key, y_data in train_token_dict_y.items()}\n",
    "\n",
    "        # Define callbacks\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True,\n",
    "            min_delta=0.001\n",
    "        )\n",
    "\n",
    "        model_specs_dir = os.path.join(\"datasets\", self.dataset_name, \"model_specs\")\n",
    "        os.makedirs(model_specs_dir, exist_ok=True)\n",
    "\n",
    "        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(model_specs_dir, \"best_model.h5\"),\n",
    "            save_weights_only=True,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\", save_best_only=True)\n",
    "\n",
    "        # Train the model\n",
    "        print(\"----------------------------------------------------\")\n",
    "        print(\"Training...\")\n",
    "        history = model.fit(\n",
    "            x=train_token_dict_x_split,\n",
    "            y=train_token_dict_y_split,\n",
    "            validation_data=(val_token_dict_x_split, val_token_dict_y_split),\n",
    "            epochs=self.model_epochs, batch_size=batch_size, shuffle=True,\n",
    "            callbacks=[early_stopping, model_checkpoint_callback]\n",
    "        )\n",
    "\n",
    "        # Plot training loss\n",
    "        self._plot_training_loss(history)\n",
    "        return model\n",
    "            \n",
    "            \n",
    "    # helper function for plotting the training loss\n",
    "    def _plot_training_loss(self, history):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        if 'val_loss' in history.history:\n",
    "            plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss Over Epochs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "    def evaluate(self, model, data_loader: LogsDataLoader, test_dfs: Dict[str, pd.DataFrame],\n",
    "                 max_case_length: int, x_scaler=None, y_scaler=None):\n",
    "        print(\"Evaluating...\")\n",
    "        \n",
    "        #TODO: testing\n",
    "        # print(f\"Unscaled MAE training: {y_scaler.scale_ * 0.3030}\")\n",
    "\n",
    "        # Prepare lists to store evaluation metrics\n",
    "        k, accuracies, fscores, precisions, recalls, weights = {}, {}, {}, {}, {}, {}\n",
    "        mae, mse, rmse, r2 = {}, {}, {}, {}\n",
    "        \n",
    "        for target_col in self.target_columns.keys():\n",
    "            for feature_type, feature_lst in self.additional_columns.items():\n",
    "                if target_col in feature_lst:\n",
    "                    k.update({target_col: []})\n",
    "                    weights.update({target_col: []})\n",
    "                    \n",
    "                    if feature_type is Feature_Type.CATEGORICAL:\n",
    "                        accuracies.update({target_col: []})\n",
    "                        fscores.update({target_col: []})\n",
    "                        precisions.update({target_col: []})\n",
    "                        recalls.update({target_col: []})\n",
    "                    elif feature_type is Feature_Type.TIMESTAMP:\n",
    "                        mae.update({target_col: []})\n",
    "                        mse.update({target_col: []})\n",
    "                        rmse.update({target_col: []})\n",
    "                        r2.update({target_col: []})\n",
    "\n",
    "        # Calculate total number of samples\n",
    "        total_samples = len(list(test_dfs.values())[0])\n",
    "\n",
    "        # Iterate over all prefixes (k)\n",
    "        for i in range(1, max_case_length + 1):\n",
    "            print(\"Prefix length: \" + str(i))\n",
    "            test_data_subsets = {}\n",
    "\n",
    "            for key, df in test_dfs.items():\n",
    "                if (Feature_Type.TIMESTAMP in self.additional_columns\n",
    "                        and key in self.additional_columns[Feature_Type.TIMESTAMP]):\n",
    "                    prefix_str = f\"{key}##Prefix Length\"\n",
    "                else:\n",
    "                    prefix_str = \"Prefix Length\"\n",
    "                filtered_df = df[df[prefix_str] == i]\n",
    "                test_data_subsets.update({key: filtered_df})\n",
    "\n",
    "\n",
    "            x_token_dict, y_token_dict, _, _, _ = self.prepare_data(data_loader=data_loader, dfs=test_data_subsets,\n",
    "                                                            x_scaler=x_scaler, y_scaler=y_scaler, train=False)\n",
    "\n",
    "            # sort dicts\n",
    "            x_token_dict = dict(sorted(x_token_dict.items()))\n",
    "            y_token_dict = dict(sorted(y_token_dict.items()))\n",
    "\n",
    "            if len(test_data_subsets[self.input_columns[0]]) > 0:\n",
    "\n",
    "                # Make predictions\n",
    "                predictions = model.predict(x_token_dict)\n",
    "                \n",
    "                # Handle multiple outputs for multitask learning\n",
    "                if len(self.target_columns) > 1:\n",
    "                    result_dict = dict(zip(self.target_columns.keys(), predictions))\n",
    "                else:\n",
    "                    result_dict = dict(zip(self.target_columns.keys(), [predictions]))\n",
    "\n",
    "                # Compute metrics\n",
    "                for feature, result in result_dict.items():\n",
    "                    for feature_type, feature_lst in self.additional_columns.items():\n",
    "                        if feature in feature_lst:\n",
    "                            if feature_type is Feature_Type.CATEGORICAL:\n",
    "                                result = np.argmax(result, axis=1)\n",
    "                                accuracy = metrics.accuracy_score(y_token_dict[f\"output_{feature}\"], result)\n",
    "                                precision, recall, fscore, _ = metrics.precision_recall_fscore_support(\n",
    "                                    y_token_dict[f\"output_{feature}\"], result, average=\"weighted\", zero_division=0)\n",
    "                                weight = len(test_data_subsets[feature]) / total_samples\n",
    "\n",
    "                                k[feature].append(i)\n",
    "                                accuracies[feature].append(accuracy)\n",
    "                                fscores[feature].append(fscore)\n",
    "                                precisions[feature].append(precision)\n",
    "                                recalls[feature].append(recall)\n",
    "                                weights[feature].append(weight)\n",
    "                            \n",
    "                            elif feature_type is Feature_Type.TIMESTAMP:\n",
    "                                y_true_unscaled = y_token_dict[f\"output_{feature}\"]\n",
    "                                y_true = y_scaler.inverse_transform( y_true_unscaled.reshape(-1, y_true_unscaled.shape[-1])\n",
    "                                                                    ).reshape(y_true_unscaled.shape)\n",
    "                                y_pred = y_scaler.inverse_transform( result )\n",
    "                                mae_value = metrics.mean_absolute_error(y_true, y_pred)\n",
    "                                mse_value = metrics.mean_squared_error(y_true, y_pred)\n",
    "                                rmse_value = np.sqrt(mse_value)\n",
    "                                r2_value = metrics.r2_score(y_true, y_pred)\n",
    "                                weight = len(test_data_subsets[feature]) / total_samples\n",
    "\n",
    "                                k[feature].append(i)\n",
    "                                mae[feature].append(mae_value)\n",
    "                                mse[feature].append(mse_value)\n",
    "                                rmse[feature].append(rmse_value)\n",
    "                                r2[feature].append(r2_value)\n",
    "                                weights[feature].append(weight)\n",
    "\n",
    "        for target_col in self.target_columns.keys():\n",
    "            for feature_type, feature_lst in self.additional_columns.items():\n",
    "                if target_col in feature_lst:\n",
    "                    if feature_type is Feature_Type.CATEGORICAL:\n",
    "                        # Compute weighted mean metrics over all k\n",
    "                        weighted_accuracy = np.average(accuracies[target_col], weights=weights[target_col])\n",
    "                        weighted_fscore = np.average(fscores[target_col], weights=weights[target_col])\n",
    "                        weighted_precision = np.average(precisions[target_col], weights=weights[target_col])\n",
    "                        weighted_recall = np.average(recalls[target_col], weights=weights[target_col])\n",
    "                        # Append weighted mean metrics to the lists\n",
    "                        weights[target_col].append(\"\")\n",
    "                        k[target_col].append(\"Weighted Mean\")\n",
    "                        accuracies[target_col].append(weighted_accuracy)\n",
    "                        fscores[target_col].append(weighted_fscore)\n",
    "                        precisions[target_col].append(weighted_precision)\n",
    "                        recalls[target_col].append(weighted_recall)\n",
    "                        # Create a DataFrame to display the results\n",
    "                        print(f\"Results for {target_col}\")\n",
    "                        results_df = pd.DataFrame({\n",
    "                            'k': k[target_col],\n",
    "                            'weight': weights[target_col],\n",
    "                            'accuracy': accuracies[target_col],\n",
    "                            'fscore': fscores[target_col],\n",
    "                            'precision': precisions[target_col],\n",
    "                            'recall': recalls[target_col]\n",
    "                        })\n",
    "                        # Display the results\n",
    "                        print(results_df)\n",
    "                    \n",
    "                    elif feature_type is Feature_Type.TIMESTAMP:\n",
    "                        # Compute weighted mean metrics over all k\n",
    "                        weighted_mae = np.average(mae[target_col], weights=weights[target_col])\n",
    "                        weighted_mse = np.average(mse[target_col], weights=weights[target_col])\n",
    "                        weighted_rmse = np.average(rmse[target_col], weights=weights[target_col])\n",
    "                        weighted_r2 = np.average(r2[target_col], weights=weights[target_col])\n",
    "                        # Append weighted mean metrics to the lists\n",
    "                        weights[target_col].append(\"\")\n",
    "                        k[target_col].append(\"Weighted Mean\")\n",
    "                        mae[target_col].append(weighted_mae)\n",
    "                        mse[target_col].append(weighted_mse)\n",
    "                        rmse[target_col].append(weighted_rmse)\n",
    "                        r2[target_col].append(weighted_r2)\n",
    "                        # Create a DataFrame to display the results\n",
    "                        print(f\"Results for {target_col}\")\n",
    "                        results_df = pd.DataFrame({\n",
    "                            'k': k[target_col],\n",
    "                            'weight': weights[target_col],\n",
    "                            'mae': mae[target_col],\n",
    "                            'mse': mse[target_col],\n",
    "                            'rmse': rmse[target_col],\n",
    "                            'r2': r2[target_col]\n",
    "                        })\n",
    "                        # Display the results\n",
    "                        print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper Functions ###\n",
    "\n",
    "# helper function to save xes file as csv\n",
    "def save_csv(args):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(**args)  # Examples: \"concept:name\", \"Resource\"\n",
    "    pipe.save_as_csv()\n",
    "    \n",
    "\n",
    "# helper function: do only preprocessing on data\n",
    "def preprocess(args):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(**args)  # Examples: \"concept:name\", \"Resource\"\n",
    "    # preprocess data\n",
    "    pipe.preprocess_log()\n",
    "\n",
    "\n",
    "# helper function\n",
    "def run(args):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(**args)  # Examples: \"concept:name\", \"Resource\"\n",
    "\n",
    "    # print parameters\n",
    "    print(pipe)\n",
    "\n",
    "    # preprocess data\n",
    "    pipe.preprocess_log()\n",
    "\n",
    "    # load data\n",
    "    data_loader, train_dfs, test_dfs, word_dicts, feature_type_dict, mask = pipe.load_data()\n",
    "\n",
    "    # prepare data\n",
    "    train_token_dict_x, train_token_dict_y, x_scaler, y_scaler, max_case_length = pipe.prepare_data(data_loader, train_dfs)\n",
    "\n",
    "    # train the model\n",
    "    model = pipe.train(\n",
    "                feature_type_dict = feature_type_dict,\n",
    "                train_token_dict_x = train_token_dict_x,\n",
    "                train_token_dict_y = train_token_dict_y,\n",
    "                word_dicts = word_dicts,\n",
    "                max_case_length = max_case_length,\n",
    "                mask = mask\n",
    "                )\n",
    "\n",
    "    # evaluate the model\n",
    "    pipe.evaluate(model=model, data_loader=data_loader, test_dfs=test_dfs, x_scaler=x_scaler,\n",
    "                  y_scaler=y_scaler, max_case_length=max_case_length)\n",
    "    print(\"\")\n",
    "    print(\"======================================\")\n",
    "    print(\"======================================\")\n",
    "    \n",
    "    \n",
    "# function for testing out code\n",
    "def test(args):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(**args)  # Examples: \"concept:name\", \"Resource\"\n",
    "\n",
    "    # print parameters\n",
    "    print(pipe)\n",
    "\n",
    "    # preprocess data\n",
    "    pipe.preprocess_log()\n",
    "\n",
    "    # load data\n",
    "    data_loader, train_dfs, test_dfs, word_dicts, feature_type_dict = pipe.load_data()\n",
    "\n",
    "    # prepare data\n",
    "    train_token_dict_x, train_token_dict_y, x_scaler, y_scaler, max_case_length = pipe.prepare_data(data_loader, train_dfs)\n",
    "\n",
    "    # # train the model\n",
    "    # model = pipe.train(\n",
    "    #             feature_type_dict = feature_type_dict,\n",
    "    #             train_token_dict_x = train_token_dict_x,\n",
    "    #             train_token_dict_y = train_token_dict_y,\n",
    "    #             word_dicts = word_dicts,\n",
    "    #             max_case_length = max_case_length\n",
    "    #             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Args & Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: 'helpdesk'\n",
      "filepath: 'helpdesk.csv'\n",
      "columns: '['Case ID', 'Activity', 'Complete Timestamp']'\n",
      "additional_columns: '{<Feature_Type.CATEGORICAL: 'categorical'>: ['Resource']}'\n",
      "datetime_format: '%Y-%m-%d %H:%M:%S.%f'\n",
      "Model learning rate: '0.001'\n",
      "Model Epochs: '1'\n",
      "Number of Transformer Layers in Model: '1'\n",
      "Target columns: '{'Resource': <Target.NEXT_FEATURE: 'next_feature'>, 'concept_name': <Target.NEXT_FEATURE: 'next_feature'>}'\n",
      "Input columns: '['concept_name', 'Resource', 'Complete Timestamp']'\n",
      "\n",
      "All processed files for current spec found. Preprocessing skipped.\n",
      "Loading data from preprocessed train-test split...\n",
      "['concept_name', 'time_timestamp', 'Resource']\n",
      "Preparing data...\n",
      "Creating model...\n",
      "Masking active.\n",
      "Using Multi-Task Learning Setup\n",
      "----------------------------------------------------\n",
      "Training...\n",
      "896/896 [==============================] - 48s 38ms/step - loss: 2.4994 - output_Resource_loss: 1.6571 - output_concept_name_loss: 0.8423 - val_loss: 1.9382 - val_output_Resource_loss: 1.2948 - val_output_concept_name_loss: 0.6434\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABL30lEQVR4nO3dd3wUdR7/8fembRLSaEkokS5VESFKkYBn6AIBFESkWdAjoJxyh4goQTEC3onKT/T0JAeKFBXwOFoooQkKKB0jeFQhICWFlizZ+f3BL/tzSZlsSLIBXs/HYx8wM9+Z+czOx5g3MztrMQzDEAAAAAAgXx7uLgAAAAAAyjqCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwDcZIYMGaKaNWsWad0JEybIYrEUb0GAiZy+O3PmjLtLAYAiIzgBQDGxWCyFeiUlJbm7VLcYMmSIAgIC3F1GoRiGodmzZysqKkohISHy9/fXXXfdpYkTJ+rixYvuLi+XnGCS3yslJcXdJQLATc/L3QUAwK1i9uzZTtOzZs1SYmJirvkNGza8of188sknstvtRVr31Vdf1csvv3xD+7/VZWdn6/HHH9f8+fPVtm1bTZgwQf7+/tqwYYPi4uK0YMECrVq1SmFhYe4uNZcZM2bkGU5DQkJKvxgAuMUQnACgmDzxxBNO01u2bFFiYmKu+de7dOmS/P39C70fb2/vItUnSV5eXvLy4kd/QaZMmaL58+dr9OjRmjp1qmP+sGHD1LdvX8XExGjIkCFatmxZqdZVmD555JFHVKlSpVKqCABuL9yqBwClqH379mrSpIm2b9+uqKgo+fv765VXXpEkLV68WN26dVPVqlVltVpVp04dvfHGG8rOznbaxvWfcTp8+LAsFoveeecd/fOf/1SdOnVktVoVGRmprVu3Oq2b12ecLBaLRowYoUWLFqlJkyayWq1q3Lixli9fnqv+pKQktWjRQr6+vqpTp44+/vjjYv/c1IIFC9S8eXP5+fmpUqVKeuKJJ/Tbb785jUlJSdHQoUNVvXp1Wa1WValSRT179tThw4cdY7Zt26ZOnTqpUqVK8vPzU61atfTkk08WuO/Lly9r6tSpuvPOOxUfH59reffu3TV48GAtX75cW7ZskSQ9/PDDql27dp7ba9WqlVq0aOE07/PPP3ccX4UKFfTYY4/p2LFjTmMK6pMbkZSUJIvFonnz5umVV15ReHi4ypUrpx49euSqQSrcuZCkn3/+WX379lXlypXl5+en+vXra9y4cbnGpaamasiQIQoJCVFwcLCGDh2qS5cuOY1JTEzUAw88oJCQEAUEBKh+/frFcuwAcKP4Z0cAKGVnz55Vly5d9Nhjj+mJJ55w3PKVkJCggIAAvfjiiwoICNCaNWv02muvKT093enKR37mzJmjjIwMPfvss7JYLJoyZYp69+6t//3vf6ZXqTZu3KhvvvlGw4cPV2BgoN5//3316dNHR48eVcWKFSVJP/30kzp37qwqVaooLi5O2dnZmjhxoipXrnzjb8r/k5CQoKFDhyoyMlLx8fE6deqU3nvvPW3atEk//fST45azPn36aO/evRo5cqRq1qyp06dPKzExUUePHnVMd+zYUZUrV9bLL7+skJAQHT58WN98843p+3D+/Hm98MIL+V6ZGzRokGbOnKklS5aoZcuW6tevnwYNGqStW7cqMjLSMe7IkSPasmWL07mbNGmSxo8fr759++rpp5/W77//rg8++EBRUVFOxyfl3ycFOXfuXK55Xl5euW7VmzRpkiwWi8aMGaPTp09r2rRpio6O1o4dO+Tn5yep8Odi165datu2rby9vTVs2DDVrFlTv/76q/7zn/9o0qRJTvvt27evatWqpfj4eP3444/69NNPFRoaqsmTJ0uS9u7dq4cfflh33323Jk6cKKvVqoMHD2rTpk2mxw4AJc4AAJSI2NhY4/ofs+3atTMkGR999FGu8ZcuXco179lnnzX8/f2NK1euOOYNHjzYqFGjhmP60KFDhiSjYsWKxrlz5xzzFy9ebEgy/vOf/zjmvf7667lqkmT4+PgYBw8edMzbuXOnIcn44IMPHPO6d+9u+Pv7G7/99ptj3oEDBwwvL69c28zL4MGDjXLlyuW7PCsrywgNDTWaNGliXL582TF/yZIlhiTjtddeMwzDMM6fP29IMqZOnZrvthYuXGhIMrZu3Wpa1x9NmzbNkGQsXLgw3zHnzp0zJBm9e/c2DMMw0tLSDKvVarz00ktO46ZMmWJYLBbjyJEjhmEYxuHDhw1PT09j0qRJTuN2795teHl5Oc0vqE/yknNe83rVr1/fMW7t2rWGJKNatWpGenq6Y/78+fMNScZ7771nGEbhz4VhGEZUVJQRGBjoOM4cdrs9V31PPvmk05hevXoZFStWdEy/++67hiTj999/L9RxA0Bp4lY9AChlVqtVQ4cOzTU/51/6JSkjI0NnzpxR27ZtdenSJf3888+m2+3Xr5/Kly/vmG7btq0k6X//+5/putHR0apTp45j+u6771ZQUJBj3ezsbK1atUoxMTGqWrWqY1zdunXVpUsX0+0XxrZt23T69GkNHz5cvr6+jvndunVTgwYN9N///lfStffJx8dHSUlJOn/+fJ7byrkasmTJEtlstkLXkJGRIUkKDAzMd0zOsvT0dElSUFCQunTpovnz58swDMe4efPmqWXLlrrjjjskSd98843sdrv69u2rM2fOOF7h4eGqV6+e1q5d67Sf/PqkIF9//bUSExOdXjNnzsw1btCgQU7H+Mgjj6hKlSpaunSppMKfi99//13r16/Xk08+6TjOHHndvvncc885Tbdt21Znz551vJc5523x4sVFfgAKAJQUghMAlLJq1arJx8cn1/y9e/eqV69eCg4OVlBQkCpXrux4sERaWprpdq//xTUnROUXLgpaN2f9nHVPnz6ty5cvq27durnG5TWvKI4cOSJJql+/fq5lDRo0cCy3Wq2aPHmyli1bprCwMEVFRWnKlClOj9xu166d+vTpo7i4OFWqVEk9e/bUzJkzlZmZWWANOWEiJ0DlJa9w1a9fPx07dkybN2+WJP3666/avn27+vXr5xhz4MABGYahevXqqXLlyk6v/fv36/Tp0077ya9PChIVFaXo6GinV6tWrXKNq1evntO0xWJR3bp1HZ8RK+y5yAnWTZo0KVR9Zj3ar18/tWnTRk8//bTCwsL02GOPaf78+YQoAGUCwQkAStkfryzlSE1NVbt27bRz505NnDhR//nPf5SYmOj47EdhfnH09PTMc/4fr4KUxLruMGrUKP3yyy+Kj4+Xr6+vxo8fr4YNG+qnn36SdC0IfPXVV9q8ebNGjBih3377TU8++aSaN2+uCxcu5LvdnEfF79q1K98xOcsaNWrkmNe9e3f5+/tr/vz5kqT58+fLw8NDjz76qGOM3W6XxWLR8uXLc10VSkxM1Mcff+y0n7z65GZn1md+fn5av369Vq1apYEDB2rXrl3q16+fOnTokOshKQBQ2ghOAFAGJCUl6ezZs0pISNALL7yghx9+WNHR0U633rlTaGiofH19dfDgwVzL8ppXFDVq1JAkJScn51qWnJzsWJ6jTp06eumll7Ry5Urt2bNHWVlZ+vvf/+40pmXLlpo0aZK2bdumL774Qnv37tXcuXPzrSHnaW5z5szJ9xf1WbNmSbr2NL0c5cqV08MPP6wFCxbIbrdr3rx5atu2rdNtjXXq1JFhGKpVq1auq0LR0dFq2bKlyTtUfA4cOOA0bRiGDh486HhaY2HPRc7TBPfs2VNstXl4eOihhx7SP/7xD+3bt0+TJk3SmjVrct3KCACljeAEAGVAzr/E//EKT1ZWlj788EN3leTE09NT0dHRWrRokU6cOOGYf/DgwWL7PqMWLVooNDRUH330kdMtdcuWLdP+/fvVrVs3Sde+z+jKlStO69apU0eBgYGO9c6fP5/ratk999wjSQXerufv76/Ro0crOTk5z8dp//e//1VCQoI6deqUK+j069dPJ06c0KeffqqdO3c63aYnSb1795anp6fi4uJy1WYYhs6ePZtvXcVt1qxZTrcjfvXVVzp58qTj82qFPReVK1dWVFSUPvvsMx09etRpH0W5WpnXUwELc94AoDTwOHIAKANat26t8uXLa/DgwXr++edlsVg0e/bsMnWr3IQJE7Ry5Uq1adNGf/7zn5Wdna3p06erSZMm2rFjR6G2YbPZ9Oabb+aaX6FCBQ0fPlyTJ0/W0KFD1a5dO/Xv39/xCOyaNWvqL3/5iyTpl19+0UMPPaS+ffuqUaNG8vLy0sKFC3Xq1Ck99thjkqR///vf+vDDD9WrVy/VqVNHGRkZ+uSTTxQUFKSuXbsWWOPLL7+sn376SZMnT9bmzZvVp08f+fn5aePGjfr888/VsGFD/fvf/861XteuXRUYGKjRo0fL09NTffr0cVpep04dvfnmmxo7dqwOHz6smJgYBQYG6tChQ1q4cKGGDRum0aNHF+p9zM9XX32lgICAXPM7dOjg9DjzChUq6IEHHtDQoUN16tQpTZs2TXXr1tUzzzwj6dqXLBfmXEjS+++/rwceeED33nuvhg0bplq1aunw4cP673//W+i+yDFx4kStX79e3bp1U40aNXT69Gl9+OGHql69uh544IGivSkAUFzc8iw/ALgN5Pc48saNG+c5ftOmTUbLli0NPz8/o2rVqsbf/vY3Y8WKFYYkY+3atY5x+T2OPK/Hc0syXn/9dcd0fo8jj42NzbVujRo1jMGDBzvNW716tdGsWTPDx8fHqFOnjvHpp58aL730kuHr65vPu/D/DR48ON9HZtepU8cxbt68eUazZs0Mq9VqVKhQwRgwYIBx/Phxx/IzZ84YsbGxRoMGDYxy5coZwcHBxv3332/Mnz/fMebHH380+vfvb9xxxx2G1Wo1QkNDjYcfftjYtm2baZ2GYRjZ2dnGzJkzjTZt2hhBQUGGr6+v0bhxYyMuLs64cOFCvusNGDDAkGRER0fnO+brr782HnjgAaNcuXJGuXLljAYNGhixsbFGcnKyY0xBfZKXgh5H/sf+yXkc+ZdffmmMHTvWCA0NNfz8/Ixu3brlepy4YZifixx79uwxevXqZYSEhBi+vr5G/fr1jfHjx+eq7/rHjM+cOdOQZBw6dMgwjGv91bNnT6Nq1aqGj4+PUbVqVaN///7GL7/8Uuj3AgBKisUwytA/ZwIAbjoxMTHau3dvrs/NoOxJSkrSgw8+qAULFuiRRx5xdzkAcFPhM04AgEK7fPmy0/SBAwe0dOlStW/f3j0FAQBQSviMEwCg0GrXrq0hQ4aodu3aOnLkiGbMmCEfHx/97W9/c3dpAACUKIITAKDQOnfurC+//FIpKSmyWq1q1aqV3nrrrVxfqAoAwK2GzzgBAAAAgAk+4wQAAAAAJghOAAAAAGDitvuMk91u14kTJxQYGCiLxeLucgAAAAC4iWEYysjIUNWqVeXhUfA1pdsuOJ04cUIRERHuLgMAAABAGXHs2DFVr169wDG3XXAKDAyUdO3NCQoKcnM1yI/NZtPKlSvVsWNHeXt7u7sc3AToGbiKnoGr6Bm4ip4p+9LT0xUREeHICAW57YJTzu15QUFBBKcyzGazyd/fX0FBQfygQaHQM3AVPQNX0TNwFT1z8yjMR3h4OAQAAAAAmCA4AQAAAIAJghMAAAAAmLjtPuMEAACAsscwDF29elXZ2dnuLqXY2Gw2eXl56cqVK7fUcd1svL295enpecPbITgBAADArbKysnTy5EldunTJ3aUUK8MwFB4ermPHjvH9oW5ksVhUvXp1BQQE3NB2CE4AAABwG7vdrkOHDsnT01NVq1aVj4/PLRMy7Ha7Lly4oICAANMvV0XJMAxDv//+u44fP6569erd0JUnghMAAADcJisrS3a7XREREfL393d3OcXKbrcrKytLvr6+BCc3qly5sg4fPiybzXZDwYkzCAAAALcjWKCkFNcVTDoUAAAAAEwQnAAAAADABMEJAAAAKANq1qypadOmFXp8UlKSLBaLUlNTS6wm/H8EJwAAAMAFFoulwNeECROKtN2tW7dq2LBhhR7funVrnTx5UsHBwUXaX2ER0K7hqXoAAACAC06ePOn4+7x58/Taa68pOTnZMe+P3xeU88W+Pj4+ptutXLmyS3X4+PgoPDzcpXVQdG694hQfH6/IyEgFBgYqNDRUMTExTk2Xl4SEhFyp3tfXt5QqBgAAQEkyDEOXsq665WUYRqFqDA8Pd7yCg4NlsVgc0z///LMCAwO1bNkyRUZGKiwsTBs3btSvv/6qnj17KiwsTAEBAYqMjNSqVauctnv9rXoWi0WffvqpevXqJX9/f9WrV0/ffvutY/n1V4ISEhIUEhKiFStWqGHDhgoICFDnzp2dgt7Vq1f1/PPPKyQkRBUrVtSYMWM0ePBgxcTEFPmcnT9/XoMGDVL58uXl7++vLl266MCBA47lR44cUffu3VW+fHmVK1dOjRs31tKlSx3rDhgwQJUrV5afn5/q1aunmTNnFrmWkuTWK07r1q1TbGysIiMjdfXqVb3yyivq2LGj9u3bp3LlyuW7XlBQkFPAulW+JA0AAOB2d9mWrUavrXDLvvdN7CR/n+L59fjll1/WlClTFBoaqoiICP3222/q2rWrJk2aJKvVqlmzZql79+5KTk7WHXfcke924uLiNGXKFE2dOlUffPCBBgwYoCNHjqhChQp5jr906ZLeeecdzZ49Wx4eHnriiSc0evRoffHFF5KkyZMn64svvtDMmTPVsGFDvffee1q0aJEefPDBIh/rkCFDdODAAX377bcKCgrSmDFj1LVrV+3bt0/e3t6KjY1VVlaW1q9fr3Llymnfvn2Oq3Ljx4/Xvn37tGzZMlWqVEkHDx7U5cuXi1xLSXJrcFq+fLnTdEJCgkJDQ7V9+3ZFRUXlu15OqgcAAADKookTJ6pDhw5KT09XUFCQKlWqpKZNmzqWv/HGG1q4cKG+/fZbjRgxIt/tDBkyRP3795ckvfXWW3r//ff1ww8/qHPnznmOt9ls+uijj1SnTh1J0ogRIzRx4kTH8g8++EBjx45Vr169JEnTp093XP0pipzAtGnTJrVu3VqS9MUXXygiIkKLFi3So48+qqNHj6pPnz666667JEm1a9d2rH/06FE1a9ZMLVq0kHTtqltZVaY+45SWliZJ+SboHBcuXFCNGjVkt9t177336q233lLjxo3zHJuZmanMzEzHdHp6uqRrTWWz2YqpchS3nHPDOUJh0TNwFT0DV9EzJcNms8kwDNntdtntdlk9LdozoYNbarF6WmS3211aJ2f89X/ee++9jlv/DMNQenq64uLitHTpUp08eVJXr17V5cuXdeTIEad95rwXOZo0aeKY9vPzU1BQkFJSUhzvV84+c17+/v6qVauWY1lYWJhOnz4tu92utLQ0nTp1Si1atHAst1gsuvfee522V9AxXj9m79698vLyUmRkpGNZ+fLlVb9+fe3bt092u10jRoxQbGysVq5cqYceeki9e/fW3XffLUl69tln9eijj+rHH39Uhw4d1LNnT0cAKy52u12GYchms8nT09NpmSv/PZeZ4GS32zVq1Ci1adNGTZo0yXdc/fr19dlnn+nuu+9WWlqa3nnnHbVu3Vp79+5V9erVc42Pj49XXFxcrvkrV66Uv79/sR4Dil9iYqK7S8BNhp6Bq+gZuIqeKV5eXl4KDw/XhQsXlJWV5dZaMq64vs6VK1ccwUi6dqucdO1324yMjGvbzcjQX/7yFyUlJemNN95QrVq15Ofnp8GDB+vChQuOde12u65cueKYlq59JumP0zn7SE9Pd+wrIyNDHh4eunLliry8vJzG/7G+nPkXL17MtQ+73Z5rP3/c3x/3k9ey9PR0p1CSnZ2tzMxMpaenq2/fvmrdurVWrlyptWvX6u2339abb76pYcOGqU2bNtq1a5cSExO1du1adejQQU8//bTeeOONQr3/hZGVlaXLly9r/fr1unr1ap71F0aZCU6xsbHas2ePNm7cWOC4Vq1aqVWrVo7p1q1bq2HDhvr444/zfIPHjh2rF1980TGdnp6uiIgIdezYUUFBQcV3AChWNptNiYmJ6tChg7y9vd1dDm4C9AxcRc/AVfRMybhy5YqOHTumgICAm/KBX76+vrJYLI7fK3P+YT4wMFCBgYHKyMhQYGCgtm3bpqFDh+rxxx+XdO0OqmPHjsnHx8exroeHh3x9fZ1+R825ypQj58FoQUFBTvsKCgrKVUvO+tK1ZwQEBQUpLCxM+/fvV5cuXSRdCzi7d+9W06ZN8/3d+Pr9/FHz5s119epV7d+/33Gl6OzZszp48KDuuecex/hGjRqpUaNGGjVqlF555RV9/vnnGj16tKO2Z599Vs8++6w+/vhjjRkzRu+9955rJ6IAV65ckZ+fn6KionL1WH5hMS9lIjiNGDFCS5Ys0fr16/O8alQQb29vNWvWTAcPHsxzudVqldVqzXM9fuiVfZwnuIqegavoGbiKnile2dnZslgs8vDwyHU142aQU3Nef+Y8wMxisahevXpauHChevToIYvFovHjx8tutzuOPcf103m9Lznz/riv66fzq2/kyJF6++23Va9ePTVo0EAffPCBzp8/X+D7nzN/7969CgwMdKq1adOm6tmzpyP0BAYG6uWXX1a1atXUq1cveXh4aNSoUerSpYvuvPNOnT9/XklJSWrYsKE8PDz02muvqXnz5mrcuLEyMzO1dOlSx7LiknMu8vpv15X/lt0anAzD0MiRI7Vw4UIlJSWpVq1aLm8jJyV37dq1BCoEAAAAbtw//vEPPfnkk2rdurUqVaqkMWPGuHS1o7iMGTNGKSkpGjRokDw9PTVs2DB16tQp12d/8nL9w9s8PT119epVzZw5Uy+88IIefvhhZWVlKSoqSkuXLnWEkuzsbMXGxur48eMKCgpS586d9e6770q69l1UY8eO1eHDh+Xn56e2bdtq7ty5xX/gxcBiFPaB9SVg+PDhmjNnjhYvXqz69es75gcHBzsuKw4aNEjVqlVTfHy8pGtPKGnZsqXq1q2r1NRUTZ06VYsWLdL27dvVqFEj032mp6crODhYaWlp3KpXhtlsNi1dulRdu3blX/VQKPQMXEXPwFX0TMm4cuWKDh06pFq1at2Ut+oVJOdzQ0FBQWX2aprdblfDhg3Vt2/fYv1cUVlSUI+5kg3cesVpxowZkqT27ds7zZ85c6aGDBki6dojCv/YaOfPn9czzzyjlJQUlS9fXs2bN9d3331XqNAEAAAA3M6OHDmilStXql27dsrMzNT06dN16NAhx2evkD+336pnJikpyWn63XffdVzaAwAAAFB4Hh4eSkhI0OjRo2UYhpo0aaJVq1apYcOG7i6tzCsTD4cAAAAAUPIiIiK0adMmd5dxUyqbN1sCAAAAQBlCcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAwA3at2+vUaNGOaZr1qypadOmFbiOxWLRokWLbnjfxbWd2wnBCQAAAHBB9+7d1blz5zyXbdiwQRaLRbt27XJ5u1u3btWwYcNutDwnEyZM0D333JNr/smTJ9WlS5di3df1EhISFBISUqL7KE0EJwAAAMAFTz31lBITE3X8+PFcy2bOnKkWLVro7rvvdnm7lStXlr+/f3GUaCo8PFxWq7VU9nWrIDgBAACg7DAMKeuie16GUagSH374YVWuXFkJCQlO8y9cuKAFCxboqaee0tmzZ/X444+rUaNGCggI0F133aUvv/yywO1ef6vegQMHFBUVJV9fXzVq1EiJiYm51hkzZozuvPNO+fv7q3bt2ho/frxsNpuka1d84uLitHPnTlksFlksFkfN19+qt3v3bv3pT3+Sn5+fKlasqGHDhunChQuO5UOGDFFMTIzeeecdValSRRUrVlRsbKxjX0Vx9OhR9ezZUwEBAQoKClLfvn116tQpx/KdO3fqwQcfVGBgoIKCgtS8eXNt27ZNknTkyBF1795d5cuXV7ly5dS4cWMtXbq0yLUUhleJbh0AAABwhe2S9FZV9+z7lROSTznTYV5eXho0aJASEhI0btw4WSwWSdKCBQuUnZ2t/v3768KFC2revLliY2NVpUoVLVu2TAMHDlSdOnV03333me7Dbrerd+/eCgsL0/fff6+0tDSnz0PlCAwMVEJCgqpWrardu3frmWeeUWBgoP72t7+pX79+2rNnj5YvX65Vq1ZJkoKDg3Nt4+LFi+rUqZNatWqlrVu36vTp03r66ac1YsQIp3C4du1aValSRWvXrtXBgwfVr18/3XPPPXrmmWdMjyev48sJTevWrdPVq1cVGxurfv36KSkpSZI0YMAANWvWTDNmzJCnp6d27Nghb29vSVJsbKyysrK0fv16lStXTvv27VNAQIDLdbiC4AQAAAC46Mknn9TUqVO1bt06tW/fXtK12/T69Omj4OBgBQcH66WXXlJ6erqCgoI0cuRIrVixQvPnzy9UcFq1apV+/vlnrVixQlWrXguSb731Vq7PJb366quOv9esWVOjR4/W3Llz9be//U1+fn4KCAiQl5eXwsPD893XnDlzdOXKFc2aNUvlyl0LjtOnT1f37t01efJkhYWFSZLKly+v6dOny9PTUw0aNFC3bt20evXqIgWn1atXa/fu3Tp06JAiIiIkSbNmzVLjxo21detWRUZG6ujRo/rrX/+qBg0aSJLq1avnWP/o0aPq06eP7rrrLklS7dq1Xa7BVQQnAAAAlB3e/teu/Lhr34XUoEEDtW7dWp999pnat2+vgwcPasOGDZo4caIkKTs7W5MmTdLcuXOVkpKirKwsZWZmFvozTPv371dERIQjNElSq1atco2bN2+e3n//ff3666+6cOGCrl69qqCgoEIfR86+mjZt6ghNktSmTRvZ7XYlJyc7glPjxo3l6enpGFOlShXt3r3bpX39cZ8RERGO0CRJjRo1UkhIiPbv36/IyEi9+OKLevrppzV79mxFR0fr0UcfVZ06dSRJzz//vP785z9r5cqVio6OVp8+fYr0uTJX8BknAAAAlB0Wy7Xb5dzx+n+33BXWU089pa+//loZGRmaOXOm6tSpo3bt2kmSpk6dqvfff18vvPCCVq9erR07dqhTp07Kysoqtrdq8+bNGjBggLp27aolS5bop59+0rhx44p1H3+Uc5tcDovFIrvdXiL7kq49EXDv3r3q1q2b1qxZo0aNGmnhwoWSpKefflr/+9//NHDgQO3evVstWrTQBx98UGK1SAQnAAAAoEj69u0rDw8PzZkzR7NmzdKTTz7p+LzTpk2b1KNHD/Xr109NmzZV7dq19csvvxR62w0bNtSxY8d08uRJx7wtW7Y4jfnuu+9Uo0YNjRs3Ti1atFC9evV05MgRpzE+Pj7Kzs423dfOnTt18eJFx7xNmzbJw8ND9evXL3TNrsg5vmPHjjnm7du3T6mpqWrUqJFj3p133qm//OUvWrlypXr37q2ZM2c6lkVEROi5557TN998o5deekmffPJJidSag+AEAAAAFEFAQID69eunsWPH6uTJkxoyZIhjWb169bRq1Sp9//332r9/v5599lmnJ8aZiY6O1p133qnBgwdr586d2rBhg8aNG+c0pl69ejp69Kjmzp2rX3/9Ve+//77jikyOmjVr6tChQ9qxY4fOnDmjzMzMXPsaMGCAfH19NXjwYO3Zs0dr167VyJEjNXDgQMdtekWVnZ2tHTt2OL3279+v6Oho3XXXXRowYIB+/PFH/fDDDxo0aJDatWunFi1a6PLlyxoxYoSSkpJ05MgRbdq0SVu3blXDhg0lSaNGjdKKFSt06NAh/fjjj1q7dq1jWUkhOAEAAABF9NRTT+n8+fPq1KmT0+eRXn31VTVr1kyPPPKI/vSnPyk8PFwxMTGF3q6Hh4cWLlyoy5cv67777tPTTz+tSZMmOY3p0aOH/vKXv2jEiBG655579N1332n8+PFOY/r06aPOnTvrwQcfVOXKlfN8JLq/v79WrFihc+fOKTIyUo888ogeeughTZ8+3bU3Iw8XLlxQs2bNnF7du3eXxWLR4sWLVb58eUVFRSk6Olq1a9fWvHnzJEmenp46e/asBg0apDvvvFN9+/ZVly5dFBcXJ+laIIuNjVXDhg3VuXNn3Xnnnfrwww9vuN6CWAyjkA+sv0Wkp6crODhYaWlpLn9wDqXHZrNp6dKl6tq1a677aYG80DNwFT0DV9EzJePKlSs6dOiQatWqJV9fX3eXU6zsdrvjqXoeHlyvcJeCesyVbMAZBAAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAgNvdZs8rQykqrt4iOAEAAMBtcp5QeOnSJTdXgltVVlaWpGuPOL8RXsVRDAAAAFAUnp6eCgkJ0enTpyVd+04hi8Xi5qqKh91uV1ZWlq5cucLjyN3Ebrfr999/l7+/v7y8biz6EJwAAADgVuHh4ZLkCE+3CsMwdPnyZfn5+d0yYfBm5OHhoTvuuOOGzwHBCQAAAG5lsVhUpUoVhYaGymazubucYmOz2bR+/XpFRUXxpclu5OPjUyxX/AhOAAAAKBM8PT1v+HMoZYmnp6euXr0qX19fgtMtgJstAQAAAMAEwQkAAAAATBCcAAAAAMAEwQkAAAAATBCcAAAAAMAEwQkAAAAATBCcAAAAAMAEwQkAAAAATBCcAAAAAMAEwQkAAAAATBCcAAAAAMAEwQkAAAAATBCcAAAAAMAEwQkAAAAATBCcAAAAAMAEwQkAAAAATBCcAAAAAMAEwQkAAAAATBCcAAAAAMAEwQkAAAAATBCcAAAAAMAEwQkAAAAATBCcAAAAAMAEwQkAAAAATBCcAAAAAMAEwQkAAAAATBCcAAAAAMAEwQkAAAAATBCcAAAAAMAEwQkAAAAATBCcAAAAAMAEwQkAAAAATBCcAAAAAMAEwQkAAAAATBCcAAAAAMCEW4NTfHy8IiMjFRgYqNDQUMXExCg5ObnQ68+dO1cWi0UxMTElVyQAAACA255bg9O6desUGxurLVu2KDExUTabTR07dtTFixdN1z18+LBGjx6ttm3blkKlAAAAAG5nXu7c+fLly52mExISFBoaqu3btysqKirf9bKzszVgwADFxcVpw4YNSk1NLeFKAQAAANzO3BqcrpeWliZJqlChQoHjJk6cqNDQUD311FPasGFDgWMzMzOVmZnpmE5PT5ck2Ww22Wy2G6wYJSXn3HCOUFj0DFxFz8BV9AxcRc+Ufa6cG4thGEYJ1lJodrtdPXr0UGpqqjZu3JjvuI0bN+qxxx7Tjh07VKlSJQ0ZMkSpqalatGhRnuMnTJiguLi4XPPnzJkjf3//4iofAAAAwE3m0qVLevzxx5WWlqagoKACx5aZK06xsbHas2dPgaEpIyNDAwcO1CeffKJKlSoVartjx47Viy++6JhOT09XRESEOnbsaPrmwH1sNpsSExPVoUMHeXt7u7sc3AToGbiKnoGr6Bm4ip4p+3LuRiuMMhGcRowYoSVLlmj9+vWqXr16vuN+/fVXHT58WN27d3fMs9vtkiQvLy8lJyerTp06TutYrVZZrdZc2/L29qaBbwKcJ7iKnoGr6Bm4ip6Bq+iZssuV8+LW4GQYhkaOHKmFCxcqKSlJtWrVKnB8gwYNtHv3bqd5r776qjIyMvTee+8pIiKiJMsFAAAAcJtya3CKjY3VnDlztHjxYgUGBiolJUWSFBwcLD8/P0nSoEGDVK1aNcXHx8vX11dNmjRx2kZISIgk5ZoPAAAAAMXFrcFpxowZkqT27ds7zZ85c6aGDBkiSTp69Kg8PNz6dVMAAAAAbnNuv1XPTFJSUoHLExISiqcYAAAAAMgHl3IAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMuDU4xcfHKzIyUoGBgQoNDVVMTIySk5MLXOebb75RixYtFBISonLlyumee+7R7NmzS6liAAAAALcjtwandevWKTY2Vlu2bFFiYqJsNps6duyoixcv5rtOhQoVNG7cOG3evFm7du3S0KFDNXToUK1YsaIUKwcAAABwO/Fy586XL1/uNJ2QkKDQ0FBt375dUVFRea7Tvn17p+kXXnhB//73v7Vx40Z16tSppEoFAAAAcBtza3C6XlpamqRrV5UKwzAMrVmzRsnJyZo8eXKeYzIzM5WZmemYTk9PlyTZbDbZbLYbrBglJefccI5QWPQMXEXPwFX0DFxFz5R9rpwbi2EYRgnWUmh2u109evRQamqqNm7cWODYtLQ0VatWTZmZmfL09NSHH36oJ598Ms+xEyZMUFxcXK75c+bMkb+/f7HUDgAAAODmc+nSJT3++ONKS0tTUFBQgWPLTHD685//rGXLlmnjxo2qXr16gWPtdrv+97//6cKFC1q9erXeeOMNLVq0KNdtfFLeV5wiIiJ05swZ0zcH7mOz2ZSYmKgOHTrI29vb3eXgJkDPwFX0DFxFz8BV9EzZl56erkqVKhUqOJWJW/VGjBihJUuWaP369aahSZI8PDxUt25dSdI999yj/fv3Kz4+Ps/gZLVaZbVac8339vamgW8CnCe4ip6Bq+gZuIqegavombLLlfPi1uBkGIZGjhyphQsXKikpSbVq1SrSdux2u9NVJQAAAAAoTm4NTrGxsZozZ44WL16swMBApaSkSJKCg4Pl5+cnSRo0aJCqVaum+Ph4Sde++6lFixaqU6eOMjMztXTpUs2ePVszZsxw23EAAAAAuLW5NTjlhJ3rb7GbOXOmhgwZIkk6evSoPDz+/9dNXbx4UcOHD9fx48fl5+enBg0a6PPPP1e/fv1Kq2wAAAAAtxm336pnJikpyWn6zTff1JtvvllCFQEAAABAbh7mQwAAAADg9kZwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATRQpOx44d0/Hjxx3TP/zwg0aNGqV//vOfxVYYAAAAAJQVRQpOjz/+uNauXStJSklJUYcOHfTDDz9o3LhxmjhxYrEWCAAAAADuVqTgtGfPHt13332SpPnz56tJkyb67rvv9MUXXyghIaE46wMAAAAAtytScLLZbLJarZKkVatWqUePHpKkBg0a6OTJk8VXHQAAAACUAUUKTo0bN9ZHH32kDRs2KDExUZ07d5YknThxQhUrVizWAgEAAADA3YoUnCZPnqyPP/5Y7du3V//+/dW0aVNJ0rfffuu4hQ8AAAAAbhVeRVmpffv2OnPmjNLT01W+fHnH/GHDhsnf37/YigMAAACAsqBIV5wuX76szMxMR2g6cuSIpk2bpuTkZIWGhhZrgQAAAADgbkUKTj179tSsWbMkSampqbr//vv197//XTExMZoxY0axFggAAAAA7lak4PTjjz+qbdu2kqSvvvpKYWFhOnLkiGbNmqX333+/WAsEAAAAAHcrUnC6dOmSAgMDJUkrV65U79695eHhoZYtW+rIkSPFWiAAAAAAuFuRglPdunW1aNEiHTt2TCtWrFDHjh0lSadPn1ZQUFCxFggAAAAA7lak4PTaa69p9OjRqlmzpu677z61atVK0rWrT82aNSvWAgEAAADA3Yr0OPJHHnlEDzzwgE6ePOn4DidJeuihh9SrV69iKw4AAAAAyoIiBSdJCg8PV3h4uI4fPy5Jql69Ol9+CwAAAOCWVKRb9ex2uyZOnKjg4GDVqFFDNWrUUEhIiN544w3Z7fbirhEAAAAA3KpIV5zGjRunf/3rX3r77bfVpk0bSdLGjRs1YcIEXblyRZMmTSrWIgEAAADAnYoUnP7973/r008/VY8ePRzz7r77blWrVk3Dhw8nOAEAAAC4pRTpVr1z586pQYMGueY3aNBA586du+GiAAAAAKAsKVJwatq0qaZPn55r/vTp03X33XffcFEAAAAAUJYU6Va9KVOmqFu3blq1apXjO5w2b96sY8eOaenSpcVaIAAAAAC4W5GuOLVr106//PKLevXqpdTUVKWmpqp3797au3evZs+eXdw1AgAAAIBbFSk4SVLVqlU1adIkff311/r666/15ptv6vz58/rXv/5V6G3Ex8crMjJSgYGBCg0NVUxMjJKTkwtc55NPPlHbtm1Vvnx5lS9fXtHR0frhhx+KehgAAAAAYKrIwak4rFu3TrGxsdqyZYsSExNls9nUsWNHXbx4Md91kpKS1L9/f61du1abN29WRESEOnbsqN9++60UKwcAAABwOynSZ5yKy/Lly52mExISFBoaqu3btysqKirPdb744gun6U8//VRff/21Vq9erUGDBpVYrQAAAABuX24NTtdLS0uTJFWoUKHQ61y6dEk2my3fdTIzM5WZmemYTk9PlyTZbDbZbLYbqBYlKefccI5QWPQMXEXPwFX0DFxFz5R9rpwbi2EYRmEH9+7du8DlqampWrdunbKzswtdQA673a4ePXooNTVVGzduLPR6w4cP14oVK7R37175+vrmWj5hwgTFxcXlmj9nzhz5+/u7XCcAAACAW8OlS5f0+OOPKy0tTUFBQQWOdSk4DR06tFDjZs6cWdhNOvz5z3/WsmXLtHHjRlWvXr1Q67z99tuaMmWKkpKS8v3+qLyuOEVEROjMmTOmbw7cx2azKTExUR06dJC3t7e7y8FNgJ6Bq+gZuIqegavombIvPT1dlSpVKlRwculWvaIEosIYMWKElixZovXr1xc6NL3zzjt6++23tWrVqgK/dNdqtcpqteaa7+3tTQPfBDhPcBU9A1fRM3AVPQNX0TNllyvnxa2fcTIMQyNHjtTChQuVlJSkWrVqFWq9KVOmaNKkSVqxYoVatGhRwlUCAAAAuN25NTjFxsZqzpw5Wrx4sQIDA5WSkiJJCg4Olp+fnyRp0KBBqlatmuLj4yVJkydP1muvvaY5c+aoZs2ajnUCAgIUEBDgngMBAAAAcEtz6/c4zZgxQ2lpaWrfvr2qVKnieM2bN88x5ujRozp58qTTOllZWXrkkUec1nnnnXfccQgAAAAAbgNuv1XPTFJSktP04cOHS6YYAAAAAMiHW684AQAAAMDNgOAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACbcGpzi4+MVGRmpwMBAhYaGKiYmRsnJyQWus3fvXvXp00c1a9aUxWLRtGnTSqdYAAAAALcttwandevWKTY2Vlu2bFFiYqJsNps6duyoixcv5rvOpUuXVLt2bb399tsKDw8vxWoBAAAA3K683Lnz5cuXO00nJCQoNDRU27dvV1RUVJ7rREZGKjIyUpL08ssvl3iNAAAAAODW4HS9tLQ0SVKFChWKbZuZmZnKzMx0TKenp0uSbDabbDZbse0HxSvn3HCOUFj0DFxFz8BV9AxcRc+Ufa6cG4thGEYJ1lJodrtdPXr0UGpqqjZu3FiodWrWrKlRo0Zp1KhR+Y6ZMGGC4uLics2fM2eO/P39i1ouAAAAgJvcpUuX9PjjjystLU1BQUEFji0zV5xiY2O1Z8+eQoemwho7dqxefPFFx3R6eroiIiLUsWNH0zcH7mOz2ZSYmKgOHTrI29vb3eXgJkDPwFX0DFxFz8BV9EzZl3M3WmGUieA0YsQILVmyROvXr1f16tWLddtWq1VWqzXXfG9vbxr4JsB5gqvoGbiKnoGr6Bm4ip4pu1w5L24NToZhaOTIkVq4cKGSkpJUq1Ytd5YDAAAAAHlya3CKjY3VnDlztHjxYgUGBiolJUWSFBwcLD8/P0nSoEGDVK1aNcXHx0uSsrKytG/fPsfff/vtN+3YsUMBAQGqW7euew4EAAAAwC3Nrd/jNGPGDKWlpal9+/aqUqWK4zVv3jzHmKNHj+rkyZOO6RMnTqhZs2Zq1qyZTp48qXfeeUfNmjXT008/7Y5DAAAAAHAbcPutemaSkpKcpmvWrFmo9QAAAACguLj1ihMAAAAA3AwITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgwq3BKT4+XpGRkQoMDFRoaKhiYmKUnJxsut6CBQvUoEED+fr66q677tLSpUtLoVoAAAAAtyu3Bqd169YpNjZWW7ZsUWJiomw2mzp27KiLFy/mu853332n/v3766mnntJPP/2kmJgYxcTEaM+ePaVYOQAAAIDbiZc7d758+XKn6YSEBIWGhmr79u2KiorKc5333ntPnTt31l//+ldJ0htvvKHExERNnz5dH330Ua7xmZmZyszMdEynp6dLkmw2m2w2W3EdCopZzrnhHKGw6Bm4ip6Bq+gZuIqeKftcOTduDU7XS0tLkyRVqFAh3zGbN2/Wiy++6DSvU6dOWrRoUZ7j4+PjFRcXl2v+ypUr5e/vX/RiUSoSExPdXQJuMvQMXEXPwFX0DFxFz5Rdly5dKvTYMhOc7Ha7Ro0apTZt2qhJkyb5jktJSVFYWJjTvLCwMKWkpOQ5fuzYsU5BKz09XREREerYsaOCgoKKp3gUO5vNpsTERHXo0EHe3t7uLgc3AXoGrqJn4Cp6Bq6iZ8q+nLvRCqPMBKfY2Fjt2bNHGzduLNbtWq1WWa3WXPO9vb1p4JsA5wmuomfgKnoGrqJn4Cp6puxy5byUieA0YsQILVmyROvXr1f16tULHBseHq5Tp045zTt16pTCw8NLskQAAAAAtzG3PlXPMAyNGDFCCxcu1Jo1a1SrVi3TdVq1aqXVq1c7zUtMTFSrVq1KqkwAAAAAtzm3XnGKjY3VnDlztHjxYgUGBjo+pxQcHCw/Pz9J0qBBg1StWjXFx8dLkl544QW1a9dOf//739WtWzfNnTtX27Zt0z//+U+3HQcAAACAW5tbrzjNmDFDaWlpat++vapUqeJ4zZs3zzHm6NGjOnnypGO6devWmjNnjv75z3+qadOm+uqrr7Ro0aICHygBAAAAADfCrVecDMMwHZOUlJRr3qOPPqpHH320BCoCAAAAgNzcesUJAAAAAG4GBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATXu4uoLQZhiFJSk9Pd3MlKIjNZtOlS5eUnp4ub29vd5eDmwA9A1fRM3AVPQNX0TNlX04myMkIBbntglNGRoYkKSIiws2VAAAAACgLMjIyFBwcXOAYi1GYeHULsdvtOnHihAIDA2WxWNxdDvKRnp6uiIgIHTt2TEFBQe4uBzcBegauomfgKnoGrqJnyj7DMJSRkaGqVavKw6PgTzHddlecPDw8VL16dXeXgUIKCgriBw1cQs/AVfQMXEXPwFX0TNlmdqUpBw+HAAAAAAATBCcAAAAAMEFwQplktVr1+uuvy2q1ursU3CToGbiKnoGr6Bm4ip65tdx2D4cAAAAAAFdxxQkAAAAATBCcAAAAAMAEwQkAAAAATBCcAAAAAMAEwQluce7cOQ0YMEBBQUEKCQnRU089pQsXLhS4zpUrVxQbG6uKFSsqICBAffr00alTp/Ice/bsWVWvXl0Wi0WpqaklcAQobSXRMzt37lT//v0VEREhPz8/NWzYUO+9915JHwpKyP/5P/9HNWvWlK+vr+6//3798MMPBY5fsGCBGjRoIF9fX911111aunSp03LDMPTaa6+pSpUq8vPzU3R0tA4cOFCSh4BSVpw9Y7PZNGbMGN11110qV66cqlatqkGDBunEiRMlfRgoRcX9c+aPnnvuOVksFk2bNq2Yq0axMQA36Ny5s9G0aVNjy5YtxoYNG4y6desa/fv3L3Cd5557zoiIiDBWr15tbNu2zWjZsqXRunXrPMf27NnT6NKliyHJOH/+fAkcAUpbSfTMv/71L+P55583kpKSjF9//dWYPXu24efnZ3zwwQclfTgoZnPnzjV8fHyMzz77zNi7d6/xzDPPGCEhIcapU6fyHL9p0ybD09PTmDJlirFv3z7j1VdfNby9vY3du3c7xrz99ttGcHCwsWjRImPnzp1Gjx49jFq1ahmXL18urcNCCSrunklNTTWio6ONefPmGT///LOxefNm47777jOaN29emoeFElQSP2dyfPPNN0bTpk2NqlWrGu+++24JHwmKiuCEUrdv3z5DkrF161bHvGXLlhkWi8X47bff8lwnNTXV8Pb2NhYsWOCYt3//fkOSsXnzZqexH374odGuXTtj9erVBKdbREn3zB8NHz7cePDBB4uveJSK++67z4iNjXVMZ2dnG1WrVjXi4+PzHN+3b1+jW7duTvPuv/9+49lnnzUMwzDsdrsRHh5uTJ061bE8NTXVsFqtxpdfflkCR4DSVtw9k5cffvjBkGQcOXKkeIqGW5VUzxw/ftyoVq2asWfPHqNGjRoEpzKMW/VQ6jZv3qyQkBC1aNHCMS86OloeHh76/vvv81xn+/btstlsio6Odsxr0KCB7rjjDm3evNkxb9++fZo4caJmzZolDw/a+1ZRkj1zvbS0NFWoUKH4ikeJy8rK0vbt253OtYeHh6Kjo/M915s3b3YaL0mdOnVyjD906JBSUlKcxgQHB+v+++8vsH9wcyiJnslLWlqaLBaLQkJCiqVuuE9J9YzdbtfAgQP117/+VY0bNy6Z4lFs+M0SpS4lJUWhoaFO87y8vFShQgWlpKTku46Pj0+u//mEhYU51snMzFT//v01depU3XHHHSVSO9yjpHrmet99953mzZunYcOGFUvdKB1nzpxRdna2wsLCnOYXdK5TUlIKHJ/zpyvbxM2jJHrmeleuXNGYMWPUv39/BQUFFU/hcJuS6pnJkyfLy8tLzz//fPEXjWJHcEKxefnll2WxWAp8/fzzzyW2/7Fjx6phw4Z64oknSmwfKF7u7pk/2rNnj3r27KnXX39dHTt2LJV9Arg12Ww29e3bV4ZhaMaMGe4uB2XU9u3b9d577ykhIUEWi8Xd5aAQvNxdAG4dL730koYMGVLgmNq1ays8PFynT592mn/16lWdO3dO4eHhea4XHh6urKwspaamOl1BOHXqlGOdNWvWaPfu3frqq68kXXsiliRVqlRJ48aNU1xcXBGPDCXF3T2TY9++fXrooYc0bNgwvfrqq0U6FrhPpUqV5Onpmespm3md6xzh4eEFjs/589SpU6pSpYrTmHvuuacYq4c7lETP5MgJTUeOHNGaNWu42nSLKIme2bBhg06fPu10l0x2drZeeuklTZs2TYcPHy7eg8AN44oTik3lypXVoEGDAl8+Pj5q1aqVUlNTtX37dse6a9askd1u1/3335/ntps3by5vb2+tXr3aMS85OVlHjx5Vq1atJElff/21du7cqR07dmjHjh369NNPJV37wRQbG1uCR46icnfPSNLevXv14IMPavDgwZo0aVLJHSxKjI+Pj5o3b+50ru12u1avXu10rv+oVatWTuMlKTEx0TG+Vq1aCg8PdxqTnp6u77//Pt9t4uZREj0j/f/QdODAAa1atUoVK1YsmQNAqSuJnhk4cKB27drl+L1lx44dqlq1qv76179qxYoVJXcwKDp3P50Ct6fOnTsbzZo1M77//ntj48aNRr169ZweLX38+HGjfv36xvfff++Y99xzzxl33HGHsWbNGmPbtm1Gq1atjFatWuW7j7Vr1/JUvVtISfTM7t27jcqVKxtPPPGEcfLkScfr9OnTpXpsuHFz5841rFarkZCQYOzbt88YNmyYERISYqSkpBiGYRgDBw40Xn75Zcf4TZs2GV5eXsY777xj7N+/33j99dfzfBx5SEiIsXjxYmPXrl1Gz549eRz5LaS4eyYrK8vo0aOHUb16dWPHjh1OP1MyMzPdcowoXiXxc+Z6PFWvbCM4wS3Onj1r9O/f3wgICDCCgoKMoUOHGhkZGY7lhw4dMiQZa9eudcy7fPmyMXz4cKN8+fKGv7+/0atXL+PkyZP57oPgdGspiZ55/fXXDUm5XjVq1CjFI0Nx+eCDD4w77rjD8PHxMe677z5jy5YtjmXt2rUzBg8e7DR+/vz5xp133mn4+PgYjRs3Nv773/86Lbfb7cb48eONsLAww2q1Gg899JCRnJxcGoeCUlKcPZPzMyiv1x9/LuHmVtw/Z65HcCrbLIbx/z4IAgAAAADIE59xAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgAAAAATBCcAAAAAMEFwAgDABRaLRYsWLXJ3GQCAUkZwAgDcNIYMGSKLxZLr1blzZ3eXBgC4xXm5uwAAAFzRuXNnzZw502me1Wp1UzUAgNsFV5wAADcVq9Wq8PBwp1f58uUlXbuNbsaMGerSpYv8/PxUu3ZtffXVV07r7969W3/605/k5+enihUratiwYbpw4YLTmM8++0yNGzeW1WpVlSpVNGLECKflZ86cUa9eveTv76969erp22+/LdmDBgC4HcEJAHBLGT9+vPr06aOdO3dqwIABeuyxx7R//35J0sWLF9WpUyeVL19eW7du1YIFC7Rq1SqnYDRjxgzFxsZq2LBh2r17t7799lvVrVvXaR9xcXHq27evdu3apa5du2rAgAE6d+5cqR4nAKB0WQzDMNxdBAAAhTFkyBB9/vnn8vX1dZr/yiuv6JVXXpHFYtFzzz2nGTNmOJa1bNlS9957rz788EN98sknGjNmjI4dO6Zy5cpJkpYuXaru3bvrxIkTCgsLU7Vq1TR06FC9+eabedZgsVj06quv6o033pB0LYwFBARo2bJlfNYKAG5hfMYJAHBTefDBB52CkSRVqFDB8fdWrVo5LWvVqpV27NghSdq/f7+aNm3qCE2S1KZNG9ntdiUnJ8tisejEiRN66KGHCqzh7rvvdvy9XLlyCgoK0unTp4t6SACAmwDBCQBwUylXrlyuW+eKi5+fX6HGeXt7O01bLBbZ7faSKAkAUEbwGScAwC1ly5YtuaYbNmwoSWrYsKF27typixcvOpZv2rRJHh4eql+/vgIDA1WzZk2tXr26VGsGAJR9XHECANxUMjMzlZKS4jTPy8tLlSpVkiQtWLBALVq00AMPPKAvvvhCP/zwg/71r39JkgYMGKDXX39dgwcP1oQJE/T7779r5MiRGjhwoMLCwiRJEyZM0HPPPafQ0FB16dJFGRkZ2rRpk0aOHFm6BwoAKFMITgCAm8ry5ctVpUoVp3n169fXzz//LOnaE+/mzp2r4cOHq0qVKvryyy/VqFEjSZK/v79WrFihF154QZGRkfL391efPn30j3/8w7GtwYMH68qVK3r33Xc1evRoVapUSY888kjpHSAAoEziqXoAgFuGxWLRwoULFRMT4+5SAAC3GD7jBAAAAAAmCE4AAAAAYILPOAEAbhncfQ4AKClccQIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADDxfwHo6ZqgO3f2vAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Prefix length: 1\n",
      "Preparing data...\n",
      "29/29 [==============================] - 2s 18ms/step\n",
      "Prefix length: 2\n",
      "Preparing data...\n",
      "29/29 [==============================] - 1s 20ms/step\n",
      "Prefix length: 3\n",
      "Preparing data...\n",
      "28/28 [==============================] - 1s 18ms/step\n",
      "Prefix length: 4\n",
      "Preparing data...\n",
      "12/12 [==============================] - 0s 20ms/step\n",
      "Prefix length: 5\n",
      "Preparing data...\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "Prefix length: 6\n",
      "Preparing data...\n",
      "2/2 [==============================] - 0s 21ms/step\n",
      "Prefix length: 7\n",
      "Preparing data...\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "Prefix length: 8\n",
      "Preparing data...\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Prefix length: 9\n",
      "Preparing data...\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "Prefix length: 10\n",
      "Preparing data...\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "Prefix length: 11\n",
      "Preparing data...\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "Prefix length: 12\n",
      "Preparing data...\n",
      "Prefix length: 13\n",
      "Preparing data...\n",
      "Prefix length: 14\n",
      "Preparing data...\n",
      "Results for Resource\n",
      "                k    weight  accuracy    fscore  precision    recall\n",
      "0               1  0.274745  0.351528  0.227336   0.267733  0.351528\n",
      "1               2  0.274445  0.657923  0.628535   0.645157  0.657923\n",
      "2               3  0.262448  0.754286  0.739837   0.764168  0.754286\n",
      "3               4  0.111878  0.683646  0.639861   0.687420  0.683646\n",
      "4               5  0.046191  0.727273  0.711000   0.725817  0.727273\n",
      "5               6  0.017996  0.650000  0.631352   0.642787  0.650000\n",
      "6               7  0.007199  0.666667  0.638889   0.645833  0.666667\n",
      "7               8  0.003299  0.272727  0.348485   0.484848  0.272727\n",
      "8               9    0.0012  0.250000  0.375000   0.750000  0.250000\n",
      "9              10    0.0003  0.000000  0.000000   0.000000  0.000000\n",
      "10             11    0.0003  1.000000  1.000000   1.000000  1.000000\n",
      "11  Weighted Mean            0.603179  0.551415   0.580622  0.603179\n",
      "Results for concept_name\n",
      "                k    weight  accuracy    fscore  precision    recall\n",
      "0               1  0.274745  0.832969  0.765892   0.720205  0.832969\n",
      "1               2  0.274445  0.695082  0.591543   0.517204  0.695082\n",
      "2               3  0.262448  0.816000  0.795010   0.775640  0.816000\n",
      "3               4  0.111878  0.836461  0.798753   0.765656  0.836461\n",
      "4               5  0.046191  0.857143  0.821683   0.807125  0.857143\n",
      "5               6  0.017996  0.816667  0.769277   0.793846  0.816667\n",
      "6               7  0.007199  0.833333  0.784105   0.794643  0.833333\n",
      "7               8  0.003299  0.727273  0.700826   0.753247  0.727273\n",
      "8               9    0.0012  0.500000  0.600000   0.750000  0.500000\n",
      "9              10    0.0003  1.000000  1.000000   1.000000  1.000000\n",
      "10             11    0.0003  1.000000  1.000000   1.000000  1.000000\n",
      "11  Weighted Mean            0.791242  0.731857   0.690315  0.791242\n",
      "\n",
      "======================================\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "# args_helpdesk = {\n",
    "#         \"dataset_name\": \"helpdesk\",\n",
    "#         \"filepath\": \"helpdesk.csv\",\n",
    "#         \"columns\": [\"Case ID\", \"Activity\", \"Complete Timestamp\"],\n",
    "#         \"additional_columns\": {},\n",
    "#         \"datetime_format\": \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "#         \"model_learning_rate\": 0.001,\n",
    "#         \"model_epochs\": 3,\n",
    "#         \"model_num_layers\": 1,\n",
    "#         \"target_columns\": {\"Complete Timestamp\": Target.NEXT_FEATURE},\n",
    "#         \"input_columns\": [\"Activity\"],\n",
    "#         \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: False, Temporal_Feature.HOUR_OF_DAY: False},\n",
    "#         \"model_architecture\": Model_Architecture.COMMON_POSEMBS_TRANSF\n",
    "#         }\n",
    "\n",
    "args_helpdesk = {\n",
    "        \"dataset_name\": \"helpdesk\",\n",
    "        \"filepath\": \"helpdesk.csv\",\n",
    "        \"columns\": [\"Case ID\", \"Activity\", \"Complete Timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"Resource\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 1,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"Activity\": Target.NEXT_FEATURE, \"Resource\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"Activity\", \"Resource\", \"Complete Timestamp\"],\n",
    "        \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: True, Temporal_Feature.HOUR_OF_DAY: True},\n",
    "        \"model_architecture\": Model_Architecture.COMMON_POSEMBS_TRANSF\n",
    "        }\n",
    "\n",
    "# args_helpdesk = {\n",
    "#         \"dataset_name\": \"helpdesk\",\n",
    "#         \"filepath\": \"helpdesk.csv\",\n",
    "#         \"columns\": [\"Case ID\", \"Activity\", \"Complete Timestamp\"],\n",
    "#         \"additional_columns\": {Feature_Type.CATEGORICAL: [\"Resource\"]},\n",
    "#         \"datetime_format\": \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "#         \"model_learning_rate\": 0.001,\n",
    "#         \"model_epochs\": 1,\n",
    "#         \"model_num_layers\": 1,\n",
    "#         \"target_columns\": {\"Activity\": Target.NEXT_FEATURE},\n",
    "#         \"input_columns\": [\"Activity\", \"Resource\", \"Complete Timestamp\"],\n",
    "#         \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: True, Temporal_Feature.HOUR_OF_DAY: True}\n",
    "#         }\n",
    "\n",
    "args_sepsis = {\n",
    "        \"dataset_name\": \"sepsis\",\n",
    "        \"filepath\": \"sepsis.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:group\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S%z\",\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 1,\n",
    "        \"model_num_layers\": 10,\n",
    "        \"target_columns\": {\"concept:name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept:name\", \"org:group\"],\n",
    "        \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: True, Temporal_Feature.HOUR_OF_DAY: True}\n",
    "        }\n",
    "\n",
    "args_bpi_2012 = {\n",
    "        \"dataset_name\": \"bpi_2012\",\n",
    "        \"filepath\": \"BPI_Challenge_2012.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:resource\"]},\n",
    "        \"datetime_format\": None,\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 10,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"concept:name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept:name\", \"org:resource\"]\n",
    "        }\n",
    "\n",
    "args_bpi_2013 = {\n",
    "        \"dataset_name\": \"bpi_2013\",\n",
    "        \"filepath\": \"BPI_Challenge_2013_incidents.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:resource\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S%z\",\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 2,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"concept:name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept:name\", \"org:resource\"]\n",
    "        }\n",
    "\n",
    "args_bpi_2015_1 = {\n",
    "        \"dataset_name\": \"bpi_2015_1\",\n",
    "        \"filepath\": \"BPIC15_1.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:resource\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S%z\",\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 2,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"concept_name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept_name\", \"org_resource\"]\n",
    "        }\n",
    "\n",
    "\n",
    "run(args_helpdesk)\n",
    "# preprocess(args_helpdesk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change settings and run again\n",
    "\n",
    "# args_bpi_2012[\"additional_columns\"] = {}\n",
    "# args_bpi_2012[\"input_columns\"] = [\"concept:name\"]\n",
    "# run(args_bpi_2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run(additional_columns={Feature_Type.CATEGORICAL: [\"Resource\"]}, input_columns=[\"Activity\", \"Resource\"], target_columns=[\"Activity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run(additional_columns={Feature_Type.CATEGORICAL: [\"Resource\"]}, input_columns=[\"Activity\", \"Resource\"], target_columns=[\"Activity\", \"Resource\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
