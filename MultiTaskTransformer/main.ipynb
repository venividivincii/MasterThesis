{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler\n",
    "from typing import List, Optional\n",
    "from numpy.typing import NDArray\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Tuple\n",
    "import pm4py\n",
    "from package import transformer\n",
    "from package.loader import LogsDataLoader\n",
    "from package.processor import LogsDataProcessor, masked_standard_scaler, masked_min_max_scaler\n",
    "from package.constants import Feature_Type, Target, Temporal_Feature, Model_Architecture\n",
    "\n",
    "\n",
    "# Initialize data dir, if not exists\n",
    "if not os.path.exists(\"datasets\"): \n",
    "    os.mkdir(\"datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pipeline:\n",
    "    \n",
    "    def __init__(self, dataset_name: str, filepath: str, sorting: bool, columns: List[str],\n",
    "                 additional_columns: Optional[Dict[Feature_Type, List[str]]],\n",
    "                 datetime_format: str, model_epochs: int, model_num_layers: int,\n",
    "                 input_columns: List[str], target_columns: Dict[str, Target], temporal_features: Dict[Temporal_Feature, bool],\n",
    "                 cross_val: bool, model_architecture: Model_Architecture):\n",
    "        self.dataset_name: str = dataset_name\n",
    "        self.filepath: str = filepath\n",
    "        self.sorting: bool = sorting\n",
    "        self.columns: List[str] = columns\n",
    "        self.additional_columns: Optional[Dict[Feature_Type, List[str]]] = additional_columns\n",
    "        self.datetime_format: str = datetime_format\n",
    "        self.model_epochs: int = model_epochs\n",
    "        self.model_num_layers: int = model_num_layers\n",
    "        \n",
    "        self.target_columns: Dict[str, Target] = target_columns\n",
    "        for target_col in target_columns.keys():\n",
    "            if target_col == columns[1]:\n",
    "                self.target_columns[\"concept_name\"] = self.target_columns.pop(target_col)\n",
    "                break\n",
    "                \n",
    "        self.input_columns: List[str] = input_columns\n",
    "        for idx, input_col in enumerate(input_columns):\n",
    "            if input_col == columns[1]:\n",
    "                self.input_columns[idx] = \"concept_name\"\n",
    "                break\n",
    "        self.temporal_features: Dict[Temporal_Feature, bool] = temporal_features\n",
    "        self.cross_val = cross_val\n",
    "        self.model_architecture = model_architecture\n",
    "        \n",
    "    def __str__(self):\n",
    "        return (\n",
    "            f\"dataset_name: '{self.dataset_name}'\\n\"\n",
    "            f\"filepath: '{self.filepath}'\\n\"\n",
    "            f\"columns: '{self.columns}'\\n\"\n",
    "            f\"additional_columns: '{self.additional_columns}'\\n\"\n",
    "            f\"datetime_format: '{self.datetime_format}'\\n\"\n",
    "            f\"Model Epochs: '{self.model_epochs}'\\n\"\n",
    "            f\"Number of Transformer Layers in Model: '{self.model_num_layers}'\\n\"\n",
    "            f\"Target columns: '{self.target_columns}'\\n\"\n",
    "            f\"Input columns: '{self.input_columns}'\\n\")\n",
    "        \n",
    "    \n",
    "    def save_as_csv(self):\n",
    "        dir_path = os.path.join( \"datasets\", self.dataset_name )\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        file_path = os.path.join( dir_path, self.filepath )\n",
    "        \n",
    "        \n",
    "        if file_path.endswith('.xes'):\n",
    "            print(\"Converting xes to csv file\")\n",
    "            df = pm4py.convert_to_dataframe(pm4py.read_xes(file_path)).astype(str)\n",
    "            df.to_csv(file_path.replace(\".xes\", \".csv\"), index=False)\n",
    "        elif file_path.endswith('.csv'):\n",
    "            print(\"Input file already has csv format\")\n",
    "            \n",
    "    \n",
    "    # preprocess the event log and save the train-test split as csv files\n",
    "    def preprocess_log(self) -> List[int]:\n",
    "        data_processor = LogsDataProcessor(\n",
    "            name=self.dataset_name,\n",
    "            filepath=self.filepath,\n",
    "            sorting=self.sorting,\n",
    "            columns=self.columns,\n",
    "            additional_columns=self.additional_columns,  # Add all additional columns here, first all categorical, then all numerical features\n",
    "            input_columns=self.input_columns,\n",
    "            target_columns=self.target_columns,\n",
    "            datetime_format=self.datetime_format,\n",
    "            temporal_features=self.temporal_features,\n",
    "            pool=4\n",
    "        )\n",
    "        \n",
    "        # TODO: sanitize columns\n",
    "        # self.columns = [data_processor.sanitize_filename(col) for col in self.columns]\n",
    "        \n",
    "        # self.additional_columns = {\n",
    "        #                         feature_type: [data_processor.sanitize_filename(feature) for feature in feature_lst] for feature_type,\n",
    "        #                         feature_lst in self.additional_columns.items()\n",
    "        #                         } if len(self.additional_columns)>0 else self.additional_columns\n",
    "        self.target_columns = {data_processor.sanitize_filename(feature, self.columns): target for feature, target in self.target_columns.items()}\n",
    "        self.input_columns = [data_processor.sanitize_filename(col, self.columns) for col in self.input_columns]\n",
    "        self.columns = [data_processor.sanitize_filename(col, self.columns) for col in self.columns]\n",
    "        \n",
    "        # Preprocess the event log and make train-test split\n",
    "        data_processor.process_logs()\n",
    "        # flatten self.additional_columns to get all used features\n",
    "        self.additional_columns = data_processor.additional_columns\n",
    "        self.used_features = [item for sublist in self.additional_columns.values() for item in sublist]\n",
    "        \n",
    "        \n",
    "        # TODO: Compute the number of unique classes in each categorical column\n",
    "        # train_df = pd.read_csv(os.path.join(\"datasets\", self.dataset_name, \"processed\", f\"{self._preprocessing_id}_train.csv\"))\n",
    "        # num_classes_list = data_processor._compute_num_classes(train_df)\n",
    "        \n",
    "        # return num_classes_list\n",
    "    \n",
    "    \n",
    "    # load the preprocessed train-test split from the csv files\n",
    "    def load_data(self) -> Tuple [ LogsDataLoader, Dict[str, pd.DataFrame], Dict[str, pd.DataFrame], Dict[str, Dict[str, int]], Dict[Feature_Type, List[str]] ]:\n",
    "        data_loader = LogsDataLoader(name=self.dataset_name, sorting=self.sorting, input_columns=self.input_columns,\n",
    "                                     target_columns=self.target_columns, temporal_features=self.temporal_features)\n",
    "        train_dfs, test_dfs, word_dicts, feature_type_dict, mask = data_loader.load_data()\n",
    "        word_dicts = dict(sorted(word_dicts.items()))\n",
    "        return data_loader, train_dfs, test_dfs, word_dicts, feature_type_dict, mask\n",
    "    \n",
    "    \n",
    "    def prepare_data( self, data_loader, dfs: Dict[str, pd.DataFrame], x_scaler=None, y_scaler=None,\n",
    "                     train: bool = True) -> Tuple[ Dict[str, NDArray[np.float32]], Dict[str, NDArray[np.float32]], Dict[str, NDArray[np.float32]], int ]:\n",
    "        print(\"Preparing data...\")\n",
    "        # initialize max_case_length\n",
    "        max_case_length = False\n",
    "        # initialize token dicts\n",
    "        x_token_dict, y_token_dict, x_token_dict_numerical, y_token_dict_numerical = {}, {}, {}, {}\n",
    "        \n",
    "        # initialize case_id_df\n",
    "        case_ids = next(iter(dfs.values()))[\"case_id\"]\n",
    "        \n",
    "        # loop over all feature dfs\n",
    "        for idx, (feature, feature_df) in enumerate(dfs.items()):\n",
    "            \n",
    "            # get current feature_type\n",
    "            for feature_type, feature_lst in self.additional_columns.items():\n",
    "                if feature in feature_lst: break\n",
    "            \n",
    "            if idx == 0 and train:\n",
    "                (x_tokens, y_tokens, max_case_length\n",
    "                ) = data_loader.prepare_data(feature=feature, df=feature_df, max_case_length=True)\n",
    "            else:\n",
    "                x_tokens, y_tokens = data_loader.prepare_data(feature=feature, df=feature_df)\n",
    "            \n",
    "            if feature_type is Feature_Type.TIMESTAMP or feature_type is Feature_Type.NUMERICAL:\n",
    "                x_token_dict_numerical.update(x_tokens)\n",
    "                y_token_dict_numerical.update(y_tokens)\n",
    "            else:\n",
    "                # update x_token_dict\n",
    "                x_token_dict.update(x_tokens)\n",
    "                y_token_dict.update(y_tokens)\n",
    "            \n",
    "        # TODO:\n",
    "        if len(x_token_dict_numerical) > 0  and len(list(x_token_dict_numerical.values())[0]) > 0:\n",
    "            # Concatenate all the feature arrays along the rows (axis=0)\n",
    "            combined_data = np.vstack(list(x_token_dict_numerical.values()))\n",
    "            if x_scaler is None:\n",
    "                # Initialize the StandardScaler\n",
    "                # x_scaler = StandardScaler()\n",
    "                # x_scaler = MinMaxScaler(feature_range=(0, 30))\n",
    "                # x_scaler = FunctionTransformer(masked_standard_scaler, kw_args={'padding_value': -1})\n",
    "                x_scaler = FunctionTransformer(masked_min_max_scaler, kw_args={'padding_value': -1})\n",
    "                # Fit the scaler on the combined data\n",
    "                x_scaler.fit(combined_data)\n",
    "            # Transform the combined data\n",
    "            scaled_combined_data = x_scaler.transform(combined_data)\n",
    "            # split the scaled combined data back into the original feature dict\n",
    "            split_indices = np.cumsum([value.shape[0] for value in x_token_dict_numerical.values()])[:-1]\n",
    "            scaled_data_parts = np.vsplit(scaled_combined_data, split_indices)\n",
    "            # Reconstruct the dictionary with scaled data\n",
    "            scaled_dict = {key: scaled_data_parts[i] for i, key in enumerate(x_token_dict_numerical.keys())}\n",
    "            # update x_token_dict\n",
    "            x_token_dict.update(scaled_dict)\n",
    "        if len(y_token_dict_numerical) > 0:\n",
    "            # Prepare list to store valid arrays (non-empty)\n",
    "            valid_arrays = []\n",
    "            valid_keys = []\n",
    "\n",
    "            # Check for empty arrays and prepare data for scaling\n",
    "            for key, value in y_token_dict_numerical.items():\n",
    "                if value.size > 0:  # Only consider non-empty arrays\n",
    "                    valid_arrays.append(value.reshape(-1, 1))  # Reshape to 2D\n",
    "                    valid_keys.append(key)\n",
    "\n",
    "            # If there are valid arrays to scale\n",
    "            if valid_arrays:\n",
    "                combined_data = np.hstack(valid_arrays)  # Horizontal stacking for features\n",
    "\n",
    "                if y_scaler is None:\n",
    "                    # Initialize the StandardScaler\n",
    "                    # y_scaler = StandardScaler()\n",
    "                    y_scaler = MinMaxScaler(feature_range=(0, 30))\n",
    "                    # Fit the scaler on the combined data\n",
    "                    y_scaler.fit(combined_data)\n",
    "\n",
    "                # Transform the combined data\n",
    "                scaled_combined_data = y_scaler.transform(combined_data)\n",
    "\n",
    "                # Split the scaled combined data back into individual features\n",
    "                scaled_data_parts = np.hsplit(scaled_combined_data, scaled_combined_data.shape[1])\n",
    "\n",
    "                # Reconstruct the dictionary with scaled data\n",
    "                scaled_dict = {key: scaled_data_parts[i].flatten() for i, key in enumerate(valid_keys)}\n",
    "\n",
    "                # Update y_token_dict with the scaled data\n",
    "                y_token_dict.update(scaled_dict)\n",
    "\n",
    "            # Handle any empty arrays (if necessary)\n",
    "            for key, value in y_token_dict_numerical.items():\n",
    "                if value.size == 0:\n",
    "                    # Optionally, you can handle empty arrays here, e.g., leave them as-is\n",
    "                    y_token_dict[key] = value\n",
    "            \n",
    "            \n",
    "        # sort dicts\n",
    "        x_token_dict = dict(sorted(x_token_dict.items()))\n",
    "        y_token_dict = dict(sorted(y_token_dict.items()))\n",
    "\n",
    "        return case_ids, x_token_dict, y_token_dict, x_scaler, y_scaler, max_case_length\n",
    "    \n",
    "    \n",
    "    # Prepare data and train the model\n",
    "    def train(self,\n",
    "            case_ids: pd.DataFrame,\n",
    "            feature_type_dict: Dict[Feature_Type, List[str]],\n",
    "            train_token_dict_x: Dict[str, NDArray[np.float32]],\n",
    "            train_token_dict_y: Dict[str, NDArray[np.float32]],\n",
    "            word_dicts: Dict[str, Dict[str, int]],\n",
    "            max_case_length: int,\n",
    "            y_scaler,\n",
    "            mask # Fraction of the training data to be used for validation\n",
    "            ) -> tf.keras.Model:\n",
    "\n",
    "        # Ensure that input columns and dictionaries are sorted\n",
    "        self.input_columns.sort()\n",
    "        self.target_columns = dict(sorted(self.target_columns.items()))\n",
    "        train_token_dict_x = dict(sorted(train_token_dict_x.items()))\n",
    "        train_token_dict_y = dict(sorted(train_token_dict_y.items()))\n",
    "        word_dicts = dict(sorted(word_dicts.items()))\n",
    "\n",
    "        # initialize model_wrapper with data for model\n",
    "        model_wrapper = transformer.ModelWrapper(\n",
    "                                                dataset_name = self.dataset_name,\n",
    "                                                case_ids = case_ids,\n",
    "                                                input_columns=self.input_columns,\n",
    "                                                target_columns=self.target_columns,\n",
    "                                                additional_columns=self.additional_columns,\n",
    "                                                word_dicts=word_dicts,\n",
    "                                                max_case_length=max_case_length,\n",
    "                                                feature_type_dict=feature_type_dict,\n",
    "                                                temporal_features=self.temporal_features,\n",
    "                                                model_architecture=self.model_architecture,\n",
    "                                                sorting=self.sorting,\n",
    "                                                masking=True\n",
    "                                                )\n",
    "        \n",
    "        # train the model\n",
    "        models, histories = model_wrapper.train_model(\n",
    "                                                    train_token_dict_x = train_token_dict_x,\n",
    "                                                    train_token_dict_y = train_token_dict_y,\n",
    "                                                    cross_val = self.cross_val,\n",
    "                                                    y_scaler = y_scaler,\n",
    "                                                    model_epochs = self.model_epochs,\n",
    "                                                    batch_size = 12,\n",
    "                                                    model_learning_rate = 0.001\n",
    "                                                    )\n",
    "        # Plot training loss\n",
    "        self._plot_training_loss(histories)\n",
    "        return models, histories\n",
    "            \n",
    "            \n",
    "    # helper function for plotting the training loss\n",
    "    def _plot_training_loss(self, histories):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # If there are multiple histories (cross-validation), plot for each fold\n",
    "        if isinstance(histories, list):\n",
    "            for i, history in enumerate(histories):\n",
    "                plt.plot(history.history['loss'], label=f'Training Loss Fold {i+1}')\n",
    "                if 'val_loss' in history.history:\n",
    "                    plt.plot(history.history['val_loss'], label=f'Validation Loss Fold {i+1}')\n",
    "        else:\n",
    "            # Single history (no cross-validation)\n",
    "            plt.plot(histories.history['loss'], label='Training Loss')\n",
    "            if 'val_loss' in histories.history:\n",
    "                plt.plot(histories.history['val_loss'], label='Validation Loss')\n",
    "        \n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def evaluate(self, models, data_loader: LogsDataLoader, test_dfs: Dict[str, pd.DataFrame],\n",
    "                 max_case_length: int, x_scaler=None, y_scaler=None):\n",
    "        \n",
    "        #TODO: testing\n",
    "        # print(f\"Unscaled MAE training: {y_scaler.scale_ * 0.3030}\")\n",
    "        results, preds = [], []\n",
    "        for idx, model in enumerate(models):\n",
    "            print(f\"Evaluating model {idx+1}...\")\n",
    "\n",
    "            # Prepare lists to store evaluation metrics\n",
    "            k, accuracies, fscores, precisions, recalls, weights = {}, {}, {}, {}, {}, {}\n",
    "            mae, mse, rmse, r2 = {}, {}, {}, {}\n",
    "            \n",
    "            for target_col in self.target_columns.keys():\n",
    "                for feature_type, feature_lst in self.additional_columns.items():\n",
    "                    if target_col in feature_lst:\n",
    "                        k.update({target_col: []})\n",
    "                        weights.update({target_col: []})\n",
    "                        \n",
    "                        if feature_type is Feature_Type.CATEGORICAL:\n",
    "                            accuracies.update({target_col: []})\n",
    "                            fscores.update({target_col: []})\n",
    "                            precisions.update({target_col: []})\n",
    "                            recalls.update({target_col: []})\n",
    "                        elif feature_type is Feature_Type.TIMESTAMP:\n",
    "                            mae.update({target_col: []})\n",
    "                            mse.update({target_col: []})\n",
    "                            rmse.update({target_col: []})\n",
    "                            r2.update({target_col: []})\n",
    "\n",
    "            # Calculate total number of samples\n",
    "            total_samples = len(list(test_dfs.values())[0])\n",
    "\n",
    "            # Iterate over all prefixes (k)\n",
    "            for i in range(1, max_case_length + 1):\n",
    "                print(\"Prefix length: \" + str(i))\n",
    "                test_data_subsets = {}\n",
    "\n",
    "                for key, df in test_dfs.items():\n",
    "                    if (Feature_Type.TIMESTAMP in self.additional_columns\n",
    "                            and key in self.additional_columns[Feature_Type.TIMESTAMP]):\n",
    "                        prefix_str = f\"{key}##Prefix Length\"\n",
    "                    else:\n",
    "                        prefix_str = \"Prefix Length\"\n",
    "                    filtered_df = df[df[prefix_str] == i]\n",
    "                    test_data_subsets.update({key: filtered_df})\n",
    "\n",
    "\n",
    "                _, x_token_dict, y_token_dict, _, _, _ = self.prepare_data(data_loader=data_loader, dfs=test_data_subsets,\n",
    "                                                                x_scaler=x_scaler, y_scaler=y_scaler, train=False)\n",
    "\n",
    "                # sort dicts\n",
    "                x_token_dict = dict(sorted(x_token_dict.items()))\n",
    "                y_token_dict = dict(sorted(y_token_dict.items()))\n",
    "\n",
    "                if len(test_data_subsets[self.input_columns[0]]) > 0:\n",
    "\n",
    "                    # Make predictions\n",
    "                    predictions = model.predict(x_token_dict)\n",
    "                    \n",
    "                    # Handle multiple outputs for multitask learning\n",
    "                    if len(self.target_columns) > 1:\n",
    "                        result_dict = dict(zip(self.target_columns.keys(), predictions))\n",
    "                    else:\n",
    "                        result_dict = dict(zip(self.target_columns.keys(), [predictions]))\n",
    "\n",
    "                    # Compute metrics\n",
    "                    for feature, result in result_dict.items():\n",
    "                        for feature_type, feature_lst in self.additional_columns.items():\n",
    "                            if feature in feature_lst:\n",
    "                                if feature_type is Feature_Type.CATEGORICAL:\n",
    "                                    result = np.argmax(result, axis=1)\n",
    "                                    accuracy = metrics.accuracy_score(y_token_dict[f\"output_{feature}\"], result)\n",
    "                                    precision, recall, fscore, _ = metrics.precision_recall_fscore_support(\n",
    "                                        y_token_dict[f\"output_{feature}\"], result, average=\"weighted\", zero_division=0)\n",
    "                                    weight = len(test_data_subsets[feature]) / total_samples\n",
    "\n",
    "                                    k[feature].append(i)\n",
    "                                    accuracies[feature].append(accuracy)\n",
    "                                    fscores[feature].append(fscore)\n",
    "                                    precisions[feature].append(precision)\n",
    "                                    recalls[feature].append(recall)\n",
    "                                    weights[feature].append(weight)\n",
    "                                \n",
    "                                elif feature_type is Feature_Type.TIMESTAMP:\n",
    "                                    y_true_unscaled = y_token_dict[f\"output_{feature}\"]\n",
    "                                    y_true = y_scaler.inverse_transform( y_true_unscaled.reshape(-1, y_true_unscaled.shape[-1])\n",
    "                                                                        ).reshape(y_true_unscaled.shape)\n",
    "                                    y_pred = y_scaler.inverse_transform( result )\n",
    "                                    mae_value = metrics.mean_absolute_error(y_true, y_pred)\n",
    "                                    mse_value = metrics.mean_squared_error(y_true, y_pred)\n",
    "                                    rmse_value = np.sqrt(mse_value)\n",
    "                                    r2_value = metrics.r2_score(y_true, y_pred)\n",
    "                                    weight = len(test_data_subsets[feature]) / total_samples\n",
    "\n",
    "                                    k[feature].append(i)\n",
    "                                    mae[feature].append(mae_value)\n",
    "                                    mse[feature].append(mse_value)\n",
    "                                    rmse[feature].append(rmse_value)\n",
    "                                    r2[feature].append(r2_value)\n",
    "                                    weights[feature].append(weight)\n",
    "            feature_results = []\n",
    "            for target_col in self.target_columns.keys():\n",
    "                for feature_type, feature_lst in self.additional_columns.items():\n",
    "                    if target_col in feature_lst:\n",
    "                        if feature_type is Feature_Type.CATEGORICAL:\n",
    "                            # Compute weighted mean metrics over all k\n",
    "                            weighted_accuracy = np.average(accuracies[target_col], weights=weights[target_col])\n",
    "                            weighted_fscore = np.average(fscores[target_col], weights=weights[target_col])\n",
    "                            weighted_precision = np.average(precisions[target_col], weights=weights[target_col])\n",
    "                            weighted_recall = np.average(recalls[target_col], weights=weights[target_col])\n",
    "                            # Append weighted mean metrics to the lists\n",
    "                            weights[target_col].append(\"\")\n",
    "                            k[target_col].append(\"Weighted Mean\")\n",
    "                            accuracies[target_col].append(weighted_accuracy)\n",
    "                            fscores[target_col].append(weighted_fscore)\n",
    "                            precisions[target_col].append(weighted_precision)\n",
    "                            recalls[target_col].append(weighted_recall)\n",
    "                            # Create a DataFrame to display the results\n",
    "                            print(f\"Results for {target_col}\")\n",
    "                            results_df = pd.DataFrame({\n",
    "                                'k': k[target_col],\n",
    "                                'weight': weights[target_col],\n",
    "                                'accuracy': accuracies[target_col],\n",
    "                                'fscore': fscores[target_col],\n",
    "                                'precision': precisions[target_col],\n",
    "                                'recall': recalls[target_col]\n",
    "                            })\n",
    "                            feature_results.append(results_df)\n",
    "                            # Display the results\n",
    "                            print(results_df)\n",
    "                        \n",
    "                        elif feature_type is Feature_Type.TIMESTAMP:\n",
    "                            # Compute weighted mean metrics over all k\n",
    "                            weighted_mae = np.average(mae[target_col], weights=weights[target_col])\n",
    "                            weighted_mse = np.average(mse[target_col], weights=weights[target_col])\n",
    "                            weighted_rmse = np.average(rmse[target_col], weights=weights[target_col])\n",
    "                            weighted_r2 = np.average(r2[target_col], weights=weights[target_col])\n",
    "                            # Append weighted mean metrics to the lists\n",
    "                            weights[target_col].append(\"\")\n",
    "                            k[target_col].append(\"Weighted Mean\")\n",
    "                            mae[target_col].append(weighted_mae)\n",
    "                            mse[target_col].append(weighted_mse)\n",
    "                            rmse[target_col].append(weighted_rmse)\n",
    "                            r2[target_col].append(weighted_r2)\n",
    "                            # Create a DataFrame to display the results\n",
    "                            print(f\"Results for {target_col}\")\n",
    "                            results_df = pd.DataFrame({\n",
    "                                'k': k[target_col],\n",
    "                                'weight': weights[target_col],\n",
    "                                'mae': mae[target_col],\n",
    "                                'mse': mse[target_col],\n",
    "                                'rmse': rmse[target_col],\n",
    "                                'r2': r2[target_col]\n",
    "                            })\n",
    "                            feature_results.append(results_df)\n",
    "                            # Display the results\n",
    "                            print(results_df)\n",
    "            results.append(feature_results)\n",
    "            print(\"_____________________________________________\")\n",
    "            \n",
    "          \n",
    "            \n",
    "            # calculate predictions for all test data\n",
    "            _, x_token_dict, y_token_dict, _, _, _ = self.prepare_data(data_loader=data_loader, dfs=test_dfs,\n",
    "                                                    x_scaler=x_scaler, y_scaler=y_scaler, train=False)\n",
    "            # sort dicts\n",
    "            x_token_dict = dict(sorted(x_token_dict.items()))\n",
    "            y_token_dict = dict(sorted(y_token_dict.items()))\n",
    "            \n",
    "            # Make predictions\n",
    "            predictions = model.predict(x_token_dict)\n",
    "            \n",
    "            # Handle multiple outputs for multitask learning\n",
    "            if len(self.target_columns) > 1:\n",
    "                result_dict = dict(zip(self.target_columns.keys(), predictions))\n",
    "            else:\n",
    "                result_dict = dict(zip(self.target_columns.keys(), [predictions]))\n",
    "                \n",
    "            feature_preds = []\n",
    "            for feature, result in result_dict.items():\n",
    "                for feature_type, feature_lst in self.additional_columns.items():\n",
    "                    if feature in feature_lst:\n",
    "                        if feature_type is Feature_Type.CATEGORICAL:\n",
    "                            y_true = y_token_dict[f\"output_{feature}\"]\n",
    "                            y_pred = np.argmax(result, axis=1)\n",
    "                        elif feature_type is Feature_Type.TIMESTAMP:\n",
    "                            y_true_unscaled = y_token_dict[f\"output_{feature}\"]\n",
    "                            y_true = y_scaler.inverse_transform( y_true_unscaled.reshape(-1, y_true_unscaled.shape[-1])\n",
    "                                                                ).reshape(y_true_unscaled.shape)\n",
    "                            y_pred = y_scaler.inverse_transform( result )\n",
    "                        preds_df = pd.DataFrame({\n",
    "                                        'y_true': y_true.reshape(-1),\n",
    "                                        'y_pred': y_pred.reshape(-1)\n",
    "                                    })\n",
    "                        feature_preds.append(preds_df)\n",
    "            preds.append(feature_preds)\n",
    "                    \n",
    "        \n",
    "        return results, preds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "          \n",
    "            \n",
    "    def safe_results(self, histories: list, results: list, preds: list):\n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        \n",
    "        dir_path = os.path.join( \"datasets\", self.dataset_name, \"results\", timestamp )\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        \n",
    "        # Safe parameters in json\n",
    "        parameters = {\"Input Columns\": self.input_columns,\n",
    "                      \"Target Columns\": {key: value.value for key, value in self.target_columns.items()},\n",
    "                      \"Model Epochs\": self.model_epochs,\n",
    "                      \"Transformer Layers\": self.model_num_layers,\n",
    "                      \"Sorting\": self.sorting,\n",
    "                      \"Cross Validation\": self.cross_val,\n",
    "                      }\n",
    "        coded_json = json.dumps(parameters)\n",
    "        with open(os.path.join(dir_path, \"parameters.json\"), \"w\") as metadata_file:\n",
    "            metadata_file.write(coded_json)\n",
    "        \n",
    "        # Save histories and results\n",
    "        for model_idx, (history, result, pred) in enumerate(zip(histories, results, preds)):\n",
    "            # Save history as CSV\n",
    "            history_df = pd.DataFrame(history.history)\n",
    "            history_path = os.path.join(dir_path, f\"history_{model_idx+1}.csv\")\n",
    "            history_df.to_csv(history_path, index=False)\n",
    "            \n",
    "            for output_idx, (output_result_df, output_pred_df) in enumerate(zip(result, pred)):\n",
    "                feature = list(self.target_columns.keys())[output_idx]\n",
    "                # Save results DataFrame as CSV\n",
    "                results_path = os.path.join(dir_path, f\"results_{model_idx+1}__{feature}.csv\")\n",
    "                output_result_df.to_csv(results_path, index=False)\n",
    "                \n",
    "                # Save predictions DataFrame as CSV\n",
    "                results_path = os.path.join(dir_path, f\"predictions_{model_idx+1}__{feature}.csv\")\n",
    "                output_pred_df.to_csv(results_path, index=False)\n",
    "\n",
    "        print(f\"Histories and results saved to {dir_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper Functions ###\n",
    "\n",
    "# helper function to save xes file as csv\n",
    "def save_csv(args):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(**args)  # Examples: \"concept:name\", \"Resource\"\n",
    "    pipe.save_as_csv()\n",
    "    \n",
    "\n",
    "# helper function: do only preprocessing on data\n",
    "def preprocess(args):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(**args)  # Examples: \"concept:name\", \"Resource\"\n",
    "    # preprocess data\n",
    "    pipe.preprocess_log()\n",
    "\n",
    "\n",
    "# helper function\n",
    "def run(args):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(**args)  # Examples: \"concept:name\", \"Resource\"\n",
    "\n",
    "    # print parameters\n",
    "    print(pipe)\n",
    "\n",
    "    # preprocess data\n",
    "    pipe.preprocess_log()\n",
    "\n",
    "    # load data\n",
    "    data_loader, train_dfs, test_dfs, word_dicts, feature_type_dict, mask = pipe.load_data()\n",
    "\n",
    "    # prepare data\n",
    "    case_ids, train_token_dict_x, train_token_dict_y, x_scaler, y_scaler, max_case_length = pipe.prepare_data(data_loader, train_dfs)\n",
    "\n",
    "    # train the model\n",
    "    models, histories = pipe.train(\n",
    "                case_ids = case_ids,\n",
    "                feature_type_dict = feature_type_dict,\n",
    "                train_token_dict_x = train_token_dict_x,\n",
    "                train_token_dict_y = train_token_dict_y,\n",
    "                word_dicts = word_dicts,\n",
    "                max_case_length = max_case_length,\n",
    "                y_scaler = y_scaler,\n",
    "                mask = mask\n",
    "                )\n",
    "\n",
    "    # evaluate the model\n",
    "    results, preds = pipe.evaluate(models=models, data_loader=data_loader, test_dfs=test_dfs, x_scaler=x_scaler,\n",
    "                                y_scaler=y_scaler, max_case_length=max_case_length)\n",
    "    \n",
    "    # safe the training histories and results\n",
    "    pipe.safe_results(histories=histories, results=results, preds=preds)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"======================================\")\n",
    "    print(\"======================================\")\n",
    "    \n",
    "    \n",
    "# function for testing out code\n",
    "def test(args):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(**args)  # Examples: \"concept:name\", \"Resource\"\n",
    "\n",
    "    # print parameters\n",
    "    print(pipe)\n",
    "\n",
    "    # preprocess data\n",
    "    pipe.preprocess_log()\n",
    "\n",
    "    # load data\n",
    "    data_loader, train_dfs, test_dfs, word_dicts, feature_type_dict = pipe.load_data()\n",
    "\n",
    "    # prepare data\n",
    "    train_token_dict_x, train_token_dict_y, x_scaler, y_scaler, max_case_length = pipe.prepare_data(data_loader, train_dfs)\n",
    "\n",
    "    # # train the model\n",
    "    # model = pipe.train(\n",
    "    #             feature_type_dict = feature_type_dict,\n",
    "    #             train_token_dict_x = train_token_dict_x,\n",
    "    #             train_token_dict_y = train_token_dict_y,\n",
    "    #             word_dicts = word_dicts,\n",
    "    #             max_case_length = max_case_length\n",
    "    #             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Args & Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: 'helpdesk'\n",
      "filepath: 'helpdesk.csv'\n",
      "columns: '['Case ID', 'Activity', 'Complete Timestamp']'\n",
      "additional_columns: '{<Feature_Type.CATEGORICAL: 'categorical'>: ['Resource']}'\n",
      "datetime_format: '%Y-%m-%d %H:%M:%S.%f'\n",
      "Model Epochs: '1'\n",
      "Number of Transformer Layers in Model: '1'\n",
      "Target columns: '{'Complete Timestamp': <Target.NEXT_FEATURE: 'next_feature'>, 'concept_name': <Target.NEXT_FEATURE: 'next_feature'>}'\n",
      "Input columns: '['concept_name', 'Resource', 'Complete Timestamp']'\n",
      "\n",
      "All processed files for current spec found. Preprocessing skipped.\n",
      "Loading data from preprocessed train-test split...\n",
      "['Resource', 'concept_name', 'time_timestamp']\n",
      "Preparing data...\n",
      "Using regular train-validation split\n",
      "Creating model...\n",
      "Masking active.\n",
      "Using Multi-Task Learning Setup\n",
      "891/891 [==============================] - 59s 42ms/step - loss: 2.2998 - output_concept_name_loss: 0.8254 - output_time_timestamp_loss: 1.4743 - output_concept_name_sparse_categorical_accuracy: 0.7451 - output_time_timestamp_mean_absolute_error: 3.5050 - val_loss: 2.0449 - val_output_concept_name_loss: 0.7310 - val_output_time_timestamp_loss: 1.3139 - val_output_concept_name_sparse_categorical_accuracy: 0.7775 - val_output_time_timestamp_mean_absolute_error: 3.1906\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model 1...\n",
      "Prefix length: 1\n",
      "Preparing data...\n",
      "29/29 [==============================] - 2s 23ms/step\n",
      "Prefix length: 2\n",
      "Preparing data...\n",
      "29/29 [==============================] - 1s 29ms/step\n",
      "Prefix length: 3\n",
      "Preparing data...\n",
      "28/28 [==============================] - 1s 22ms/step\n",
      "Prefix length: 4\n",
      "Preparing data...\n",
      "12/12 [==============================] - 0s 21ms/step\n",
      "Prefix length: 5\n",
      "Preparing data...\n",
      "5/5 [==============================] - 0s 23ms/step\n",
      "Prefix length: 6\n",
      "Preparing data...\n",
      "2/2 [==============================] - 0s 26ms/step\n",
      "Prefix length: 7\n",
      "Preparing data...\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "Prefix length: 8\n",
      "Preparing data...\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "Prefix length: 9\n",
      "Preparing data...\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "Prefix length: 10\n",
      "Preparing data...\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "Prefix length: 11\n",
      "Preparing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\sklearn\\metrics\\_regression.py:1187: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 307ms/step\n",
      "Prefix length: 12\n",
      "Preparing data...\n",
      "Prefix length: 13\n",
      "Preparing data...\n",
      "Prefix length: 14\n",
      "Preparing data...\n",
      "Results for concept_name\n",
      "                k    weight  accuracy    fscore  precision    recall\n",
      "0               1  0.274745  0.853712  0.809197   0.834575  0.853712\n",
      "1               2  0.274445  0.684153  0.581523   0.509494  0.684153\n",
      "2               3  0.262448  0.829714  0.793395   0.788068  0.829714\n",
      "3               4  0.111878  0.820375  0.776648   0.748477  0.820375\n",
      "4               5  0.046191  0.772727  0.742755   0.716097  0.772727\n",
      "5               6  0.017996  0.750000  0.719919   0.693526  0.750000\n",
      "6               7  0.007199  0.750000  0.702778   0.685049  0.750000\n",
      "7               8  0.003299  0.545455  0.545455   0.590909  0.545455\n",
      "8               9    0.0012  0.500000  0.600000   0.750000  0.500000\n",
      "9              10    0.0003  1.000000  1.000000   1.000000  1.000000\n",
      "10             11    0.0003  1.000000  1.000000   1.000000  1.000000\n",
      "11  Weighted Mean            0.789442  0.732476   0.713626  0.789442\n",
      "Results for time_timestamp\n",
      "                k    weight        mae         mse       rmse        r2\n",
      "0               1  0.274745   3.651702   47.170570   6.868083  0.003579\n",
      "1               2  0.274445   5.753092   91.311211   9.555690  0.281556\n",
      "2               3  0.262448   8.649969  136.887695  11.699902  0.502827\n",
      "3               4  0.111878   7.974072  101.220192  10.060824  0.546994\n",
      "4               5  0.046191   8.479579  122.698280  11.076925  0.420528\n",
      "5               6  0.017996   8.662145  108.492676  10.415981  0.573747\n",
      "6               7  0.007199   7.104013   69.144989   8.315347  0.640377\n",
      "7               8  0.003299  10.413054  170.736435  13.066615  0.419068\n",
      "8               9    0.0012  10.565951  119.948471  10.952099 -0.976494\n",
      "9              10    0.0003   8.389099   70.376984   8.389099       NaN\n",
      "10             11    0.0003  10.872383  118.208717  10.872383       NaN\n",
      "11  Weighted Mean             6.395993   94.151446   9.526664       NaN\n",
      "_____________________________________________\n",
      "Preparing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\sklearn\\metrics\\_regression.py:1187: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 2s 20ms/step\n",
      "Histories and results saved to datasets\\helpdesk\\results\\20240913-135851\n",
      "\n",
      "======================================\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "# args_helpdesk = {\n",
    "#         \"dataset_name\": \"helpdesk\",\n",
    "#         \"filepath\": \"helpdesk.csv\",\n",
    "#         \"columns\": [\"Case ID\", \"Activity\", \"Complete Timestamp\"],\n",
    "#         \"additional_columns\": {},\n",
    "#         \"datetime_format\": \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "#         \"model_learning_rate\": 0.001,\n",
    "#         \"model_epochs\": 3,\n",
    "#         \"model_num_layers\": 1,\n",
    "#         \"target_columns\": {\"Complete Timestamp\": Target.NEXT_FEATURE},\n",
    "#         \"input_columns\": [\"Activity\"],\n",
    "#         \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: False, Temporal_Feature.HOUR_OF_DAY: False},\n",
    "#         \"model_architecture\": Model_Architecture.COMMON_POSEMBS_TRANSF\n",
    "#         }\n",
    "\n",
    "args_helpdesk = {\n",
    "        \"dataset_name\": \"helpdesk\",\n",
    "        \"filepath\": \"helpdesk.csv\",\n",
    "        \"columns\": [\"Case ID\", \"Activity\", \"Complete Timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"Resource\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "        \"model_epochs\": 1,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"Activity\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"Activity\", \"Resource\", \"Complete Timestamp\"],\n",
    "        \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: False, Temporal_Feature.HOUR_OF_DAY: False},\n",
    "        \"model_architecture\": Model_Architecture.COMMON_POSEMBS_TRANSF,\n",
    "        \"sorting\": True,\n",
    "        \"cross_val\": True\n",
    "        }\n",
    "\n",
    "# args_helpdesk = {\n",
    "#         \"dataset_name\": \"helpdesk\",\n",
    "#         \"filepath\": \"helpdesk.csv\",\n",
    "#         \"columns\": [\"Case ID\", \"Activity\", \"Complete Timestamp\"],\n",
    "#         \"additional_columns\": {Feature_Type.CATEGORICAL: [\"Resource\"]},\n",
    "#         \"datetime_format\": \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "#         \"model_learning_rate\": 0.001,\n",
    "#         \"model_epochs\": 1,\n",
    "#         \"model_num_layers\": 1,\n",
    "#         \"target_columns\": {\"Activity\": Target.NEXT_FEATURE},\n",
    "#         \"input_columns\": [\"Activity\", \"Resource\", \"Complete Timestamp\"],\n",
    "#         \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: True, Temporal_Feature.HOUR_OF_DAY: True}\n",
    "#         }\n",
    "\n",
    "args_sepsis = {\n",
    "        \"dataset_name\": \"sepsis\",\n",
    "        \"filepath\": \"sepsis.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:group\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S%z\",\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 1,\n",
    "        \"model_num_layers\": 10,\n",
    "        \"target_columns\": {\"concept:name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept:name\", \"org:group\"],\n",
    "        \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: True, Temporal_Feature.HOUR_OF_DAY: True}\n",
    "        }\n",
    "\n",
    "args_bpi_2012 = {\n",
    "        \"dataset_name\": \"bpi_2012\",\n",
    "        \"filepath\": \"BPI_Challenge_2012.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:resource\"]},\n",
    "        \"datetime_format\": None,\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 10,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"concept:name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept:name\", \"org:resource\"]\n",
    "        }\n",
    "\n",
    "args_bpi_2013 = {\n",
    "        \"dataset_name\": \"bpi_2013\",\n",
    "        \"filepath\": \"BPI_Challenge_2013_incidents.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:resource\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S%z\",\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 2,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"concept:name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept:name\", \"org:resource\"]\n",
    "        }\n",
    "\n",
    "args_bpi_2015_1 = {\n",
    "        \"dataset_name\": \"bpi_2015_1\",\n",
    "        \"filepath\": \"BPIC15_1.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:resource\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S%z\",\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 2,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"concept_name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept_name\", \"org_resource\"]\n",
    "        }\n",
    "\n",
    "\n",
    "run(args_helpdesk)\n",
    "# preprocess(args_helpdesk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change settings and run again\n",
    "\n",
    "# args_bpi_2012[\"additional_columns\"] = {}\n",
    "# args_bpi_2012[\"input_columns\"] = [\"concept:name\"]\n",
    "# run(args_bpi_2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run(additional_columns={Feature_Type.CATEGORICAL: [\"Resource\"]}, input_columns=[\"Activity\", \"Resource\"], target_columns=[\"Activity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run(additional_columns={Feature_Type.CATEGORICAL: [\"Resource\"]}, input_columns=[\"Activity\", \"Resource\"], target_columns=[\"Activity\", \"Resource\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
