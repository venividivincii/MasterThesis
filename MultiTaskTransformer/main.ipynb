{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "\n",
    "from package.processtransformer import constants\n",
    "from package.processtransformer.models import transformer\n",
    "from package.processtransformer.data.loader import LogsDataLoader\n",
    "from package.processtransformer.data.processor import LogsDataProcessor\n",
    "\n",
    "\n",
    "\n",
    "# Initialize data dir, if not exists\n",
    "if not os.path.exists(\"datasets\"): \n",
    "    os.mkdir(\"datasets\")\n",
    "    \n",
    "# Helper function to process and load data\n",
    "def process_and_load_data(dataset_name, filepath, columns, additional_columns, datetime_format, task):\n",
    "    data_processor = LogsDataProcessor(\n",
    "        name=dataset_name,\n",
    "        filepath=filepath,\n",
    "        columns=columns,\n",
    "        additional_columns=additional_columns,  # Add all additional columns here, first all categorical, then all numerical features\n",
    "        datetime_format=datetime_format,\n",
    "        pool=4\n",
    "    )\n",
    "    data_processor.process_logs(task=task, sort_temporally=False)\n",
    "    train_df = pd.read_csv(f\"datasets/{dataset_name}/processed/{task.value}_train.csv\")\n",
    "    num_classes_list = data_processor._compute_num_classes(train_df)\n",
    "    del data_processor\n",
    "    data_loader = LogsDataLoader(name=dataset_name)\n",
    "    train_df, test_df, x_word_dict, y_word_dict, max_case_length, vocab_size, num_output = data_loader.load_data(task)\n",
    "    return data_loader, train_df, test_df, x_word_dict, y_word_dict, max_case_length, vocab_size, num_output, num_classes_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Next Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpdesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No preprocessed train-test split for task next_activity found. Preprocessing...\n",
      "Parsing Event-Log...\n",
      "Parsing successful.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21348 entries, 0 to 21347\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   case:concept:name  21348 non-null  object        \n",
      " 1   concept:name       21348 non-null  object        \n",
      " 2   time:timestamp     21348 non-null  datetime64[ns]\n",
      " 3   Resource           21348 non-null  object        \n",
      " 4   product            21348 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(4)\n",
      "memory usage: 834.0+ KB\n",
      "None\n",
      "  case:concept:name           concept:name      time:timestamp Resource  \\\n",
      "0            Case 1     assign-seriousness 2012-10-09 14:50:17  Value 1   \n",
      "1            Case 1  take-in-charge-ticket 2012-10-09 14:51:01  Value 1   \n",
      "2            Case 1  take-in-charge-ticket 2012-10-12 15:02:56  Value 2   \n",
      "3            Case 1         resolve-ticket 2012-10-25 11:54:26  Value 1   \n",
      "4            Case 1                 closed 2012-11-09 12:54:39  Value 3   \n",
      "\n",
      "   product  \n",
      "0  Value 1  \n",
      "1  Value 1  \n",
      "2  Value 1  \n",
      "3  Value 1  \n",
      "4  Value 1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from preprocessed train-test split...\n"
     ]
    }
   ],
   "source": [
    "# Process and load data for the next activity task\n",
    "dataset_name = \"helpdesk\"\n",
    "data_loader, train_df, test_df, x_word_dict, y_word_dict, max_case_length, vocab_size, num_output, num_classes_list = process_and_load_data(\n",
    "    dataset_name = dataset_name,\n",
    "    filepath = \"helpdesk.csv\",\n",
    "    columns = [\"Case ID\", \"Activity\", \"Complete Timestamp\"],\n",
    "    additional_columns = [\"Resource\", \"product\"],\n",
    "    datetime_format = \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "    task = constants.Task.NEXT_ACTIVITY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sepsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset processing\n",
    "dataset_name = \"sepsis\"\n",
    "data_processor = LogsDataProcessor(\n",
    "    name=dataset_name,\n",
    "    filepath=\"sepsis.xes\",\n",
    "    columns=[\"case:concept:name\", \"concept:name\", \"time:timestamp\"],  # specify the columns name containing case_id, activity name and timestamp\n",
    "    additional_columns=[\"org:group\"],\n",
    "    datetime_format=\"%Y-%m-%d %H:%M:%S%z\",\n",
    "    pool=4\n",
    ")\n",
    "data_processor.process_logs(task=constants.Task.NEXT_ACTIVITY, sort_temporally=False)\n",
    "\n",
    "# Garbage collection\n",
    "del data_processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for task next_activity...\n"
     ]
    }
   ],
   "source": [
    "# Prepare training examples for next activity prediction task\n",
    "train_token_x, train_token_y, train_additional_features, num_categorical_features, num_numerical_features = data_loader.prepare_data_next_activity(\n",
    "    train_df, x_word_dict, y_word_dict, max_case_length, full_df=pd.concat([train_df, test_df])\n",
    ")\n",
    "\n",
    "# Garbage collection\n",
    "del data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model for task next_activity...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\keras\\backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1121/1121 [==============================] - 45s 25ms/step - loss: 0.7815 - sparse_categorical_accuracy: 0.7412\n",
      "Epoch 2/10\n",
      "1121/1121 [==============================] - 31s 28ms/step - loss: 0.6285 - sparse_categorical_accuracy: 0.7998\n",
      "Epoch 3/10\n",
      "1121/1121 [==============================] - 29s 26ms/step - loss: 0.6111 - sparse_categorical_accuracy: 0.8054\n",
      "Epoch 4/10\n",
      "1121/1121 [==============================] - 28s 25ms/step - loss: 0.6053 - sparse_categorical_accuracy: 0.8060\n",
      "Epoch 5/10\n",
      "1121/1121 [==============================] - 30s 26ms/step - loss: 0.5979 - sparse_categorical_accuracy: 0.8063\n",
      "Epoch 6/10\n",
      "1121/1121 [==============================] - 43s 38ms/step - loss: 0.5960 - sparse_categorical_accuracy: 0.8042\n",
      "Epoch 7/10\n",
      "1121/1121 [==============================] - 31s 28ms/step - loss: 0.5927 - sparse_categorical_accuracy: 0.8073\n",
      "Epoch 8/10\n",
      "1121/1121 [==============================] - 34s 30ms/step - loss: 0.5885 - sparse_categorical_accuracy: 0.8039\n",
      "Epoch 9/10\n",
      "1121/1121 [==============================] - 33s 29ms/step - loss: 0.5846 - sparse_categorical_accuracy: 0.8071\n",
      "Epoch 10/10\n",
      "1121/1121 [==============================] - 33s 29ms/step - loss: 0.5806 - sparse_categorical_accuracy: 0.8072\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 12\n",
    "epochs = 10\n",
    "\n",
    "# Define and compile the model\n",
    "model = transformer.get_next_activity_model(\n",
    "    max_case_length=max_case_length,\n",
    "    vocab_size=vocab_size,\n",
    "    output_dim=num_output,\n",
    "    num_categorical_features=num_categorical_features,\n",
    "    num_numerical_features=num_numerical_features,\n",
    "    num_classes_list=num_classes_list,  # Pass the computed number of classes list\n",
    "    num_layers=1\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "if train_additional_features.shape[1] == 0:\n",
    "    model.fit([train_token_x], train_token_y, epochs=epochs, batch_size=batch_size)\n",
    "else:\n",
    "    model.fit([train_token_x, train_additional_features], train_token_y, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for task next_activity...\n",
      "29/29 [==============================] - 3s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for task next_activity...\n",
      "29/29 [==============================] - 1s 14ms/step\n",
      "Preparing data for task next_activity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 15ms/step\n",
      "Preparing data for task next_activity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 14ms/step\n",
      "Preparing data for task next_activity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 17ms/step\n",
      "Preparing data for task next_activity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 13ms/step\n",
      "Preparing data for task next_activity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step\n",
      "Preparing data for task next_activity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 100ms/step\n",
      "Preparing data for task next_activity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 102ms/step\n",
      "Preparing data for task next_activity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 117ms/step\n",
      "Preparing data for task next_activity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 104ms/step\n",
      "Preparing data for task next_activity...\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "     k  accuracy    fscore  precision    recall\n",
      "0    0  0.836245  0.789133   0.829856  0.836245\n",
      "1    1  0.664847  0.655426   0.647535  0.664847\n",
      "2    2  0.813873  0.777961   0.770799  0.813873\n",
      "3    3  0.826331  0.802044   0.801193  0.826331\n",
      "4    4  0.801418  0.764404   0.773232  0.801418\n",
      "5    5  0.855072  0.817633   0.801242  0.855072\n",
      "6    6  0.727273  0.656412   0.617211  0.727273\n",
      "7    7  0.615385  0.512821   0.461538  0.615385\n",
      "8    8  0.571429  0.485714   0.464286  0.571429\n",
      "9    9  0.750000  0.650000   0.583333  0.750000\n",
      "10  10  1.000000  1.000000   1.000000  1.000000\n",
      "11  11  1.000000  1.000000   1.000000  1.000000\n",
      "12  14  0.788489  0.742629   0.729185  0.788489\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the data loader for evaluation\n",
    "data_loader = LogsDataLoader(name=dataset_name)\n",
    "\n",
    "# Evaluate over all the prefixes (k) and save the results\n",
    "k, accuracies, fscores, precisions, recalls = [], [], [], [], []\n",
    "for i in range(max_case_length):\n",
    "    test_data_subset = test_df[test_df[\"k\"] == i]\n",
    "    if len(test_data_subset) > 0:\n",
    "        test_token_x, test_token_y, test_additional_features, _, _ = data_loader.prepare_data_next_activity(\n",
    "            test_data_subset, x_word_dict, y_word_dict, max_case_length, full_df=pd.concat([train_df, test_df])\n",
    "        )\n",
    "        \n",
    "        y_pred = np.argmax(model.predict([test_token_x, test_additional_features]), axis=1) if test_additional_features.shape[1] != 0 else np.argmax(model.predict([test_token_x]), axis=1)\n",
    "        accuracy = metrics.accuracy_score(test_token_y, y_pred)\n",
    "        precision, recall, fscore, _ = metrics.precision_recall_fscore_support(test_token_y, y_pred, average=\"weighted\")\n",
    "        \n",
    "        k.append(i)\n",
    "        accuracies.append(accuracy)\n",
    "        fscores.append(fscore)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "# Compute mean metrics over all k\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "mean_fscore = np.mean(fscores)\n",
    "mean_precision = np.mean(precisions)\n",
    "mean_recall = np.mean(recalls)\n",
    "\n",
    "# Append mean metrics to the lists\n",
    "k.append(max_case_length)\n",
    "accuracies.append(mean_accuracy)\n",
    "fscores.append(mean_fscore)\n",
    "precisions.append(mean_precision)\n",
    "recalls.append(mean_recall)\n",
    "\n",
    "# Display the results\n",
    "results_df = pd.DataFrame({\n",
    "    'k': k,\n",
    "    'accuracy': accuracies,\n",
    "    'fscore': fscores,\n",
    "    'precision': precisions,\n",
    "    'recall': recalls\n",
    "})\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy across all prefixes: 0.7884893237674948\n",
      "Average f-score across all prefixes: 0.7426289811324243\n",
      "Average precision across all prefixes: 0.7291853815016823\n",
      "Average recall across all prefixes: 0.7884893237674948\n"
     ]
    }
   ],
   "source": [
    "print('Average accuracy across all prefixes:', np.mean(accuracies))\n",
    "print('Average f-score across all prefixes:', np.mean(fscores))\n",
    "print('Average precision across all prefixes:', np.mean(precisions))\n",
    "print('Average recall across all prefixes:', np.mean(recalls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Next Time  -- Ignored for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpdesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and load data for the next activity task\n",
    "dataset_name = \"helpdesk\"\n",
    "data_loader, train_df, test_df, x_word_dict, y_word_dict, max_case_length, vocab_size, num_output, num_classes_list = process_and_load_data(\n",
    "    dataset_name = dataset_name,\n",
    "    filepath = \"helpdesk.csv\",\n",
    "    columns = [\"Case ID\", \"Activity\", \"Complete Timestamp\"],\n",
    "    additional_columns = [\"Resource\", \"product\"],\n",
    "    datetime_format = \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "    task = constants.Task.NEXT_TIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sepsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training examples for next time prediction task\n",
    "train_token_x, train_time_x, train_token_y, train_additional_features, time_scaler, y_scaler, num_categorical_features, num_numerical_features = data_loader.prepare_data_next_time(\n",
    "    train_df, x_word_dict, max_case_length, shuffle=True)\n",
    "\n",
    "# Garbage collection\n",
    "del data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Remaining Time -- Ignored for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpdesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sepsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and load data for the next time task\n",
    "dataset_name = \"sepsis\"\n",
    "data_loader, train_df, test_df, x_word_dict, y_word_dict, max_case_length, vocab_size, num_output, num_classes_list = process_and_load_data(\n",
    "    dataset_name, \"sepsis.xes\", [\"case:concept:name\", \"concept:name\", \"time:timestamp\"], [\"org:group\"], \"%Y-%m-%d %H:%M:%S%z\", constants.Task.NEXT_TIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
