{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from typing import List, Optional\n",
    "from numpy.typing import NDArray\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Tuple\n",
    "import pm4py\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from package.processtransformer.models import transformer\n",
    "from package.processtransformer.data.loader import LogsDataLoader\n",
    "from package.processtransformer.data.processor import LogsDataProcessor\n",
    "from package.processtransformer.constants import Feature_Type, Target, Temporal_Feature, Model_Architecture\n",
    "\n",
    "\n",
    "# Initialize data dir, if not exists\n",
    "if not os.path.exists(\"datasets\"): \n",
    "    os.mkdir(\"datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pipeline:\n",
    "    \n",
    "    def __init__(self, dataset_name: str, filepath: str, columns: List[str], additional_columns: Optional[Dict[Feature_Type, List[str]]],\n",
    "                 datetime_format: str, model_learning_rate: float, model_epochs: int, model_num_layers: int,\n",
    "                 input_columns: List[str], target_columns: Dict[str, Target], temporal_features: Dict[Temporal_Feature, bool],\n",
    "                 model_architecture = Model_Architecture):\n",
    "        self.dataset_name: str = dataset_name\n",
    "        self.filepath: str = filepath\n",
    "        self.columns: List[str] = columns\n",
    "        self.additional_columns: Optional[Dict[Feature_Type, List[str]]] = additional_columns\n",
    "        self.datetime_format: str = datetime_format\n",
    "        self.model_learning_rate: float = model_learning_rate\n",
    "        self.model_epochs: int = model_epochs\n",
    "        self.model_num_layers: int = model_num_layers\n",
    "        \n",
    "        self.target_columns: Dict[str, Target] = target_columns\n",
    "        for target_col in target_columns.keys():\n",
    "            if target_col == columns[1]:\n",
    "                self.target_columns[\"concept_name\"] = self.target_columns.pop(target_col)\n",
    "                break\n",
    "                \n",
    "        self.input_columns: List[str] = input_columns\n",
    "        for idx, input_col in enumerate(input_columns):\n",
    "            if input_col == columns[1]:\n",
    "                self.input_columns[idx] = \"concept_name\"\n",
    "                break\n",
    "        self.temporal_features: Dict[Temporal_Feature, bool] = temporal_features\n",
    "        self.model_architecture = model_architecture\n",
    "        \n",
    "        # self._model_id: str = (\n",
    "        #     f\"{dataset_name}\"\n",
    "        #     f\"##{'#'.join(self.columns)}\"\n",
    "        #     f\"##{'#'.join(self.additional_columns)}\"\n",
    "        #     f\"##{'#'.join(self.task.value)}\"\n",
    "        #     f\"##{self.model_learning_rate}\"\n",
    "        #     f\"##{self.model_epochs}\"\n",
    "        #     f\"##{self.model_num_layers}\")\n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        return (\n",
    "            f\"dataset_name: '{self.dataset_name}'\\n\"\n",
    "            f\"filepath: '{self.filepath}'\\n\"\n",
    "            f\"columns: '{self.columns}'\\n\"\n",
    "            f\"additional_columns: '{self.additional_columns}'\\n\"\n",
    "            f\"datetime_format: '{self.datetime_format}'\\n\"\n",
    "            f\"Model learning rate: '{self.model_learning_rate}'\\n\"\n",
    "            f\"Model Epochs: '{self.model_epochs}'\\n\"\n",
    "            f\"Number of Transformer Layers in Model: '{self.model_num_layers}'\\n\"\n",
    "            f\"Target columns: '{self.target_columns}'\\n\"\n",
    "            f\"Input columns: '{self.input_columns}'\\n\")\n",
    "        \n",
    "    \n",
    "    def save_as_csv(self):\n",
    "        dir_path = os.path.join( \"datasets\", self.dataset_name )\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        file_path = os.path.join( dir_path, self.filepath )\n",
    "        \n",
    "        \n",
    "        if file_path.endswith('.xes'):\n",
    "            print(\"Converting xes to csv file\")\n",
    "            df = pm4py.convert_to_dataframe(pm4py.read_xes(file_path)).astype(str)\n",
    "            df.to_csv(file_path.replace(\".xes\", \".csv\"), index=False)\n",
    "        elif file_path.endswith('.csv'):\n",
    "            print(\"Input file already has csv format\")\n",
    "            \n",
    "    \n",
    "    # preprocess the event log and save the train-test split as csv files\n",
    "    def preprocess_log(self) -> List[int]:\n",
    "        data_processor = LogsDataProcessor(\n",
    "            name=self.dataset_name,\n",
    "            filepath=self.filepath,\n",
    "            columns=self.columns,\n",
    "            additional_columns=self.additional_columns,  # Add all additional columns here, first all categorical, then all numerical features\n",
    "            input_columns=self.input_columns,\n",
    "            target_columns=self.target_columns,\n",
    "            datetime_format=self.datetime_format,\n",
    "            temporal_features=self.temporal_features,\n",
    "            pool=4\n",
    "        )\n",
    "        \n",
    "        # TODO: sanitize columns\n",
    "        # self.columns = [data_processor.sanitize_filename(col) for col in self.columns]\n",
    "        \n",
    "        # self.additional_columns = {\n",
    "        #                         feature_type: [data_processor.sanitize_filename(feature) for feature in feature_lst] for feature_type,\n",
    "        #                         feature_lst in self.additional_columns.items()\n",
    "        #                         } if len(self.additional_columns)>0 else self.additional_columns\n",
    "        self.target_columns = {data_processor.sanitize_filename(feature, self.columns): target for feature, target in self.target_columns.items()}\n",
    "        self.input_columns = [data_processor.sanitize_filename(col, self.columns) for col in self.input_columns]\n",
    "        self.columns = [data_processor.sanitize_filename(col, self.columns) for col in self.columns]\n",
    "        \n",
    "        # Preprocess the event log and make train-test split\n",
    "        data_processor.process_logs()\n",
    "        # flatten self.additional_columns to get all used features\n",
    "        self.additional_columns = data_processor.additional_columns\n",
    "        self.used_features = [item for sublist in self.additional_columns.values() for item in sublist]\n",
    "        \n",
    "        \n",
    "        # TODO: Compute the number of unique classes in each categorical column\n",
    "        # train_df = pd.read_csv(os.path.join(\"datasets\", self.dataset_name, \"processed\", f\"{self._preprocessing_id}_train.csv\"))\n",
    "        # num_classes_list = data_processor._compute_num_classes(train_df)\n",
    "        \n",
    "        # return num_classes_list\n",
    "    \n",
    "    \n",
    "    # load the preprocessed train-test split from the csv files\n",
    "    def load_data(self) -> Tuple [ LogsDataLoader, Dict[str, pd.DataFrame], Dict[str, pd.DataFrame], Dict[str, Dict[str, int]], Dict[Feature_Type, List[str]] ]:\n",
    "        data_loader = LogsDataLoader(name=self.dataset_name, input_columns=self.input_columns,\n",
    "                                     target_columns=self.target_columns, temporal_features=self.temporal_features)\n",
    "        train_dfs, test_dfs, word_dicts, feature_type_dict = data_loader.load_data()\n",
    "        word_dicts = dict(sorted(word_dicts.items()))\n",
    "        return data_loader, train_dfs, test_dfs, word_dicts, feature_type_dict\n",
    "    \n",
    "    \n",
    "    def prepare_data( self, data_loader, dfs: Dict[str, pd.DataFrame] ) -> Tuple[ Dict[str, NDArray[np.float32]], Dict[str, NDArray[np.float32]], Dict[str, NDArray[np.float32]], int ]:\n",
    "        print(\"Preparing data...\")\n",
    "        \n",
    "        # initialize token dicts\n",
    "        x_token_dict, y_token_dict = {}, {}\n",
    "        \n",
    "        # loop over all feature dfs\n",
    "        for idx, (feature, feature_df) in enumerate(dfs.items()):\n",
    "            \n",
    "            if idx == 0:\n",
    "                (x_tokens, y_tokens, max_case_length\n",
    "                ) = data_loader.prepare_data(feature=feature, df=feature_df, max_case_length=True)\n",
    "            else:\n",
    "                x_tokens, y_tokens = data_loader.prepare_data(feature=feature, df=feature_df)\n",
    "            \n",
    "            # update x_token_dict\n",
    "            x_token_dict.update(x_tokens)\n",
    "            y_token_dict.update(y_tokens)\n",
    "                \n",
    "            # # if feature is target column\n",
    "            # if feature in self.target_columns.keys():\n",
    "            #     # update y_token_dict with next_feature as target\n",
    "            #     if self.target_columns[feature] == Target.NEXT_FEATURE:\n",
    "            #         y_token_dict.update(y_next_tokens)\n",
    "            #     # update y_token_dict with last_feature as target\n",
    "            #     elif self.target_columns[feature] == Target.LAST_FEATURE:\n",
    "            #         y_token_dict.update(y_last_tokens)\n",
    "            #     else: raise ValueError(\"Target type not defined\")\n",
    "        # sort dicts\n",
    "        x_token_dict = dict(sorted(x_token_dict.items()))\n",
    "        y_token_dict = dict(sorted(y_token_dict.items()))\n",
    "\n",
    "        return x_token_dict, y_token_dict, max_case_length\n",
    "    \n",
    "    \n",
    "    # TODO: implement training reporting for numerica featurey\n",
    "    # Prepare data and train the model\n",
    "    def train(self,\n",
    "            feature_type_dict: Dict[Feature_Type, List[str]],\n",
    "            train_token_dict_x: Dict[str, NDArray[np.float32]],\n",
    "            train_token_dict_y: Dict[str, NDArray[np.float32]],\n",
    "            word_dicts: Dict[str, Dict[str, int]],\n",
    "            max_case_length: int,\n",
    "            validation_split: float = 0.2  # Fraction of the training data to be used for validation\n",
    "            ) -> tf.keras.Model:\n",
    "\n",
    "        # Ensure that input columns and dictionaries are sorted\n",
    "        self.input_columns.sort()\n",
    "        self.target_columns = dict(sorted(self.target_columns.items()))\n",
    "        train_token_dict_x = dict(sorted(train_token_dict_x.items()))\n",
    "        train_token_dict_y = dict(sorted(train_token_dict_y.items()))\n",
    "        word_dicts = dict(sorted(word_dicts.items()))\n",
    "\n",
    "        batch_size = 12\n",
    "\n",
    "        # Define and compile the model\n",
    "        model = transformer.get_model(\n",
    "            input_columns=self.input_columns,\n",
    "            target_columns=self.target_columns,\n",
    "            word_dicts=word_dicts,\n",
    "            max_case_length=max_case_length,\n",
    "            feature_type_dict=feature_type_dict,\n",
    "            temporal_features=self.temporal_features,\n",
    "            model_architecture=self.model_architecture\n",
    "        )\n",
    "\n",
    "        # Check the number of target columns to determine if it's a multi-task or single-task problem\n",
    "        if len(self.target_columns) > 1:\n",
    "            print(\"Using Multi-Task Learning Setup\")\n",
    "            # Multi-task scenario: use MultiTaskLoss\n",
    "            # Define the loss functions for each output and whether they are regression tasks\n",
    "            losses = []\n",
    "            is_regression = []\n",
    "\n",
    "            for feature, target in self.target_columns.items():\n",
    "                if feature_type_dict[Feature_Type.CATEGORICAL]:\n",
    "                    losses.append(tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False))\n",
    "                    is_regression.append(False)  # False for classification tasks\n",
    "                if feature_type_dict[Feature_Type.TIMESTAMP]:\n",
    "                    losses.append(tf.keras.losses.MeanSquaredError())\n",
    "                    is_regression.append(True)  # True for regression tasks\n",
    "\n",
    "            # Create the MultiTaskLoss layer\n",
    "            multitask_loss_layer = transformer.MultiTaskLoss(is_regression=is_regression, reduction='sum')\n",
    "\n",
    "            # Convert losses to a tensor and apply the MultiTaskLoss\n",
    "            def combined_loss(y_true, y_pred):\n",
    "                loss_values = []\n",
    "                for i in range(len(losses)):\n",
    "                    loss_value = losses[i](y_true[i], y_pred[i])\n",
    "                    loss_values.append(loss_value)\n",
    "\n",
    "                loss_tensor = tf.stack(loss_values)\n",
    "                return multitask_loss_layer(loss_tensor)\n",
    "\n",
    "            # Compile the model with the combined loss\n",
    "            model.compile(\n",
    "                optimizer=tf.keras.optimizers.Adam(self.model_learning_rate),\n",
    "                loss=combined_loss,\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            print(\"Using Single-Task Learning Setup\")\n",
    "            # Single-task scenario: use standard loss\n",
    "            target_feature = list(self.target_columns.keys())[0]\n",
    "            # get feature_type\n",
    "            for feature_type, feature_lst in self.additional_columns.items():\n",
    "                if target_feature in feature_lst: break\n",
    "                \n",
    "            # if target is categorical\n",
    "            if feature_type is Feature_Type.CATEGORICAL:\n",
    "                # Classification task\n",
    "                model.compile(\n",
    "                    optimizer=tf.keras.optimizers.Adam(self.model_learning_rate),\n",
    "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "                )\n",
    "                \n",
    "            # if target is temporal\n",
    "            elif feature_type is Feature_Type.TIMESTAMP:\n",
    "                # Regression task\n",
    "                model.compile(\n",
    "                    optimizer=tf.keras.optimizers.Adam(self.model_learning_rate),\n",
    "                    loss=tf.keras.losses.MeanSquaredError(),\n",
    "                    metrics=[tf.keras.metrics.MeanAbsoluteError()]\n",
    "                )\n",
    "\n",
    "        # Train-validation split\n",
    "        first_key = next(iter(train_token_dict_x.keys()))\n",
    "        n_samples = train_token_dict_x[first_key].shape[0]\n",
    "        indices = np.arange(n_samples)\n",
    "        train_indices, val_indices = train_test_split(indices, test_size=validation_split, random_state=42)\n",
    "\n",
    "        # Split the data\n",
    "        train_token_dict_x_split = {key: x_data[train_indices] for key, x_data in train_token_dict_x.items()}\n",
    "        val_token_dict_x_split = {key: x_data[val_indices] for key, x_data in train_token_dict_x.items()}\n",
    "        train_token_dict_y_split = {key: y_data[train_indices] for key, y_data in train_token_dict_y.items()}\n",
    "        val_token_dict_y_split = {key: y_data[val_indices] for key, y_data in train_token_dict_y.items()}\n",
    "\n",
    "        # Define callbacks\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True,\n",
    "            min_delta=0.001\n",
    "        )\n",
    "\n",
    "        model_specs_dir = os.path.join(\"datasets\", self.dataset_name, \"model_specs\")\n",
    "        os.makedirs(model_specs_dir, exist_ok=True)\n",
    "\n",
    "        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(model_specs_dir, \"best_model.h5\"),\n",
    "            save_weights_only=True,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\", save_best_only=True)\n",
    "\n",
    "        # Train the model\n",
    "        print(\"Training...\")\n",
    "        history = model.fit(\n",
    "            x=train_token_dict_x_split,\n",
    "            y=train_token_dict_y_split,\n",
    "            validation_data=(val_token_dict_x_split, val_token_dict_y_split),\n",
    "            epochs=self.model_epochs, batch_size=batch_size, shuffle=True,\n",
    "            callbacks=[early_stopping, model_checkpoint_callback]\n",
    "        )\n",
    "\n",
    "        # Plot training loss\n",
    "        self._plot_training_loss(history)\n",
    "        return model\n",
    "            \n",
    "            \n",
    "    # helper function for plotting the training loss\n",
    "    def _plot_training_loss(self, history):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        if 'val_loss' in history.history:\n",
    "            plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss Over Epochs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "    def evaluate(self, model, data_loader: LogsDataLoader, test_dfs: Dict[str, pd.DataFrame], max_case_length: int):\n",
    "        print(\"Evaluating...\")\n",
    "\n",
    "        # Prepare lists to store evaluation metrics\n",
    "        k, accuracies, fscores, precisions, recalls, weights = {}, {}, {}, {}, {}, {}\n",
    "        mae, mse, rmse, r2 = {}, {}, {}, {}\n",
    "        \n",
    "        for target_col in self.target_columns.keys():\n",
    "            for feature_type, feature_lst in self.additional_columns.items():\n",
    "                if target_col in feature_lst:\n",
    "                    k.update({target_col: []})\n",
    "                    weights.update({target_col: []})\n",
    "                    \n",
    "                    if feature_type is Feature_Type.CATEGORICAL:\n",
    "                        accuracies.update({target_col: []})\n",
    "                        fscores.update({target_col: []})\n",
    "                        precisions.update({target_col: []})\n",
    "                        recalls.update({target_col: []})\n",
    "                    elif feature_type is Feature_Type.TIMESTAMP:\n",
    "                        mae.update({target_col: []})\n",
    "                        mse.update({target_col: []})\n",
    "                        rmse.update({target_col: []})\n",
    "                        r2.update({target_col: []})\n",
    "\n",
    "        # Calculate total number of samples\n",
    "        total_samples = len(list(test_dfs.values())[0])\n",
    "\n",
    "        # Iterate over all prefixes (k)\n",
    "        for i in range(1, max_case_length + 1):\n",
    "            print(\"Prefix length: \" + str(i))\n",
    "            test_data_subsets = {}\n",
    "\n",
    "            for key, df in test_dfs.items():\n",
    "                if (Feature_Type.TIMESTAMP in self.additional_columns\n",
    "                        and key in self.additional_columns[Feature_Type.TIMESTAMP]):\n",
    "                    prefix_str = f\"{key}##Prefix Length\"\n",
    "                else:\n",
    "                    prefix_str = \"Prefix Length\"\n",
    "                filtered_df = df[df[prefix_str] == i]\n",
    "                test_data_subsets.update({key: filtered_df})\n",
    "\n",
    "            if len(test_data_subsets[self.input_columns[0]]) > 0:\n",
    "\n",
    "                # initialize token dicts\n",
    "                x_token_dict, y_token_dict = {}, {}\n",
    "\n",
    "                # Prepare the test data\n",
    "                for feature, test_data_subset in test_data_subsets.items():\n",
    "                    # prepare data of subset batch\n",
    "                    x_tokens, y_tokens = data_loader.prepare_data(feature=feature, df=test_data_subset)\n",
    "\n",
    "                    # update x_token_dict and y_token_dict\n",
    "                    x_token_dict.update(x_tokens)\n",
    "                    y_token_dict.update(y_tokens)\n",
    "\n",
    "                # Filter x_token_dict and y_token_dict for input and target columns\n",
    "                x_token_dict = {key: value for key, value in x_token_dict.items()}\n",
    "                y_token_dict = {key: value for key, value in y_token_dict.items()}\n",
    "\n",
    "                # Make predictions\n",
    "                predictions = model.predict(x_token_dict)\n",
    "                \n",
    "                # Handle multiple outputs for multitask learning\n",
    "                if len(self.target_columns) > 1:\n",
    "                    result_dict = dict(zip(self.target_columns.keys(), predictions))\n",
    "                else:\n",
    "                    result_dict = dict(zip(self.target_columns.keys(), [predictions]))\n",
    "\n",
    "                # Compute metrics\n",
    "                for feature, result in result_dict.items():\n",
    "                    for feature_type, feature_lst in self.additional_columns.items():\n",
    "                        if feature in feature_lst:\n",
    "                            if feature_type is Feature_Type.CATEGORICAL:\n",
    "                                result = np.argmax(result, axis=1)\n",
    "                                accuracy = metrics.accuracy_score(y_token_dict[f\"output_{feature}\"], result)\n",
    "                                precision, recall, fscore, _ = metrics.precision_recall_fscore_support(\n",
    "                                    y_token_dict[f\"output_{feature}\"], result, average=\"weighted\", zero_division=0)\n",
    "                                weight = len(test_data_subsets[feature]) / total_samples\n",
    "\n",
    "                                k[feature].append(i)\n",
    "                                accuracies[feature].append(accuracy)\n",
    "                                fscores[feature].append(fscore)\n",
    "                                precisions[feature].append(precision)\n",
    "                                recalls[feature].append(recall)\n",
    "                                weights[feature].append(weight)\n",
    "                            \n",
    "                            elif feature_type is Feature_Type.TIMESTAMP:\n",
    "                                mae_value = metrics.mean_absolute_error(y_token_dict[f\"output_{feature}\"], result)\n",
    "                                mse_value = metrics.mean_squared_error(y_token_dict[f\"output_{feature}\"], result)\n",
    "                                rmse_value = np.sqrt(mse_value)\n",
    "                                r2_value = metrics.r2_score(y_token_dict[f\"output_{feature}\"], result)\n",
    "                                weight = len(test_data_subsets[feature]) / total_samples\n",
    "\n",
    "                                k[feature].append(i)\n",
    "                                mae[feature].append(mae_value)\n",
    "                                mse[feature].append(mse_value)\n",
    "                                rmse[feature].append(rmse_value)\n",
    "                                r2[feature].append(r2_value)\n",
    "                                weights[feature].append(weight)\n",
    "\n",
    "        for target_col in self.target_columns.keys():\n",
    "            for feature_type, feature_lst in self.additional_columns.items():\n",
    "                if target_col in feature_lst:\n",
    "                    if feature_type is Feature_Type.CATEGORICAL:\n",
    "                        # Compute weighted mean metrics over all k\n",
    "                        weighted_accuracy = np.average(accuracies[target_col], weights=weights[target_col])\n",
    "                        weighted_fscore = np.average(fscores[target_col], weights=weights[target_col])\n",
    "                        weighted_precision = np.average(precisions[target_col], weights=weights[target_col])\n",
    "                        weighted_recall = np.average(recalls[target_col], weights=weights[target_col])\n",
    "                        # Append weighted mean metrics to the lists\n",
    "                        weights[target_col].append(\"\")\n",
    "                        k[target_col].append(\"Weighted Mean\")\n",
    "                        accuracies[target_col].append(weighted_accuracy)\n",
    "                        fscores[target_col].append(weighted_fscore)\n",
    "                        precisions[target_col].append(weighted_precision)\n",
    "                        recalls[target_col].append(weighted_recall)\n",
    "                        # Create a DataFrame to display the results\n",
    "                        print(f\"Results for {target_col}\")\n",
    "                        results_df = pd.DataFrame({\n",
    "                            'k': k[target_col],\n",
    "                            'weight': weights[target_col],\n",
    "                            'accuracy': accuracies[target_col],\n",
    "                            'fscore': fscores[target_col],\n",
    "                            'precision': precisions[target_col],\n",
    "                            'recall': recalls[target_col]\n",
    "                        })\n",
    "                        # Display the results\n",
    "                        print(results_df)\n",
    "                    \n",
    "                    elif feature_type is Feature_Type.TIMESTAMP:\n",
    "                        # Compute weighted mean metrics over all k\n",
    "                        weighted_mae = np.average(mae[target_col], weights=weights[target_col])\n",
    "                        weighted_mse = np.average(mse[target_col], weights=weights[target_col])\n",
    "                        weighted_rmse = np.average(rmse[target_col], weights=weights[target_col])\n",
    "                        weighted_r2 = np.average(r2[target_col], weights=weights[target_col])\n",
    "                        # Append weighted mean metrics to the lists\n",
    "                        weights[target_col].append(\"\")\n",
    "                        k[target_col].append(\"Weighted Mean\")\n",
    "                        mae[target_col].append(weighted_mae)\n",
    "                        mse[target_col].append(weighted_mse)\n",
    "                        rmse[target_col].append(weighted_rmse)\n",
    "                        r2[target_col].append(weighted_r2)\n",
    "                        # Create a DataFrame to display the results\n",
    "                        print(f\"Results for {target_col}\")\n",
    "                        results_df = pd.DataFrame({\n",
    "                            'k': k[target_col],\n",
    "                            'weight': weights[target_col],\n",
    "                            'mae': mae[target_col],\n",
    "                            'mse': mse[target_col],\n",
    "                            'rmse': rmse[target_col],\n",
    "                            'r2': r2[target_col]\n",
    "                        })\n",
    "                        # Display the results\n",
    "                        print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper Functions ###\n",
    "\n",
    "# helper function to save xes file as csv\n",
    "def save_csv(args):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(**args)  # Examples: \"concept:name\", \"Resource\"\n",
    "    pipe.save_as_csv()\n",
    "    \n",
    "\n",
    "# helper function: do only preprocessing on data\n",
    "def preprocess(additional_columns, input_columns, target_columns):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(\n",
    "        dataset_name = \"helpdesk\",\n",
    "        filepath = \"helpdesk.csv\",\n",
    "        columns = [\"Case ID\", \"Activity\", \"Complete Timestamp\"],\n",
    "        additional_columns = additional_columns,\n",
    "        datetime_format = \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "        model_learning_rate = 0.001,\n",
    "        model_epochs = 1,\n",
    "        model_num_layers = 1,\n",
    "        target_columns=target_columns,\n",
    "        input_columns=input_columns)  # Examples: \"concept_name\", \"Resource\"\n",
    "    # preprocess data\n",
    "    pipe.preprocess_log()\n",
    "\n",
    "\n",
    "# helper function\n",
    "def run(args):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(**args)  # Examples: \"concept:name\", \"Resource\"\n",
    "\n",
    "    # print parameters\n",
    "    print(pipe)\n",
    "\n",
    "    # preprocess data\n",
    "    pipe.preprocess_log()\n",
    "\n",
    "    # load data\n",
    "    data_loader, train_dfs, test_dfs, word_dicts, feature_type_dict = pipe.load_data()\n",
    "\n",
    "    # prepare data\n",
    "    train_token_dict_x, train_token_dict_y, max_case_length = pipe.prepare_data(data_loader, train_dfs)\n",
    "\n",
    "    # train the model\n",
    "    model = pipe.train(\n",
    "                feature_type_dict = feature_type_dict,\n",
    "                train_token_dict_x = train_token_dict_x,\n",
    "                train_token_dict_y = train_token_dict_y,\n",
    "                word_dicts = word_dicts,\n",
    "                max_case_length = max_case_length\n",
    "                )\n",
    "\n",
    "    # evaluate the model\n",
    "    pipe.evaluate(model, data_loader, test_dfs, max_case_length)\n",
    "    print(\"\")\n",
    "    print(\"======================================\")\n",
    "    print(\"======================================\")\n",
    "    \n",
    "    \n",
    "# function for testing out code\n",
    "def test(args):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(**args)  # Examples: \"concept:name\", \"Resource\"\n",
    "\n",
    "    # print parameters\n",
    "    print(pipe)\n",
    "\n",
    "    # preprocess data\n",
    "    pipe.preprocess_log()\n",
    "\n",
    "    # load data\n",
    "    data_loader, train_dfs, test_dfs, word_dicts, feature_type_dict = pipe.load_data()\n",
    "\n",
    "    # prepare data\n",
    "    train_token_dict_x, train_token_dict_y, max_case_length = pipe.prepare_data(data_loader, train_dfs)\n",
    "\n",
    "    # # train the model\n",
    "    # model = pipe.train(\n",
    "    #             feature_type_dict = feature_type_dict,\n",
    "    #             train_token_dict_x = train_token_dict_x,\n",
    "    #             train_token_dict_y = train_token_dict_y,\n",
    "    #             word_dicts = word_dicts,\n",
    "    #             max_case_length = max_case_length\n",
    "    #             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Args & Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: 'helpdesk'\n",
      "filepath: 'helpdesk.csv'\n",
      "columns: '['Case ID', 'Activity', 'Complete Timestamp']'\n",
      "additional_columns: '{<Feature_Type.CATEGORICAL: 'categorical'>: ['Resource']}'\n",
      "datetime_format: '%Y-%m-%d %H:%M:%S.%f'\n",
      "Model learning rate: '0.001'\n",
      "Model Epochs: '20'\n",
      "Number of Transformer Layers in Model: '1'\n",
      "Target columns: '{'concept_name': <Target.NEXT_FEATURE: 'next_feature'>}'\n",
      "Input columns: '['concept_name', 'Resource', 'Complete Timestamp']'\n",
      "\n",
      "All processed files for current spec found. Preprocessing skipped.\n",
      "Loading data from preprocessed train-test split...\n",
      "['Resource', 'concept_name', 'time_timestamp']\n",
      "Preparing data...\n",
      "Creating model...\n",
      "Training...\n",
      "Epoch 1/20\n",
      "896/896 [==============================] - 39s 36ms/step - loss: 0.8070 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.6263 - val_sparse_categorical_accuracy: 0.8061\n",
      "Epoch 2/20\n",
      "896/896 [==============================] - 32s 36ms/step - loss: 0.6415 - sparse_categorical_accuracy: 0.8042 - val_loss: 0.6096 - val_sparse_categorical_accuracy: 0.8083\n",
      "Epoch 3/20\n",
      "896/896 [==============================] - 34s 38ms/step - loss: 0.6290 - sparse_categorical_accuracy: 0.8066 - val_loss: 0.6046 - val_sparse_categorical_accuracy: 0.8076\n",
      "Epoch 4/20\n",
      "896/896 [==============================] - 36s 41ms/step - loss: 0.6134 - sparse_categorical_accuracy: 0.8093 - val_loss: 0.6108 - val_sparse_categorical_accuracy: 0.8087\n",
      "Epoch 5/20\n",
      "462/896 [==============>...............] - ETA: 21s - loss: 0.6121 - sparse_categorical_accuracy: 0.8111"
     ]
    }
   ],
   "source": [
    "# args_helpdesk = {\n",
    "#         \"dataset_name\": \"helpdesk\",\n",
    "#         \"filepath\": \"helpdesk.csv\",\n",
    "#         \"columns\": [\"Case ID\", \"Activity\", \"Complete Timestamp\"],\n",
    "#         \"additional_columns\": {},\n",
    "#         \"datetime_format\": \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "#         \"model_learning_rate\": 0.001,\n",
    "#         \"model_epochs\": 30,\n",
    "#         \"model_num_layers\": 1,\n",
    "#         \"target_columns\": {\"Activity\": Target.NEXT_FEATURE},\n",
    "#         \"input_columns\": [\"Activity\"],\n",
    "#         \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: False, Temporal_Feature.HOUR_OF_DAY: False},\n",
    "#         \"model_architecture\": Model_Architecture.COMMON_POSEMBS_TRANSF\n",
    "#         }\n",
    "\n",
    "args_helpdesk = {\n",
    "        \"dataset_name\": \"helpdesk\",\n",
    "        \"filepath\": \"helpdesk.csv\",\n",
    "        \"columns\": [\"Case ID\", \"Activity\", \"Complete Timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"Resource\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 20,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"Activity\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"Activity\", \"Resource\", \"Complete Timestamp\"],\n",
    "        \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: True, Temporal_Feature.HOUR_OF_DAY: True},\n",
    "        \"model_architecture\": Model_Architecture.COMMON_POSEMBS_TRANSF\n",
    "        }\n",
    "\n",
    "# args_helpdesk = {\n",
    "#         \"dataset_name\": \"helpdesk\",\n",
    "#         \"filepath\": \"helpdesk.csv\",\n",
    "#         \"columns\": [\"Case ID\", \"Activity\", \"Complete Timestamp\"],\n",
    "#         \"additional_columns\": {Feature_Type.CATEGORICAL: [\"Resource\"]},\n",
    "#         \"datetime_format\": \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "#         \"model_learning_rate\": 0.001,\n",
    "#         \"model_epochs\": 1,\n",
    "#         \"model_num_layers\": 1,\n",
    "#         \"target_columns\": {\"Activity\": Target.NEXT_FEATURE},\n",
    "#         \"input_columns\": [\"Activity\", \"Resource\"],\n",
    "#         \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: False, Temporal_Feature.HOUR_OF_DAY: False}\n",
    "#         }\n",
    "\n",
    "args_sepsis = {\n",
    "        \"dataset_name\": \"sepsis\",\n",
    "        \"filepath\": \"sepsis.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:group\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S%z\",\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 1,\n",
    "        \"model_num_layers\": 10,\n",
    "        \"target_columns\": {\"concept:name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept:name\", \"org:group\"],\n",
    "        \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: True, Temporal_Feature.HOUR_OF_DAY: True}\n",
    "        }\n",
    "\n",
    "args_bpi_2012 = {\n",
    "        \"dataset_name\": \"bpi_2012\",\n",
    "        \"filepath\": \"BPI_Challenge_2012.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:resource\"]},\n",
    "        \"datetime_format\": None,\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 10,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"concept:name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept:name\", \"org:resource\"]\n",
    "        }\n",
    "\n",
    "args_bpi_2013 = {\n",
    "        \"dataset_name\": \"bpi_2013\",\n",
    "        \"filepath\": \"BPI_Challenge_2013_incidents.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:resource\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S%z\",\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 2,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"concept:name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept:name\", \"org:resource\"]\n",
    "        }\n",
    "\n",
    "args_bpi_2015_1 = {\n",
    "        \"dataset_name\": \"bpi_2015_1\",\n",
    "        \"filepath\": \"BPIC15_1.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:resource\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S%z\",\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 2,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"concept_name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept_name\", \"org_resource\"]\n",
    "        }\n",
    "\n",
    "\n",
    "run(args_helpdesk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change settings and run again\n",
    "\n",
    "# args_bpi_2012[\"additional_columns\"] = {}\n",
    "# args_bpi_2012[\"input_columns\"] = [\"concept:name\"]\n",
    "# run(args_bpi_2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run(additional_columns={Feature_Type.CATEGORICAL: [\"Resource\"]}, input_columns=[\"Activity\", \"Resource\"], target_columns=[\"Activity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run(additional_columns={Feature_Type.CATEGORICAL: [\"Resource\"]}, input_columns=[\"Activity\", \"Resource\"], target_columns=[\"Activity\", \"Resource\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
