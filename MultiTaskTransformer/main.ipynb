{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler\n",
    "from typing import List, Optional\n",
    "from numpy.typing import NDArray\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Tuple\n",
    "import pm4py\n",
    "from package import transformer\n",
    "from package.loader import LogsDataLoader\n",
    "from package.processor import LogsDataProcessor, masked_standard_scaler, masked_min_max_scaler\n",
    "from package.constants import Feature_Type, Target, Temporal_Feature, Model_Architecture\n",
    "\n",
    "\n",
    "# Initialize data dir, if not exists\n",
    "if not os.path.exists(\"datasets\"): \n",
    "    os.mkdir(\"datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pipeline:\n",
    "    \n",
    "    def __init__(self, dataset_name: str, filepath: str, columns: List[str], additional_columns: Optional[Dict[Feature_Type, List[str]]],\n",
    "                 datetime_format: str, model_epochs: int, model_num_layers: int,\n",
    "                 input_columns: List[str], target_columns: Dict[str, Target], temporal_features: Dict[Temporal_Feature, bool],\n",
    "                 model_architecture = Model_Architecture):\n",
    "        self.dataset_name: str = dataset_name\n",
    "        self.filepath: str = filepath\n",
    "        self.columns: List[str] = columns\n",
    "        self.additional_columns: Optional[Dict[Feature_Type, List[str]]] = additional_columns\n",
    "        self.datetime_format: str = datetime_format\n",
    "        self.model_epochs: int = model_epochs\n",
    "        self.model_num_layers: int = model_num_layers\n",
    "        \n",
    "        self.target_columns: Dict[str, Target] = target_columns\n",
    "        for target_col in target_columns.keys():\n",
    "            if target_col == columns[1]:\n",
    "                self.target_columns[\"concept_name\"] = self.target_columns.pop(target_col)\n",
    "                break\n",
    "                \n",
    "        self.input_columns: List[str] = input_columns\n",
    "        for idx, input_col in enumerate(input_columns):\n",
    "            if input_col == columns[1]:\n",
    "                self.input_columns[idx] = \"concept_name\"\n",
    "                break\n",
    "        self.temporal_features: Dict[Temporal_Feature, bool] = temporal_features\n",
    "        self.model_architecture = model_architecture\n",
    "        \n",
    "    def __str__(self):\n",
    "        return (\n",
    "            f\"dataset_name: '{self.dataset_name}'\\n\"\n",
    "            f\"filepath: '{self.filepath}'\\n\"\n",
    "            f\"columns: '{self.columns}'\\n\"\n",
    "            f\"additional_columns: '{self.additional_columns}'\\n\"\n",
    "            f\"datetime_format: '{self.datetime_format}'\\n\"\n",
    "            f\"Model Epochs: '{self.model_epochs}'\\n\"\n",
    "            f\"Number of Transformer Layers in Model: '{self.model_num_layers}'\\n\"\n",
    "            f\"Target columns: '{self.target_columns}'\\n\"\n",
    "            f\"Input columns: '{self.input_columns}'\\n\")\n",
    "        \n",
    "    \n",
    "    def save_as_csv(self):\n",
    "        dir_path = os.path.join( \"datasets\", self.dataset_name )\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        file_path = os.path.join( dir_path, self.filepath )\n",
    "        \n",
    "        \n",
    "        if file_path.endswith('.xes'):\n",
    "            print(\"Converting xes to csv file\")\n",
    "            df = pm4py.convert_to_dataframe(pm4py.read_xes(file_path)).astype(str)\n",
    "            df.to_csv(file_path.replace(\".xes\", \".csv\"), index=False)\n",
    "        elif file_path.endswith('.csv'):\n",
    "            print(\"Input file already has csv format\")\n",
    "            \n",
    "    \n",
    "    # preprocess the event log and save the train-test split as csv files\n",
    "    def preprocess_log(self) -> List[int]:\n",
    "        data_processor = LogsDataProcessor(\n",
    "            name=self.dataset_name,\n",
    "            filepath=self.filepath,\n",
    "            columns=self.columns,\n",
    "            additional_columns=self.additional_columns,  # Add all additional columns here, first all categorical, then all numerical features\n",
    "            input_columns=self.input_columns,\n",
    "            target_columns=self.target_columns,\n",
    "            datetime_format=self.datetime_format,\n",
    "            temporal_features=self.temporal_features,\n",
    "            pool=4\n",
    "        )\n",
    "        \n",
    "        # TODO: sanitize columns\n",
    "        # self.columns = [data_processor.sanitize_filename(col) for col in self.columns]\n",
    "        \n",
    "        # self.additional_columns = {\n",
    "        #                         feature_type: [data_processor.sanitize_filename(feature) for feature in feature_lst] for feature_type,\n",
    "        #                         feature_lst in self.additional_columns.items()\n",
    "        #                         } if len(self.additional_columns)>0 else self.additional_columns\n",
    "        self.target_columns = {data_processor.sanitize_filename(feature, self.columns): target for feature, target in self.target_columns.items()}\n",
    "        self.input_columns = [data_processor.sanitize_filename(col, self.columns) for col in self.input_columns]\n",
    "        self.columns = [data_processor.sanitize_filename(col, self.columns) for col in self.columns]\n",
    "        \n",
    "        # Preprocess the event log and make train-test split\n",
    "        data_processor.process_logs()\n",
    "        # flatten self.additional_columns to get all used features\n",
    "        self.additional_columns = data_processor.additional_columns\n",
    "        self.used_features = [item for sublist in self.additional_columns.values() for item in sublist]\n",
    "        \n",
    "        \n",
    "        # TODO: Compute the number of unique classes in each categorical column\n",
    "        # train_df = pd.read_csv(os.path.join(\"datasets\", self.dataset_name, \"processed\", f\"{self._preprocessing_id}_train.csv\"))\n",
    "        # num_classes_list = data_processor._compute_num_classes(train_df)\n",
    "        \n",
    "        # return num_classes_list\n",
    "    \n",
    "    \n",
    "    # load the preprocessed train-test split from the csv files\n",
    "    def load_data(self) -> Tuple [ LogsDataLoader, Dict[str, pd.DataFrame], Dict[str, pd.DataFrame], Dict[str, Dict[str, int]], Dict[Feature_Type, List[str]] ]:\n",
    "        data_loader = LogsDataLoader(name=self.dataset_name, input_columns=self.input_columns,\n",
    "                                     target_columns=self.target_columns, temporal_features=self.temporal_features)\n",
    "        train_dfs, test_dfs, word_dicts, feature_type_dict, mask = data_loader.load_data()\n",
    "        word_dicts = dict(sorted(word_dicts.items()))\n",
    "        return data_loader, train_dfs, test_dfs, word_dicts, feature_type_dict, mask\n",
    "    \n",
    "    \n",
    "    def prepare_data( self, data_loader, dfs: Dict[str, pd.DataFrame], x_scaler=None, y_scaler=None,\n",
    "                     train: bool = True) -> Tuple[ Dict[str, NDArray[np.float32]], Dict[str, NDArray[np.float32]], Dict[str, NDArray[np.float32]], int ]:\n",
    "        print(\"Preparing data...\")\n",
    "        # initialize max_case_length\n",
    "        max_case_length = False\n",
    "        # initialize token dicts\n",
    "        x_token_dict, y_token_dict, x_token_dict_numerical, y_token_dict_numerical = {}, {}, {}, {}\n",
    "        \n",
    "        # loop over all feature dfs\n",
    "        for idx, (feature, feature_df) in enumerate(dfs.items()):\n",
    "            \n",
    "            # get current feature_type\n",
    "            for feature_type, feature_lst in self.additional_columns.items():\n",
    "                if feature in feature_lst: break\n",
    "            \n",
    "            if idx == 0 and train:\n",
    "                (x_tokens, y_tokens, max_case_length\n",
    "                ) = data_loader.prepare_data(feature=feature, df=feature_df, max_case_length=True)\n",
    "            else:\n",
    "                x_tokens, y_tokens = data_loader.prepare_data(feature=feature, df=feature_df)\n",
    "            \n",
    "            if feature_type is Feature_Type.TIMESTAMP or feature_type is Feature_Type.NUMERICAL:\n",
    "                x_token_dict_numerical.update(x_tokens)\n",
    "                y_token_dict_numerical.update(y_tokens)\n",
    "            else:\n",
    "                # update x_token_dict\n",
    "                x_token_dict.update(x_tokens)\n",
    "                y_token_dict.update(y_tokens)\n",
    "            \n",
    "        # TODO:\n",
    "        if len(x_token_dict_numerical) > 0  and len(list(x_token_dict_numerical.values())[0]) > 0:\n",
    "            # Concatenate all the feature arrays along the rows (axis=0)\n",
    "            combined_data = np.vstack(list(x_token_dict_numerical.values()))\n",
    "            if x_scaler is None:\n",
    "                # Initialize the StandardScaler\n",
    "                # x_scaler = StandardScaler()\n",
    "                # x_scaler = MinMaxScaler(feature_range=(0, 30))\n",
    "                # x_scaler = FunctionTransformer(masked_standard_scaler, kw_args={'padding_value': -1})\n",
    "                x_scaler = FunctionTransformer(masked_min_max_scaler, kw_args={'padding_value': -1})\n",
    "                # Fit the scaler on the combined data\n",
    "                x_scaler.fit(combined_data)\n",
    "            # Transform the combined data\n",
    "            scaled_combined_data = x_scaler.transform(combined_data)\n",
    "            # split the scaled combined data back into the original feature dict\n",
    "            split_indices = np.cumsum([value.shape[0] for value in x_token_dict_numerical.values()])[:-1]\n",
    "            scaled_data_parts = np.vsplit(scaled_combined_data, split_indices)\n",
    "            # Reconstruct the dictionary with scaled data\n",
    "            scaled_dict = {key: scaled_data_parts[i] for i, key in enumerate(x_token_dict_numerical.keys())}\n",
    "            # update x_token_dict\n",
    "            x_token_dict.update(scaled_dict)\n",
    "        if len(y_token_dict_numerical) > 0:\n",
    "            # Prepare list to store valid arrays (non-empty)\n",
    "            valid_arrays = []\n",
    "            valid_keys = []\n",
    "\n",
    "            # Check for empty arrays and prepare data for scaling\n",
    "            for key, value in y_token_dict_numerical.items():\n",
    "                if value.size > 0:  # Only consider non-empty arrays\n",
    "                    valid_arrays.append(value.reshape(-1, 1))  # Reshape to 2D\n",
    "                    valid_keys.append(key)\n",
    "\n",
    "            # If there are valid arrays to scale\n",
    "            if valid_arrays:\n",
    "                combined_data = np.hstack(valid_arrays)  # Horizontal stacking for features\n",
    "\n",
    "                if y_scaler is None:\n",
    "                    # Initialize the StandardScaler\n",
    "                    # y_scaler = StandardScaler()\n",
    "                    y_scaler = MinMaxScaler(feature_range=(0, 30))\n",
    "                    # Fit the scaler on the combined data\n",
    "                    y_scaler.fit(combined_data)\n",
    "\n",
    "                # Transform the combined data\n",
    "                scaled_combined_data = y_scaler.transform(combined_data)\n",
    "\n",
    "                # Split the scaled combined data back into individual features\n",
    "                scaled_data_parts = np.hsplit(scaled_combined_data, scaled_combined_data.shape[1])\n",
    "\n",
    "                # Reconstruct the dictionary with scaled data\n",
    "                scaled_dict = {key: scaled_data_parts[i].flatten() for i, key in enumerate(valid_keys)}\n",
    "\n",
    "                # Update y_token_dict with the scaled data\n",
    "                y_token_dict.update(scaled_dict)\n",
    "\n",
    "            # Handle any empty arrays (if necessary)\n",
    "            for key, value in y_token_dict_numerical.items():\n",
    "                if value.size == 0:\n",
    "                    # Optionally, you can handle empty arrays here, e.g., leave them as-is\n",
    "                    y_token_dict[key] = value\n",
    "            \n",
    "            \n",
    "        # sort dicts\n",
    "        x_token_dict = dict(sorted(x_token_dict.items()))\n",
    "        y_token_dict = dict(sorted(y_token_dict.items()))\n",
    "\n",
    "        return x_token_dict, y_token_dict, x_scaler, y_scaler, max_case_length\n",
    "    \n",
    "    \n",
    "    # Prepare data and train the model\n",
    "    def train(self,\n",
    "            feature_type_dict: Dict[Feature_Type, List[str]],\n",
    "            train_token_dict_x: Dict[str, NDArray[np.float32]],\n",
    "            train_token_dict_y: Dict[str, NDArray[np.float32]],\n",
    "            word_dicts: Dict[str, Dict[str, int]],\n",
    "            max_case_length: int,\n",
    "            mask,\n",
    "            validation_split: float = 0.2  # Fraction of the training data to be used for validation\n",
    "            ) -> tf.keras.Model:\n",
    "\n",
    "        # Ensure that input columns and dictionaries are sorted\n",
    "        self.input_columns.sort()\n",
    "        self.target_columns = dict(sorted(self.target_columns.items()))\n",
    "        train_token_dict_x = dict(sorted(train_token_dict_x.items()))\n",
    "        train_token_dict_y = dict(sorted(train_token_dict_y.items()))\n",
    "        word_dicts = dict(sorted(word_dicts.items()))\n",
    "\n",
    "        # initialize model_wrapper with data for model\n",
    "        model_wrapper = transformer.ModelWrapper(\n",
    "                                                dataset_name = self.dataset_name,\n",
    "                                                input_columns=self.input_columns,\n",
    "                                                target_columns=self.target_columns,\n",
    "                                                word_dicts=word_dicts,\n",
    "                                                max_case_length=max_case_length,\n",
    "                                                feature_type_dict=feature_type_dict,\n",
    "                                                temporal_features=self.temporal_features,\n",
    "                                                model_architecture=self.model_architecture,\n",
    "                                                masking = True\n",
    "                                                )\n",
    "        \n",
    "        # train the model\n",
    "        model, history = model_wrapper.train_model(\n",
    "                                                    train_token_dict_x = train_token_dict_x,\n",
    "                                                    train_token_dict_y = train_token_dict_y,\n",
    "                                                    model_epochs = self.model_epochs,\n",
    "                                                    batch_size = 12,\n",
    "                                                    model_learning_rate = 0.001\n",
    "                                                    )\n",
    "        # Plot training loss\n",
    "        self._plot_training_loss(history)\n",
    "        return model\n",
    "            \n",
    "            \n",
    "    # helper function for plotting the training loss\n",
    "    def _plot_training_loss(self, history):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        if 'val_loss' in history.history:\n",
    "            plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss Over Epochs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "    def evaluate(self, model, data_loader: LogsDataLoader, test_dfs: Dict[str, pd.DataFrame],\n",
    "                 max_case_length: int, x_scaler=None, y_scaler=None):\n",
    "        print(\"Evaluating...\")\n",
    "        \n",
    "        #TODO: testing\n",
    "        # print(f\"Unscaled MAE training: {y_scaler.scale_ * 0.3030}\")\n",
    "\n",
    "        # Prepare lists to store evaluation metrics\n",
    "        k, accuracies, fscores, precisions, recalls, weights = {}, {}, {}, {}, {}, {}\n",
    "        mae, mse, rmse, r2 = {}, {}, {}, {}\n",
    "        \n",
    "        for target_col in self.target_columns.keys():\n",
    "            for feature_type, feature_lst in self.additional_columns.items():\n",
    "                if target_col in feature_lst:\n",
    "                    k.update({target_col: []})\n",
    "                    weights.update({target_col: []})\n",
    "                    \n",
    "                    if feature_type is Feature_Type.CATEGORICAL:\n",
    "                        accuracies.update({target_col: []})\n",
    "                        fscores.update({target_col: []})\n",
    "                        precisions.update({target_col: []})\n",
    "                        recalls.update({target_col: []})\n",
    "                    elif feature_type is Feature_Type.TIMESTAMP:\n",
    "                        mae.update({target_col: []})\n",
    "                        mse.update({target_col: []})\n",
    "                        rmse.update({target_col: []})\n",
    "                        r2.update({target_col: []})\n",
    "\n",
    "        # Calculate total number of samples\n",
    "        total_samples = len(list(test_dfs.values())[0])\n",
    "\n",
    "        # Iterate over all prefixes (k)\n",
    "        for i in range(1, max_case_length + 1):\n",
    "            print(\"Prefix length: \" + str(i))\n",
    "            test_data_subsets = {}\n",
    "\n",
    "            for key, df in test_dfs.items():\n",
    "                if (Feature_Type.TIMESTAMP in self.additional_columns\n",
    "                        and key in self.additional_columns[Feature_Type.TIMESTAMP]):\n",
    "                    prefix_str = f\"{key}##Prefix Length\"\n",
    "                else:\n",
    "                    prefix_str = \"Prefix Length\"\n",
    "                filtered_df = df[df[prefix_str] == i]\n",
    "                test_data_subsets.update({key: filtered_df})\n",
    "\n",
    "\n",
    "            x_token_dict, y_token_dict, _, _, _ = self.prepare_data(data_loader=data_loader, dfs=test_data_subsets,\n",
    "                                                            x_scaler=x_scaler, y_scaler=y_scaler, train=False)\n",
    "\n",
    "            # sort dicts\n",
    "            x_token_dict = dict(sorted(x_token_dict.items()))\n",
    "            y_token_dict = dict(sorted(y_token_dict.items()))\n",
    "\n",
    "            if len(test_data_subsets[self.input_columns[0]]) > 0:\n",
    "\n",
    "                # Make predictions\n",
    "                predictions = model.predict(x_token_dict)\n",
    "                \n",
    "                # Handle multiple outputs for multitask learning\n",
    "                if len(self.target_columns) > 1:\n",
    "                    result_dict = dict(zip(self.target_columns.keys(), predictions))\n",
    "                else:\n",
    "                    result_dict = dict(zip(self.target_columns.keys(), [predictions]))\n",
    "\n",
    "                # Compute metrics\n",
    "                for feature, result in result_dict.items():\n",
    "                    for feature_type, feature_lst in self.additional_columns.items():\n",
    "                        if feature in feature_lst:\n",
    "                            if feature_type is Feature_Type.CATEGORICAL:\n",
    "                                result = np.argmax(result, axis=1)\n",
    "                                accuracy = metrics.accuracy_score(y_token_dict[f\"output_{feature}\"], result)\n",
    "                                precision, recall, fscore, _ = metrics.precision_recall_fscore_support(\n",
    "                                    y_token_dict[f\"output_{feature}\"], result, average=\"weighted\", zero_division=0)\n",
    "                                weight = len(test_data_subsets[feature]) / total_samples\n",
    "\n",
    "                                k[feature].append(i)\n",
    "                                accuracies[feature].append(accuracy)\n",
    "                                fscores[feature].append(fscore)\n",
    "                                precisions[feature].append(precision)\n",
    "                                recalls[feature].append(recall)\n",
    "                                weights[feature].append(weight)\n",
    "                            \n",
    "                            elif feature_type is Feature_Type.TIMESTAMP:\n",
    "                                y_true_unscaled = y_token_dict[f\"output_{feature}\"]\n",
    "                                y_true = y_scaler.inverse_transform( y_true_unscaled.reshape(-1, y_true_unscaled.shape[-1])\n",
    "                                                                    ).reshape(y_true_unscaled.shape)\n",
    "                                y_pred = y_scaler.inverse_transform( result )\n",
    "                                mae_value = metrics.mean_absolute_error(y_true, y_pred)\n",
    "                                mse_value = metrics.mean_squared_error(y_true, y_pred)\n",
    "                                rmse_value = np.sqrt(mse_value)\n",
    "                                r2_value = metrics.r2_score(y_true, y_pred)\n",
    "                                weight = len(test_data_subsets[feature]) / total_samples\n",
    "\n",
    "                                k[feature].append(i)\n",
    "                                mae[feature].append(mae_value)\n",
    "                                mse[feature].append(mse_value)\n",
    "                                rmse[feature].append(rmse_value)\n",
    "                                r2[feature].append(r2_value)\n",
    "                                weights[feature].append(weight)\n",
    "\n",
    "        for target_col in self.target_columns.keys():\n",
    "            for feature_type, feature_lst in self.additional_columns.items():\n",
    "                if target_col in feature_lst:\n",
    "                    if feature_type is Feature_Type.CATEGORICAL:\n",
    "                        # Compute weighted mean metrics over all k\n",
    "                        weighted_accuracy = np.average(accuracies[target_col], weights=weights[target_col])\n",
    "                        weighted_fscore = np.average(fscores[target_col], weights=weights[target_col])\n",
    "                        weighted_precision = np.average(precisions[target_col], weights=weights[target_col])\n",
    "                        weighted_recall = np.average(recalls[target_col], weights=weights[target_col])\n",
    "                        # Append weighted mean metrics to the lists\n",
    "                        weights[target_col].append(\"\")\n",
    "                        k[target_col].append(\"Weighted Mean\")\n",
    "                        accuracies[target_col].append(weighted_accuracy)\n",
    "                        fscores[target_col].append(weighted_fscore)\n",
    "                        precisions[target_col].append(weighted_precision)\n",
    "                        recalls[target_col].append(weighted_recall)\n",
    "                        # Create a DataFrame to display the results\n",
    "                        print(f\"Results for {target_col}\")\n",
    "                        results_df = pd.DataFrame({\n",
    "                            'k': k[target_col],\n",
    "                            'weight': weights[target_col],\n",
    "                            'accuracy': accuracies[target_col],\n",
    "                            'fscore': fscores[target_col],\n",
    "                            'precision': precisions[target_col],\n",
    "                            'recall': recalls[target_col]\n",
    "                        })\n",
    "                        # Display the results\n",
    "                        print(results_df)\n",
    "                    \n",
    "                    elif feature_type is Feature_Type.TIMESTAMP:\n",
    "                        # Compute weighted mean metrics over all k\n",
    "                        weighted_mae = np.average(mae[target_col], weights=weights[target_col])\n",
    "                        weighted_mse = np.average(mse[target_col], weights=weights[target_col])\n",
    "                        weighted_rmse = np.average(rmse[target_col], weights=weights[target_col])\n",
    "                        weighted_r2 = np.average(r2[target_col], weights=weights[target_col])\n",
    "                        # Append weighted mean metrics to the lists\n",
    "                        weights[target_col].append(\"\")\n",
    "                        k[target_col].append(\"Weighted Mean\")\n",
    "                        mae[target_col].append(weighted_mae)\n",
    "                        mse[target_col].append(weighted_mse)\n",
    "                        rmse[target_col].append(weighted_rmse)\n",
    "                        r2[target_col].append(weighted_r2)\n",
    "                        # Create a DataFrame to display the results\n",
    "                        print(f\"Results for {target_col}\")\n",
    "                        results_df = pd.DataFrame({\n",
    "                            'k': k[target_col],\n",
    "                            'weight': weights[target_col],\n",
    "                            'mae': mae[target_col],\n",
    "                            'mse': mse[target_col],\n",
    "                            'rmse': rmse[target_col],\n",
    "                            'r2': r2[target_col]\n",
    "                        })\n",
    "                        # Display the results\n",
    "                        print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper Functions ###\n",
    "\n",
    "# helper function to save xes file as csv\n",
    "def save_csv(args):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(**args)  # Examples: \"concept:name\", \"Resource\"\n",
    "    pipe.save_as_csv()\n",
    "    \n",
    "\n",
    "# helper function: do only preprocessing on data\n",
    "def preprocess(args):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(**args)  # Examples: \"concept:name\", \"Resource\"\n",
    "    # preprocess data\n",
    "    pipe.preprocess_log()\n",
    "\n",
    "\n",
    "# helper function\n",
    "def run(args):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(**args)  # Examples: \"concept:name\", \"Resource\"\n",
    "\n",
    "    # print parameters\n",
    "    print(pipe)\n",
    "\n",
    "    # preprocess data\n",
    "    pipe.preprocess_log()\n",
    "\n",
    "    # load data\n",
    "    data_loader, train_dfs, test_dfs, word_dicts, feature_type_dict, mask = pipe.load_data()\n",
    "\n",
    "    # prepare data\n",
    "    train_token_dict_x, train_token_dict_y, x_scaler, y_scaler, max_case_length = pipe.prepare_data(data_loader, train_dfs)\n",
    "\n",
    "    # train the model\n",
    "    model = pipe.train(\n",
    "                feature_type_dict = feature_type_dict,\n",
    "                train_token_dict_x = train_token_dict_x,\n",
    "                train_token_dict_y = train_token_dict_y,\n",
    "                word_dicts = word_dicts,\n",
    "                max_case_length = max_case_length,\n",
    "                mask = mask\n",
    "                )\n",
    "\n",
    "    # evaluate the model\n",
    "    pipe.evaluate(model=model, data_loader=data_loader, test_dfs=test_dfs, x_scaler=x_scaler,\n",
    "                  y_scaler=y_scaler, max_case_length=max_case_length)\n",
    "    print(\"\")\n",
    "    print(\"======================================\")\n",
    "    print(\"======================================\")\n",
    "    \n",
    "    \n",
    "# function for testing out code\n",
    "def test(args):\n",
    "    # initialize pipeline with parameters\n",
    "    pipe = pipeline(**args)  # Examples: \"concept:name\", \"Resource\"\n",
    "\n",
    "    # print parameters\n",
    "    print(pipe)\n",
    "\n",
    "    # preprocess data\n",
    "    pipe.preprocess_log()\n",
    "\n",
    "    # load data\n",
    "    data_loader, train_dfs, test_dfs, word_dicts, feature_type_dict = pipe.load_data()\n",
    "\n",
    "    # prepare data\n",
    "    train_token_dict_x, train_token_dict_y, x_scaler, y_scaler, max_case_length = pipe.prepare_data(data_loader, train_dfs)\n",
    "\n",
    "    # # train the model\n",
    "    # model = pipe.train(\n",
    "    #             feature_type_dict = feature_type_dict,\n",
    "    #             train_token_dict_x = train_token_dict_x,\n",
    "    #             train_token_dict_y = train_token_dict_y,\n",
    "    #             word_dicts = word_dicts,\n",
    "    #             max_case_length = max_case_length\n",
    "    #             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Args & Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: 'helpdesk'\n",
      "filepath: 'helpdesk.csv'\n",
      "columns: '['Case ID', 'Activity', 'Complete Timestamp']'\n",
      "additional_columns: '{<Feature_Type.CATEGORICAL: 'categorical'>: ['Resource']}'\n",
      "datetime_format: '%Y-%m-%d %H:%M:%S.%f'\n",
      "Model Epochs: '1'\n",
      "Number of Transformer Layers in Model: '1'\n",
      "Target columns: '{'Resource': <Target.NEXT_FEATURE: 'next_feature'>, 'concept_name': <Target.NEXT_FEATURE: 'next_feature'>}'\n",
      "Input columns: '['concept_name', 'Resource', 'Complete Timestamp']'\n",
      "\n",
      "All processed files for current spec found. Preprocessing skipped.\n",
      "Loading data from preprocessed train-test split...\n",
      "['concept_name', 'time_timestamp', 'Resource']\n",
      "Preparing data...\n",
      "Creating model...\n",
      "Masking active.\n",
      "Using Multi-Task Learning Setup\n",
      "----------------------------------------------------\n",
      "Training...\n",
      "896/896 [==============================] - 46s 38ms/step - loss: 2.5458 - output_Resource_loss: 1.6919 - output_concept_name_loss: 0.8539 - val_loss: 1.9266 - val_output_Resource_loss: 1.2712 - val_output_concept_name_loss: 0.6554\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Prefix length: 1\n",
      "Preparing data...\n",
      "29/29 [==============================] - 3s 19ms/step\n",
      "Prefix length: 2\n",
      "Preparing data...\n",
      "29/29 [==============================] - 1s 19ms/step\n",
      "Prefix length: 3\n",
      "Preparing data...\n",
      "28/28 [==============================] - 1s 22ms/step\n",
      "Prefix length: 4\n",
      "Preparing data...\n",
      "12/12 [==============================] - 0s 18ms/step\n",
      "Prefix length: 5\n",
      "Preparing data...\n",
      "5/5 [==============================] - 0s 22ms/step\n",
      "Prefix length: 6\n",
      "Preparing data...\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Prefix length: 7\n",
      "Preparing data...\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Prefix length: 8\n",
      "Preparing data...\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "Prefix length: 9\n",
      "Preparing data...\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Prefix length: 10\n",
      "Preparing data...\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Prefix length: 11\n",
      "Preparing data...\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Prefix length: 12\n",
      "Preparing data...\n",
      "Prefix length: 13\n",
      "Preparing data...\n",
      "Prefix length: 14\n",
      "Preparing data...\n",
      "Results for Resource\n",
      "                k    weight  accuracy    fscore  precision    recall\n",
      "0               1  0.274745  0.425764  0.358721   0.448114  0.425764\n",
      "1               2  0.274445  0.660109  0.629135   0.631611  0.660109\n",
      "2               3  0.262448  0.762286  0.716943   0.751775  0.762286\n",
      "3               4  0.111878  0.656836  0.579020   0.655561  0.656836\n",
      "4               5  0.046191  0.720779  0.659321   0.715771  0.720779\n",
      "5               6  0.017996  0.683333  0.622595   0.705105  0.683333\n",
      "6               7  0.007199  0.708333  0.655754   0.636111  0.708333\n",
      "7               8  0.003299  0.363636  0.409091   0.484848  0.363636\n",
      "8               9    0.0012  0.500000  0.541667   0.875000  0.500000\n",
      "9              10    0.0003  1.000000  1.000000   1.000000  1.000000\n",
      "10             11    0.0003  1.000000  1.000000   1.000000  1.000000\n",
      "11  Weighted Mean            0.624775  0.573138   0.620683  0.624775\n",
      "Results for concept_name\n",
      "                k    weight  accuracy    fscore  precision    recall\n",
      "0               1  0.274745  0.832969  0.765892   0.720205  0.832969\n",
      "1               2  0.274445  0.697268  0.593481   0.518789  0.697268\n",
      "2               3  0.262448  0.836571  0.804390   0.795663  0.836571\n",
      "3               4  0.111878  0.839142  0.798938   0.770103  0.839142\n",
      "4               5  0.046191  0.811688  0.755433   0.715946  0.811688\n",
      "5               6  0.017996  0.833333  0.788871   0.821663  0.833333\n",
      "6               7  0.007199  0.791667  0.709105   0.652976  0.791667\n",
      "7               8  0.003299  0.545455  0.496503   0.707071  0.545455\n",
      "8               9    0.0012  0.250000  0.375000   0.750000  0.250000\n",
      "9              10    0.0003  1.000000  1.000000   1.000000  1.000000\n",
      "10             11    0.0003  1.000000  1.000000   1.000000  1.000000\n",
      "11  Weighted Mean            0.794541  0.730680   0.691619  0.794541\n",
      "\n",
      "======================================\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "# args_helpdesk = {\n",
    "#         \"dataset_name\": \"helpdesk\",\n",
    "#         \"filepath\": \"helpdesk.csv\",\n",
    "#         \"columns\": [\"Case ID\", \"Activity\", \"Complete Timestamp\"],\n",
    "#         \"additional_columns\": {},\n",
    "#         \"datetime_format\": \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "#         \"model_learning_rate\": 0.001,\n",
    "#         \"model_epochs\": 3,\n",
    "#         \"model_num_layers\": 1,\n",
    "#         \"target_columns\": {\"Complete Timestamp\": Target.NEXT_FEATURE},\n",
    "#         \"input_columns\": [\"Activity\"],\n",
    "#         \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: False, Temporal_Feature.HOUR_OF_DAY: False},\n",
    "#         \"model_architecture\": Model_Architecture.COMMON_POSEMBS_TRANSF\n",
    "#         }\n",
    "\n",
    "args_helpdesk = {\n",
    "        \"dataset_name\": \"helpdesk\",\n",
    "        \"filepath\": \"helpdesk.csv\",\n",
    "        \"columns\": [\"Case ID\", \"Activity\", \"Complete Timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"Resource\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "        \"model_epochs\": 1,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"Activity\": Target.NEXT_FEATURE, \"Resource\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"Activity\", \"Resource\", \"Complete Timestamp\"],\n",
    "        \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: True, Temporal_Feature.HOUR_OF_DAY: True},\n",
    "        \"model_architecture\": Model_Architecture.COMMON_POSEMBS_TRANSF\n",
    "        }\n",
    "\n",
    "# args_helpdesk = {\n",
    "#         \"dataset_name\": \"helpdesk\",\n",
    "#         \"filepath\": \"helpdesk.csv\",\n",
    "#         \"columns\": [\"Case ID\", \"Activity\", \"Complete Timestamp\"],\n",
    "#         \"additional_columns\": {Feature_Type.CATEGORICAL: [\"Resource\"]},\n",
    "#         \"datetime_format\": \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "#         \"model_learning_rate\": 0.001,\n",
    "#         \"model_epochs\": 1,\n",
    "#         \"model_num_layers\": 1,\n",
    "#         \"target_columns\": {\"Activity\": Target.NEXT_FEATURE},\n",
    "#         \"input_columns\": [\"Activity\", \"Resource\", \"Complete Timestamp\"],\n",
    "#         \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: True, Temporal_Feature.HOUR_OF_DAY: True}\n",
    "#         }\n",
    "\n",
    "args_sepsis = {\n",
    "        \"dataset_name\": \"sepsis\",\n",
    "        \"filepath\": \"sepsis.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:group\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S%z\",\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 1,\n",
    "        \"model_num_layers\": 10,\n",
    "        \"target_columns\": {\"concept:name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept:name\", \"org:group\"],\n",
    "        \"temporal_features\": {Temporal_Feature.DAY_OF_WEEK: True, Temporal_Feature.HOUR_OF_DAY: True}\n",
    "        }\n",
    "\n",
    "args_bpi_2012 = {\n",
    "        \"dataset_name\": \"bpi_2012\",\n",
    "        \"filepath\": \"BPI_Challenge_2012.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:resource\"]},\n",
    "        \"datetime_format\": None,\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 10,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"concept:name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept:name\", \"org:resource\"]\n",
    "        }\n",
    "\n",
    "args_bpi_2013 = {\n",
    "        \"dataset_name\": \"bpi_2013\",\n",
    "        \"filepath\": \"BPI_Challenge_2013_incidents.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:resource\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S%z\",\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 2,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"concept:name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept:name\", \"org:resource\"]\n",
    "        }\n",
    "\n",
    "args_bpi_2015_1 = {\n",
    "        \"dataset_name\": \"bpi_2015_1\",\n",
    "        \"filepath\": \"BPIC15_1.xes\",\n",
    "        \"columns\": [\"case:concept:name\", \"concept:name\", \"time:timestamp\"],\n",
    "        \"additional_columns\": {Feature_Type.CATEGORICAL: [\"org:resource\"]},\n",
    "        \"datetime_format\": \"%Y-%m-%d %H:%M:%S%z\",\n",
    "        \"model_learning_rate\": 0.001,\n",
    "        \"model_epochs\": 2,\n",
    "        \"model_num_layers\": 1,\n",
    "        \"target_columns\": {\"concept_name\": Target.NEXT_FEATURE},\n",
    "        \"input_columns\": [\"concept_name\", \"org_resource\"]\n",
    "        }\n",
    "\n",
    "\n",
    "run(args_helpdesk)\n",
    "# preprocess(args_helpdesk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change settings and run again\n",
    "\n",
    "# args_bpi_2012[\"additional_columns\"] = {}\n",
    "# args_bpi_2012[\"input_columns\"] = [\"concept:name\"]\n",
    "# run(args_bpi_2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run(additional_columns={Feature_Type.CATEGORICAL: [\"Resource\"]}, input_columns=[\"Activity\", \"Resource\"], target_columns=[\"Activity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run(additional_columns={Feature_Type.CATEGORICAL: [\"Resource\"]}, input_columns=[\"Activity\", \"Resource\"], target_columns=[\"Activity\", \"Resource\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
